{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, Embedding, Masking\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Bidirectional\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "parent_wd = cwd.replace('/model', '')\n",
    "training_set_path = parent_wd + '/preprocessing/training_set'\n",
    "dev_set_path = parent_wd + '/preprocessing/dev_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_set_path, 'rb') as f:\n",
    "    training_set = pickle.load(f)\n",
    "with open(dev_set_path, 'rb') as f:\n",
    "    dev_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_set['X']\n",
    "Y_train = training_set['Y']\n",
    "X_dev = dev_set['X']\n",
    "Y_dev = dev_set['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_normalized_set_path = parent_wd + '/preprocessing/training_set_n'\n",
    "dev_normalized_set_path = parent_wd + '/preprocessing/dev_set_n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_normalized_set_path, 'rb') as f:\n",
    "    training_set_n = pickle.load(f)\n",
    "with open(dev_normalized_set_path, 'rb') as f:\n",
    "    dev_set_n = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n = training_set_n['X']\n",
    "Y_train_n = training_set_n['Y']\n",
    "X_dev_n = dev_set_n['X']\n",
    "Y_dev_n = dev_set_n['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 1: LSTM, Relu, adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 50)                12200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                816       \n",
      "=================================================================\n",
      "Total params: 13,016\n",
      "Trainable params: 13,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(LSTM(50, activation='relu', input_shape=(30, 10)))\n",
    "model1.add(Dense(16, activation='softmax'))\n",
    "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 188us/step - loss: 2.0903 - accuracy: 0.3211 - val_loss: 1.7760 - val_accuracy: 0.3377\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 4s 178us/step - loss: 1.7138 - accuracy: 0.3616 - val_loss: 1.6933 - val_accuracy: 0.3713\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 4s 174us/step - loss: 1.6557 - accuracy: 0.3756 - val_loss: 1.6665 - val_accuracy: 0.3740\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 4s 177us/step - loss: 1.6128 - accuracy: 0.3840 - val_loss: 1.6043 - val_accuracy: 0.3893\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 4s 177us/step - loss: 1.6038 - accuracy: 0.3895 - val_loss: 1.5829 - val_accuracy: 0.3933\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 4s 176us/step - loss: 1.5748 - accuracy: 0.3969 - val_loss: 1.5757 - val_accuracy: 0.3940\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 4s 180us/step - loss: 1.5589 - accuracy: 0.3992 - val_loss: 1.5570 - val_accuracy: 0.3997\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 4s 175us/step - loss: 1.5542 - accuracy: 0.4013 - val_loss: 1.5440 - val_accuracy: 0.4080\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 4s 180us/step - loss: 1.5538 - accuracy: 0.3998 - val_loss: 1.6152 - val_accuracy: 0.3787\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 4s 177us/step - loss: 1.5434 - accuracy: 0.4050 - val_loss: 1.5847 - val_accuracy: 0.3893\n"
     ]
    }
   ],
   "source": [
    "history1= model1.fit(X_train, Y_train, epochs=10, batch_size=256, validation_data = (X_dev, Y_dev))\n",
    "history1_all.append(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 4s 181us/step - loss: 1.5375 - accuracy: 0.4052 - val_loss: 1.5429 - val_accuracy: 0.3997\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 4s 176us/step - loss: 1.5262 - accuracy: 0.4069 - val_loss: 1.5718 - val_accuracy: 0.3877\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 4s 178us/step - loss: 1.5208 - accuracy: 0.4088 - val_loss: 1.5338 - val_accuracy: 0.4060\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 4s 180us/step - loss: 1.5129 - accuracy: 0.4085 - val_loss: 1.5343 - val_accuracy: 0.4103\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 186us/step - loss: 1.5249 - accuracy: 0.4045 - val_loss: 1.5695 - val_accuracy: 0.4050\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 4s 182us/step - loss: 1.5209 - accuracy: 0.4081 - val_loss: 1.5443 - val_accuracy: 0.4067\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 4s 179us/step - loss: 1.5091 - accuracy: 0.4098 - val_loss: 1.5118 - val_accuracy: 0.4170\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 4s 180us/step - loss: 1.5109 - accuracy: 0.4067 - val_loss: 1.5224 - val_accuracy: 0.4073\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 4s 178us/step - loss: 1.5046 - accuracy: 0.4111 - val_loss: 1.5265 - val_accuracy: 0.4127\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 4s 179us/step - loss: 1.5036 - accuracy: 0.4098 - val_loss: 1.5450 - val_accuracy: 0.4077\n"
     ]
    }
   ],
   "source": [
    "history1= model1.fit(X_train, Y_train, epochs=10, batch_size=256, validation_data = (X_dev, Y_dev))\n",
    "history1_all.append(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 4s 179us/step - loss: 1.5122 - accuracy: 0.4112 - val_loss: 1.5094 - val_accuracy: 0.4197\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 4s 170us/step - loss: 1.4921 - accuracy: 0.4149 - val_loss: 1.5308 - val_accuracy: 0.4050\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 4s 182us/step - loss: 1.5073 - accuracy: 0.4115 - val_loss: 1.5191 - val_accuracy: 0.4090\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 4s 178us/step - loss: 1.4935 - accuracy: 0.4137 - val_loss: 1.5499 - val_accuracy: 0.3990\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 4s 176us/step - loss: 1.4998 - accuracy: 0.4119 - val_loss: 1.5764 - val_accuracy: 0.4027\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 4s 179us/step - loss: 1.4953 - accuracy: 0.4120 - val_loss: 1.5177 - val_accuracy: 0.4090\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 4s 182us/step - loss: 1.4989 - accuracy: 0.4134 - val_loss: 1.5288 - val_accuracy: 0.4080\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 4s 182us/step - loss: 1.4873 - accuracy: 0.4163 - val_loss: 1.4969 - val_accuracy: 0.4230\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 206us/step - loss: 1.4807 - accuracy: 0.4191 - val_loss: 1.5127 - val_accuracy: 0.4110\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 188us/step - loss: 1.4851 - accuracy: 0.4147 - val_loss: 1.5042 - val_accuracy: 0.4163\n"
     ]
    }
   ],
   "source": [
    "history1= model1.fit(X_train, Y_train, epochs=10, batch_size=256, validation_data = (X_dev, Y_dev))\n",
    "history1_all.append(history1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 2: LSTM, Relu, adam, increase neuron number to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                1616      \n",
      "=================================================================\n",
      "Total params: 46,016\n",
      "Trainable params: 46,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(100, activation='relu', input_shape=(30, 10)))\n",
    "model2.add(Dense(16, activation='softmax'))\n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 8s 318us/step - loss: 1.9014 - accuracy: 0.3375 - val_loss: 1.7173 - val_accuracy: 0.3640\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 8s 305us/step - loss: 1.6525 - accuracy: 0.3774 - val_loss: 1.6370 - val_accuracy: 0.3760\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 8s 310us/step - loss: 1.6109 - accuracy: 0.3855 - val_loss: 1.5822 - val_accuracy: 0.4017\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 8s 320us/step - loss: 1.5749 - accuracy: 0.3964 - val_loss: 1.5808 - val_accuracy: 0.3960\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 9s 365us/step - loss: 1.5524 - accuracy: 0.4011 - val_loss: 1.5520 - val_accuracy: 0.4080\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 8s 313us/step - loss: 1.5409 - accuracy: 0.4039 - val_loss: 1.5572 - val_accuracy: 0.4077\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 8s 315us/step - loss: 1.5349 - accuracy: 0.4040 - val_loss: 1.5643 - val_accuracy: 0.4047\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 8s 315us/step - loss: 1.5219 - accuracy: 0.4085 - val_loss: 1.5508 - val_accuracy: 0.4070\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 8s 320us/step - loss: 1.5136 - accuracy: 0.4096 - val_loss: 1.5159 - val_accuracy: 0.4177\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 8s 315us/step - loss: 1.5145 - accuracy: 0.4101 - val_loss: 1.5739 - val_accuracy: 0.4030\n"
     ]
    }
   ],
   "source": [
    "history2= model2.fit(X_train, Y_train, epochs=10, batch_size=256, validation_data = (X_dev, Y_dev))\n",
    "history2_all.append(history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 3: LSTM, Relu, adam, add masking layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_1 (Masking)          (None, 30, 10)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                1616      \n",
      "=================================================================\n",
      "Total params: 46,016\n",
      "Trainable params: 46,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Masking(mask_value=0., input_shape=(30, 10)))\n",
    "model3.add(LSTM(100, activation='relu', input_shape=(30, 10)))\n",
    "model3.add(Dense(16, activation='softmax'))\n",
    "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "history3_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 9s 377us/step - loss: 1.9538 - accuracy: 0.3169 - val_loss: 1.7443 - val_accuracy: 0.3540\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 10s 388us/step - loss: 1.6918 - accuracy: 0.3673 - val_loss: 1.6766 - val_accuracy: 0.3733\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 10s 404us/step - loss: 1.6372 - accuracy: 0.3827 - val_loss: 1.6175 - val_accuracy: 0.3953\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 10s 402us/step - loss: 1.5958 - accuracy: 0.3902 - val_loss: 1.5834 - val_accuracy: 0.3883\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 9s 383us/step - loss: 1.5690 - accuracy: 0.3968 - val_loss: 1.5670 - val_accuracy: 0.3940\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 12s 474us/step - loss: 1.5540 - accuracy: 0.3989 - val_loss: 1.5603 - val_accuracy: 0.3970\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 11s 443us/step - loss: 1.5420 - accuracy: 0.4021 - val_loss: 1.5667 - val_accuracy: 0.3970\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 8s 343us/step - loss: 1.5353 - accuracy: 0.4044 - val_loss: 1.5384 - val_accuracy: 0.3997\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 9s 381us/step - loss: 1.5218 - accuracy: 0.4073 - val_loss: 1.5436 - val_accuracy: 0.4007\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 9s 374us/step - loss: 1.5134 - accuracy: 0.4123 - val_loss: 1.5205 - val_accuracy: 0.4063\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(X_train, Y_train, epochs=10, batch_size=256, validation_data = (X_dev, Y_dev))\n",
    "history3_all.append(history3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 4: LSTM, Relu, adam, add masking layer, increase neuron to 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_2 (Masking)          (None, 30, 10)            0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 1000)              4044000   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                16016     \n",
      "=================================================================\n",
      "Total params: 4,060,016\n",
      "Trainable params: 4,060,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Masking(mask_value=0., input_shape=(30, 10)))\n",
    "model4.add(LSTM(1000, activation='relu', input_shape=(30, 10)))\n",
    "model4.add(Dense(16, activation='softmax'))\n",
    "model4.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "history4_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 190s 8ms/step - loss: 1.7885 - accuracy: 0.3481 - val_loss: 1.6928 - val_accuracy: 0.3677\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 181s 7ms/step - loss: 1.6352 - accuracy: 0.3810 - val_loss: 1.6430 - val_accuracy: 0.3710\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 178s 7ms/step - loss: 1.5960 - accuracy: 0.3911 - val_loss: 1.5738 - val_accuracy: 0.3983\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 196s 8ms/step - loss: 1.5624 - accuracy: 0.3964 - val_loss: 1.5432 - val_accuracy: 0.4103\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 202s 8ms/step - loss: 1.5395 - accuracy: 0.4027 - val_loss: 1.5270 - val_accuracy: 0.4037\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 209s 9ms/step - loss: 1.5248 - accuracy: 0.4094 - val_loss: 1.5268 - val_accuracy: 0.4080\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 198s 8ms/step - loss: 1.5086 - accuracy: 0.4091 - val_loss: 1.5176 - val_accuracy: 0.4023\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 196s 8ms/step - loss: 1.4958 - accuracy: 0.4140 - val_loss: 1.5257 - val_accuracy: 0.3977\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 189s 8ms/step - loss: 1.4864 - accuracy: 0.4180 - val_loss: 1.5102 - val_accuracy: 0.4120\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 204s 8ms/step - loss: 1.4783 - accuracy: 0.4213 - val_loss: 1.4903 - val_accuracy: 0.4123\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(X_train, Y_train, epochs=10, batch_size=256, validation_data = (X_dev, Y_dev))\n",
    "history4_all.append(history4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 5: LSTM, Relu, adam, add masking layer, using normalized input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_3 (Masking)          (None, 30, 10)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                1616      \n",
      "=================================================================\n",
      "Total params: 46,016\n",
      "Trainable params: 46,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Masking(mask_value=0., input_shape=(30, 10)))\n",
    "model5.add(LSTM(100, activation='relu', input_shape=(30, 10)))\n",
    "model5.add(Dense(16, activation='softmax'))\n",
    "model5.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "history5_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 11s 434us/step - loss: 1.9202 - accuracy: 0.3386 - val_loss: 1.7371 - val_accuracy: 0.3617\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 13s 515us/step - loss: 1.6864 - accuracy: 0.3731 - val_loss: 1.6865 - val_accuracy: 0.3800\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 12s 480us/step - loss: 1.6438 - accuracy: 0.3807 - val_loss: 1.6331 - val_accuracy: 0.3903\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 10s 405us/step - loss: 1.6121 - accuracy: 0.3900 - val_loss: 1.6034 - val_accuracy: 0.3913\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 10s 394us/step - loss: 1.5800 - accuracy: 0.3960 - val_loss: 1.5816 - val_accuracy: 0.3993\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 11s 450us/step - loss: 1.5591 - accuracy: 0.3989 - val_loss: 1.5608 - val_accuracy: 0.4033\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 11s 431us/step - loss: 1.5447 - accuracy: 0.4038 - val_loss: 1.5400 - val_accuracy: 0.4010\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 10s 423us/step - loss: 1.5350 - accuracy: 0.4078 - val_loss: 1.5513 - val_accuracy: 0.4063\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 11s 447us/step - loss: 1.5229 - accuracy: 0.4078 - val_loss: 1.5288 - val_accuracy: 0.4103\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 10s 387us/step - loss: 1.5172 - accuracy: 0.4110 - val_loss: 1.5082 - val_accuracy: 0.4167\n"
     ]
    }
   ],
   "source": [
    "history5 = model5.fit(X_train_n, Y_train_n, epochs=10, batch_size=256, validation_data = (X_dev_n, Y_dev_n))\n",
    "history5_all.append(history5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 11s 432us/step - loss: 1.5082 - accuracy: 0.4152 - val_loss: 1.5093 - val_accuracy: 0.4100\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 11s 453us/step - loss: 1.5016 - accuracy: 0.4182 - val_loss: 1.5035 - val_accuracy: 0.4123\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 10s 422us/step - loss: 1.4970 - accuracy: 0.4175 - val_loss: 1.4964 - val_accuracy: 0.4177\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 10s 415us/step - loss: 1.4945 - accuracy: 0.4211 - val_loss: 1.4958 - val_accuracy: 0.4157\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 11s 440us/step - loss: 1.4912 - accuracy: 0.4216 - val_loss: 1.5199 - val_accuracy: 0.4137\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 10s 390us/step - loss: 1.4825 - accuracy: 0.4234 - val_loss: 1.4988 - val_accuracy: 0.4157\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 10s 410us/step - loss: 1.4802 - accuracy: 0.4229 - val_loss: 1.4898 - val_accuracy: 0.4157\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 12s 483us/step - loss: 1.4733 - accuracy: 0.4227 - val_loss: 1.5042 - val_accuracy: 0.4177\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 14s 574us/step - loss: 1.4724 - accuracy: 0.4239 - val_loss: 1.4880 - val_accuracy: 0.4147\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 16s 630us/step - loss: 1.4622 - accuracy: 0.4254 - val_loss: 1.4951 - val_accuracy: 0.4157\n"
     ]
    }
   ],
   "source": [
    "history5 = model5.fit(X_train_n, Y_train_n, epochs=10, batch_size=256, validation_data = (X_dev_n, Y_dev_n))\n",
    "history5_all.append(history5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 6: LSTM, Relu, adam, add masking layer, using normalized input, weighted input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 10150,\n",
    "                1: 10150,\n",
    "                2: 1128., \n",
    "                3: 1, \n",
    "                4: 2.65, \n",
    "                5: 2.20, \n",
    "                6: 2.51, \n",
    "                7: 3.30, \n",
    "                8: 6.54, \n",
    "                9: 6.26, \n",
    "                10: 9.57, \n",
    "                11: 26.1, \n",
    "                12: 56.1, \n",
    "                13: 199, \n",
    "                14: 191, \n",
    "                15: 10150}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_log = {0: 10.23,\n",
    "                1: 10.23,\n",
    "                2: 8.03, \n",
    "                3: 1, \n",
    "                4: 1.97, \n",
    "                5: 1.79, \n",
    "                6: 1.92, \n",
    "                7: 2.29, \n",
    "                8: 2.88, \n",
    "                9: 2.83, \n",
    "                10: 3.26, \n",
    "                11: 4.26, \n",
    "                12: 5.03, \n",
    "                13: 6.29, \n",
    "                14: 6.25, \n",
    "                15: 10.23}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_5 (Masking)          (None, 30, 10)            0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1616      \n",
      "=================================================================\n",
      "Total params: 46,016\n",
      "Trainable params: 46,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Masking(mask_value=0., input_shape=(30, 10)))\n",
    "model6.add(LSTM(100, activation='relu', input_shape=(30, 10)))\n",
    "model6.add(Dense(16, activation='softmax'))\n",
    "model6.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model6.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "history6_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 12s 475us/step - loss: 28.2097 - accuracy: 0.0046 - val_loss: 3.0710 - val_accuracy: 0.0013\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 10s 416us/step - loss: 20.2837 - accuracy: 7.7129e-04 - val_loss: 3.3970 - val_accuracy: 0.0013\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 10s 395us/step - loss: 18.7282 - accuracy: 7.7129e-04 - val_loss: 3.2223 - val_accuracy: 0.0013\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 10s 395us/step - loss: 18.0757 - accuracy: 7.7129e-04 - val_loss: 3.5722 - val_accuracy: 0.0013\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 10s 401us/step - loss: 17.6993 - accuracy: 7.7129e-04 - val_loss: 3.3520 - val_accuracy: 0.0013\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 10s 405us/step - loss: 17.2966 - accuracy: 7.7129e-04 - val_loss: 3.0918 - val_accuracy: 0.0013\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 10s 405us/step - loss: 17.2960 - accuracy: 0.0342 - val_loss: 2.9924 - val_accuracy: 0.0067\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 10s 396us/step - loss: 16.2556 - accuracy: 0.0482 - val_loss: 2.9263 - val_accuracy: 0.0923\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 10s 398us/step - loss: 15.7294 - accuracy: 0.0781 - val_loss: 3.0469 - val_accuracy: 0.0650\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 10s 388us/step - loss: 14.8798 - accuracy: 0.1329 - val_loss: 2.6969 - val_accuracy: 0.1403\n"
     ]
    }
   ],
   "source": [
    "history6 = model6.fit(X_train_n, Y_train_n, epochs=10, batch_size=256, validation_data = (X_dev_n, Y_dev_n), class_weight=class_weight)\n",
    "history6_all.append(history6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 10s 424us/step - loss: 14.4689 - accuracy: 0.1255 - val_loss: 2.6855 - val_accuracy: 0.1450\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 9s 383us/step - loss: 13.9215 - accuracy: 0.1713 - val_loss: 2.6016 - val_accuracy: 0.2000\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 10s 398us/step - loss: 12.8512 - accuracy: 0.1552 - val_loss: 2.4450 - val_accuracy: 0.1813\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 10s 389us/step - loss: 13.0175 - accuracy: 0.1530 - val_loss: 2.6318 - val_accuracy: 0.0720\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 9s 381us/step - loss: 13.5409 - accuracy: 0.1517 - val_loss: 2.7211 - val_accuracy: 0.2007\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 10s 386us/step - loss: 12.8318 - accuracy: 0.2369 - val_loss: 2.3968 - val_accuracy: 0.2453\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 10s 390us/step - loss: 12.1627 - accuracy: 0.2303 - val_loss: 2.3223 - val_accuracy: 0.2437\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 9s 381us/step - loss: 11.3249 - accuracy: 0.2383 - val_loss: 2.7887 - val_accuracy: 0.0813\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 9s 384us/step - loss: 11.4941 - accuracy: 0.1932 - val_loss: 4.3552 - val_accuracy: 0.0477\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 10s 410us/step - loss: 13.4503 - accuracy: 0.1120 - val_loss: 2.4907 - val_accuracy: 0.1703\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 10s 398us/step - loss: 12.8058 - accuracy: 0.1320 - val_loss: 2.5375 - val_accuracy: 0.1517\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 10s 390us/step - loss: 11.8863 - accuracy: 0.2059 - val_loss: 2.4148 - val_accuracy: 0.2043\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 10s 389us/step - loss: 10.9680 - accuracy: 0.2118 - val_loss: 2.3306 - val_accuracy: 0.2293\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 10s 387us/step - loss: 10.6984 - accuracy: 0.2158 - val_loss: 2.2871 - val_accuracy: 0.2470\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 10s 386us/step - loss: 10.4150 - accuracy: 0.2262 - val_loss: 2.2277 - val_accuracy: 0.2310\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 10s 409us/step - loss: 10.1800 - accuracy: 0.2235 - val_loss: 2.1760 - val_accuracy: 0.2547\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 10s 409us/step - loss: 9.9186 - accuracy: 0.2492 - val_loss: 2.3822 - val_accuracy: 0.0973\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 9s 358us/step - loss: 9.8556 - accuracy: 0.2227 - val_loss: 2.2998 - val_accuracy: 0.2027\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 8s 343us/step - loss: 9.6585 - accuracy: 0.2149 - val_loss: 2.1215 - val_accuracy: 0.2610\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 8s 344us/step - loss: 9.9229 - accuracy: 0.2337 - val_loss: 2.2937 - val_accuracy: 0.2400\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 9s 379us/step - loss: 9.7607 - accuracy: 0.2461 - val_loss: 2.1605 - val_accuracy: 0.2247\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 10s 414us/step - loss: 10.1814 - accuracy: 0.2309 - val_loss: 2.1827 - val_accuracy: 0.2603\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 14s 552us/step - loss: 9.3081 - accuracy: 0.2467 - val_loss: 2.1576 - val_accuracy: 0.2577\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 10s 408us/step - loss: 9.1167 - accuracy: 0.2604 - val_loss: 2.2113 - val_accuracy: 0.1990\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 10s 398us/step - loss: 8.9912 - accuracy: 0.2445 - val_loss: 2.1083 - val_accuracy: 0.2637\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 10s 408us/step - loss: 8.7298 - accuracy: 0.2653 - val_loss: 2.0986 - val_accuracy: 0.2593\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 10s 403us/step - loss: 8.7851 - accuracy: 0.2706 - val_loss: 2.1286 - val_accuracy: 0.2557\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 10s 405us/step - loss: 8.8798 - accuracy: 0.2300 - val_loss: 2.2335 - val_accuracy: 0.2217\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 10s 395us/step - loss: 8.7608 - accuracy: 0.2645 - val_loss: 2.0374 - val_accuracy: 0.2697\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 10s 389us/step - loss: 8.6659 - accuracy: 0.2692 - val_loss: 1.9961 - val_accuracy: 0.2867\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 10s 395us/step - loss: 8.7499 - accuracy: 0.2779 - val_loss: 2.1468 - val_accuracy: 0.2403\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 10s 389us/step - loss: 8.2825 - accuracy: 0.2804 - val_loss: 1.9928 - val_accuracy: 0.2870\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 10s 390us/step - loss: 8.2007 - accuracy: 0.2879 - val_loss: 2.0001 - val_accuracy: 0.2853\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 10s 392us/step - loss: 8.0736 - accuracy: 0.2847 - val_loss: 1.9890 - val_accuracy: 0.2863\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 9s 379us/step - loss: 9.9903 - accuracy: 0.2837 - val_loss: 3.4316 - val_accuracy: 0.1083\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 9s 377us/step - loss: 11.8374 - accuracy: 0.2296 - val_loss: 2.1803 - val_accuracy: 0.2507\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 9s 370us/step - loss: 9.1871 - accuracy: 0.2668 - val_loss: 2.2064 - val_accuracy: 0.2420\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 9s 372us/step - loss: 8.6785 - accuracy: 0.2757 - val_loss: 2.0997 - val_accuracy: 0.2623\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 9s 371us/step - loss: 8.3658 - accuracy: 0.2839 - val_loss: 2.0455 - val_accuracy: 0.2657\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 9s 373us/step - loss: 8.1161 - accuracy: 0.2884 - val_loss: 2.0060 - val_accuracy: 0.2730\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 9s 374us/step - loss: 17.9435 - accuracy: 0.2334 - val_loss: 2.6581 - val_accuracy: 0.1463\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 9s 373us/step - loss: 9.9961 - accuracy: 0.2445 - val_loss: 2.3125 - val_accuracy: 0.2147\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 10s 421us/step - loss: 8.8288 - accuracy: 0.2639 - val_loss: 2.1226 - val_accuracy: 0.2523\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 12s 470us/step - loss: 8.3781 - accuracy: 0.2825 - val_loss: 2.0664 - val_accuracy: 0.2580\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 10s 398us/step - loss: 8.1465 - accuracy: 0.2866 - val_loss: 2.0117 - val_accuracy: 0.2753\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 9s 378us/step - loss: 8.0479 - accuracy: 0.2910 - val_loss: 2.0317 - val_accuracy: 0.2657\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 9s 378us/step - loss: 7.9514 - accuracy: 0.2901 - val_loss: 2.0371 - val_accuracy: 0.2667\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 9s 379us/step - loss: 7.8181 - accuracy: 0.2978 - val_loss: 1.9618 - val_accuracy: 0.2910\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 9s 380us/step - loss: 7.7500 - accuracy: 0.3044 - val_loss: 1.9614 - val_accuracy: 0.2817\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 9s 382us/step - loss: 7.6649 - accuracy: 0.3061 - val_loss: 1.9202 - val_accuracy: 0.2960\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    history6 = model6.fit(X_train_n, Y_train_n, epochs=10, batch_size=256, validation_data = (X_dev_n, Y_dev_n), class_weight=class_weight)\n",
    "    history6_all.append(history6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 9s 383us/step - loss: 7.5998 - accuracy: 0.3078 - val_loss: 1.9273 - val_accuracy: 0.2883\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 9s 374us/step - loss: 7.5479 - accuracy: 0.3074 - val_loss: 1.9264 - val_accuracy: 0.2947\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 9s 373us/step - loss: 7.4589 - accuracy: 0.3144 - val_loss: 1.9351 - val_accuracy: 0.2867\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 9s 369us/step - loss: 7.3950 - accuracy: 0.3166 - val_loss: 1.9179 - val_accuracy: 0.3080\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 12s 484us/step - loss: 7.3355 - accuracy: 0.3179 - val_loss: 1.8677 - val_accuracy: 0.3160\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 9s 385us/step - loss: 7.2688 - accuracy: 0.3254 - val_loss: 1.8995 - val_accuracy: 0.3057\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 9s 374us/step - loss: 7.2120 - accuracy: 0.3225 - val_loss: 1.8675 - val_accuracy: 0.3210\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 9s 374us/step - loss: 7.1710 - accuracy: 0.3246 - val_loss: 1.9227 - val_accuracy: 0.3013\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 9s 374us/step - loss: 7.1600 - accuracy: 0.3285 - val_loss: 1.8977 - val_accuracy: 0.3127\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 9s 374us/step - loss: 7.0495 - accuracy: 0.3290 - val_loss: 1.8595 - val_accuracy: 0.3197\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 9s 372us/step - loss: 6.9860 - accuracy: 0.3299 - val_loss: 1.8262 - val_accuracy: 0.3317\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 9s 374us/step - loss: 6.9555 - accuracy: 0.3302 - val_loss: 1.9113 - val_accuracy: 0.3043\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 9s 373us/step - loss: 7.2478 - accuracy: 0.3235 - val_loss: 1.9461 - val_accuracy: 0.3027\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 9s 374us/step - loss: 7.8464 - accuracy: 0.3240 - val_loss: 1.8734 - val_accuracy: 0.3277\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 9s 375us/step - loss: 7.5851 - accuracy: 0.3069 - val_loss: 1.9313 - val_accuracy: 0.3000\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 9s 369us/step - loss: 7.5642 - accuracy: 0.3192 - val_loss: 1.9655 - val_accuracy: 0.3037\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 9s 374us/step - loss: 7.1118 - accuracy: 0.3226 - val_loss: 1.9970 - val_accuracy: 0.3043\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 9s 373us/step - loss: 6.8860 - accuracy: 0.3284 - val_loss: 1.8801 - val_accuracy: 0.3187\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 9s 374us/step - loss: 6.7920 - accuracy: 0.3365 - val_loss: 1.8403 - val_accuracy: 0.3210\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 9s 373us/step - loss: 6.6672 - accuracy: 0.3414 - val_loss: 1.8228 - val_accuracy: 0.3140\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 9s 374us/step - loss: 6.6326 - accuracy: 0.3358 - val_loss: 1.8239 - val_accuracy: 0.3247\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 9s 375us/step - loss: 6.5512 - accuracy: 0.3442 - val_loss: 1.8517 - val_accuracy: 0.3210\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 9s 377us/step - loss: 6.4874 - accuracy: 0.3439 - val_loss: 1.7863 - val_accuracy: 0.3403\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 9s 374us/step - loss: 6.4311 - accuracy: 0.3451 - val_loss: 1.7814 - val_accuracy: 0.3440\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 11s 444us/step - loss: 6.3920 - accuracy: 0.3449 - val_loss: 1.7814 - val_accuracy: 0.3370\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 13s 521us/step - loss: 6.3097 - accuracy: 0.3494 - val_loss: 1.8155 - val_accuracy: 0.3403\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 13s 521us/step - loss: 6.2627 - accuracy: 0.3507 - val_loss: 1.8371 - val_accuracy: 0.3200\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 13s 542us/step - loss: 6.2229 - accuracy: 0.3483 - val_loss: 1.7841 - val_accuracy: 0.3307\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 13s 529us/step - loss: 6.1784 - accuracy: 0.3515 - val_loss: 1.7123 - val_accuracy: 0.3560\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 12s 493us/step - loss: 6.1201 - accuracy: 0.3573 - val_loss: 1.8244 - val_accuracy: 0.3263\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 13s 522us/step - loss: 6.0908 - accuracy: 0.3521 - val_loss: 1.7789 - val_accuracy: 0.3447\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 14s 553us/step - loss: 6.0116 - accuracy: 0.3529 - val_loss: 1.8028 - val_accuracy: 0.3343\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 13s 531us/step - loss: 6.0069 - accuracy: 0.3567 - val_loss: 1.7637 - val_accuracy: 0.3477\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 10s 401us/step - loss: 5.9198 - accuracy: 0.3556 - val_loss: 1.7469 - val_accuracy: 0.3557\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 15s 595us/step - loss: 5.8692 - accuracy: 0.3605 - val_loss: 1.7871 - val_accuracy: 0.3397\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 13s 542us/step - loss: 5.8122 - accuracy: 0.3611 - val_loss: 1.7346 - val_accuracy: 0.3530\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 13s 532us/step - loss: 5.7639 - accuracy: 0.3642 - val_loss: 1.8505 - val_accuracy: 0.3190\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 13s 533us/step - loss: 5.7249 - accuracy: 0.3635 - val_loss: 1.7704 - val_accuracy: 0.3380\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 13s 522us/step - loss: 5.6817 - accuracy: 0.3640 - val_loss: 1.8367 - val_accuracy: 0.3203\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 13s 535us/step - loss: 5.8197 - accuracy: 0.3609 - val_loss: 1.7193 - val_accuracy: 0.3440\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 13s 520us/step - loss: 12.9453 - accuracy: 0.3072 - val_loss: 2.2256 - val_accuracy: 0.2907\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 13s 517us/step - loss: 9.5205 - accuracy: 0.2759 - val_loss: 2.2850 - val_accuracy: 0.2350\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 13s 544us/step - loss: 14.4615 - accuracy: 0.2265 - val_loss: 3.1391 - val_accuracy: 0.1823\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 10s 415us/step - loss: 8.7441 - accuracy: 0.2716 - val_loss: 2.0675 - val_accuracy: 0.2757\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 10s 407us/step - loss: 7.5467 - accuracy: 0.3077 - val_loss: 1.9209 - val_accuracy: 0.2957\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 10s 421us/step - loss: 7.5999 - accuracy: 0.3011 - val_loss: 2.0176 - val_accuracy: 0.2930\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 10s 393us/step - loss: 7.1921 - accuracy: 0.3175 - val_loss: 1.9931 - val_accuracy: 0.2897\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 11s 448us/step - loss: 6.9826 - accuracy: 0.3222 - val_loss: 1.9661 - val_accuracy: 0.2950\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 10s 400us/step - loss: 6.8554 - accuracy: 0.3294 - val_loss: 1.9491 - val_accuracy: 0.3043\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 9s 375us/step - loss: 6.6939 - accuracy: 0.3297 - val_loss: 1.9087 - val_accuracy: 0.3057\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    history6 = model6.fit(X_train_n, Y_train_n, epochs=10, batch_size=256, validation_data = (X_dev_n, Y_dev_n), class_weight=class_weight)\n",
    "    history6_all.append(history6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 7: LSTM, Relu, adam, add masking layer, using normalized input, log weighted input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_6 (Masking)          (None, 30, 10)            0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                1616      \n",
      "=================================================================\n",
      "Total params: 46,016\n",
      "Trainable params: 46,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(Masking(mask_value=0., input_shape=(30, 10)))\n",
    "model7.add(LSTM(100, activation='relu', input_shape=(30, 10)))\n",
    "model7.add(Dense(16, activation='softmax'))\n",
    "model7.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model7.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "history7_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 9s 384us/step - loss: 4.0775 - accuracy: 0.3171 - val_loss: 1.7880 - val_accuracy: 0.3480\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 9s 369us/step - loss: 3.6814 - accuracy: 0.3610 - val_loss: 1.7394 - val_accuracy: 0.3523\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 11s 443us/step - loss: 3.5688 - accuracy: 0.3658 - val_loss: 1.6714 - val_accuracy: 0.3663\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 10s 406us/step - loss: 3.4714 - accuracy: 0.3728 - val_loss: 1.6862 - val_accuracy: 0.3610\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 10s 401us/step - loss: 3.4052 - accuracy: 0.3770 - val_loss: 1.6223 - val_accuracy: 0.3857\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 9s 386us/step - loss: 3.3478 - accuracy: 0.3813 - val_loss: 1.5702 - val_accuracy: 0.3943\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 10s 390us/step - loss: 3.3167 - accuracy: 0.3886 - val_loss: 1.5759 - val_accuracy: 0.3897\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 11s 428us/step - loss: 3.2852 - accuracy: 0.3937 - val_loss: 1.5850 - val_accuracy: 0.3737\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 11s 456us/step - loss: 3.2642 - accuracy: 0.3940 - val_loss: 1.6220 - val_accuracy: 0.3737\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 11s 440us/step - loss: 3.2455 - accuracy: 0.3936 - val_loss: 1.5990 - val_accuracy: 0.3757\n"
     ]
    }
   ],
   "source": [
    "history7 = model7.fit(X_train_n, Y_train_n, epochs=10, batch_size=256, validation_data = (X_dev_n, Y_dev_n), class_weight=class_weight_log)\n",
    "history7_all.append(history7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 10s 411us/step - loss: 3.2305 - accuracy: 0.3934 - val_loss: 1.5588 - val_accuracy: 0.3887\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 10s 397us/step - loss: 3.2110 - accuracy: 0.3977 - val_loss: 1.6257 - val_accuracy: 0.3760\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 10s 387us/step - loss: 3.2040 - accuracy: 0.3998 - val_loss: 1.5808 - val_accuracy: 0.3860\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 10s 387us/step - loss: 3.1806 - accuracy: 0.4055 - val_loss: 1.5535 - val_accuracy: 0.3973\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 10s 392us/step - loss: 3.1742 - accuracy: 0.4075 - val_loss: 1.5713 - val_accuracy: 0.3853\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 10s 392us/step - loss: 3.1559 - accuracy: 0.4060 - val_loss: 1.5764 - val_accuracy: 0.3953\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 10s 400us/step - loss: 3.1434 - accuracy: 0.4079 - val_loss: 1.5380 - val_accuracy: 0.3913\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 10s 402us/step - loss: 3.1308 - accuracy: 0.4072 - val_loss: 1.5567 - val_accuracy: 0.3957\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 10s 393us/step - loss: 3.1120 - accuracy: 0.4112 - val_loss: 1.5153 - val_accuracy: 0.4107\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 10s 395us/step - loss: 3.1109 - accuracy: 0.4071 - val_loss: 1.5466 - val_accuracy: 0.3980\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 10s 421us/step - loss: 3.1046 - accuracy: 0.4091 - val_loss: 1.5349 - val_accuracy: 0.4003\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 11s 453us/step - loss: 3.0826 - accuracy: 0.4163 - val_loss: 1.5630 - val_accuracy: 0.3910\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 13s 516us/step - loss: 3.0726 - accuracy: 0.4145 - val_loss: 1.5034 - val_accuracy: 0.4047\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 12s 489us/step - loss: 3.0722 - accuracy: 0.4145 - val_loss: 1.5155 - val_accuracy: 0.4053\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 12s 497us/step - loss: 3.0553 - accuracy: 0.4168 - val_loss: 1.5116 - val_accuracy: 0.4080\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 12s 492us/step - loss: 3.0374 - accuracy: 0.4156 - val_loss: 1.5242 - val_accuracy: 0.3967\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 12s 467us/step - loss: 3.0285 - accuracy: 0.4213 - val_loss: 1.5695 - val_accuracy: 0.3777\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 11s 452us/step - loss: 3.0173 - accuracy: 0.4239 - val_loss: 1.5708 - val_accuracy: 0.3707\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 9s 375us/step - loss: 3.0114 - accuracy: 0.4213 - val_loss: 1.5313 - val_accuracy: 0.4043\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 9s 371us/step - loss: 2.9888 - accuracy: 0.4260 - val_loss: 1.5241 - val_accuracy: 0.4007\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 9s 375us/step - loss: 2.9927 - accuracy: 0.4213 - val_loss: 1.5391 - val_accuracy: 0.3850\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 12s 500us/step - loss: 2.9679 - accuracy: 0.4307 - val_loss: 1.5235 - val_accuracy: 0.4100\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 13s 526us/step - loss: 2.9589 - accuracy: 0.4281 - val_loss: 1.5237 - val_accuracy: 0.4053\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 13s 521us/step - loss: 2.9537 - accuracy: 0.4294 - val_loss: 1.5966 - val_accuracy: 0.3770\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 13s 519us/step - loss: 2.9415 - accuracy: 0.4303 - val_loss: 1.5408 - val_accuracy: 0.3963\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 13s 522us/step - loss: 2.9297 - accuracy: 0.4313 - val_loss: 1.5565 - val_accuracy: 0.3867\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 13s 520us/step - loss: 2.9141 - accuracy: 0.4298 - val_loss: 1.5427 - val_accuracy: 0.3960\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 13s 547us/step - loss: 2.9104 - accuracy: 0.4338 - val_loss: 1.5638 - val_accuracy: 0.3730\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 13s 541us/step - loss: 2.8919 - accuracy: 0.4353 - val_loss: 1.5605 - val_accuracy: 0.3960\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 13s 526us/step - loss: 2.8734 - accuracy: 0.4394 - val_loss: 1.5457 - val_accuracy: 0.4010\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 11s 445us/step - loss: 2.8687 - accuracy: 0.4402 - val_loss: 1.5451 - val_accuracy: 0.4017\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 11s 433us/step - loss: 2.8491 - accuracy: 0.4451 - val_loss: 1.5705 - val_accuracy: 0.3990\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 10s 405us/step - loss: 2.8335 - accuracy: 0.4450 - val_loss: 1.5493 - val_accuracy: 0.4070\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 9s 385us/step - loss: 2.8241 - accuracy: 0.4467 - val_loss: 1.6051 - val_accuracy: 0.3773\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 10s 387us/step - loss: 2.8179 - accuracy: 0.4468 - val_loss: 1.5920 - val_accuracy: 0.3670\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 10s 387us/step - loss: 2.7916 - accuracy: 0.4522 - val_loss: 1.5937 - val_accuracy: 0.3603\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 10s 388us/step - loss: 2.7795 - accuracy: 0.4546 - val_loss: 1.5929 - val_accuracy: 0.3897\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 10s 398us/step - loss: 2.7647 - accuracy: 0.4555 - val_loss: 1.5918 - val_accuracy: 0.3910\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 10s 390us/step - loss: 2.7818 - accuracy: 0.4541 - val_loss: 1.6389 - val_accuracy: 0.3593\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 10s 400us/step - loss: 2.7484 - accuracy: 0.4578 - val_loss: 1.5966 - val_accuracy: 0.3847\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 9s 376us/step - loss: 2.7202 - accuracy: 0.4598 - val_loss: 1.5973 - val_accuracy: 0.3860\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 9s 383us/step - loss: 2.7229 - accuracy: 0.4621 - val_loss: 1.5902 - val_accuracy: 0.3810\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 11s 454us/step - loss: 2.7017 - accuracy: 0.4674 - val_loss: 1.6141 - val_accuracy: 0.3823\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 11s 433us/step - loss: 2.6819 - accuracy: 0.4692 - val_loss: 1.5989 - val_accuracy: 0.3913\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 11s 433us/step - loss: 2.6731 - accuracy: 0.4713 - val_loss: 1.6217 - val_accuracy: 0.3923\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 11s 430us/step - loss: 2.6512 - accuracy: 0.4741 - val_loss: 1.6053 - val_accuracy: 0.3900\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 11s 434us/step - loss: 2.6399 - accuracy: 0.4755 - val_loss: 1.6561 - val_accuracy: 0.3650\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 10s 403us/step - loss: 2.6279 - accuracy: 0.4781 - val_loss: 1.6277 - val_accuracy: 0.3830\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 10s 386us/step - loss: 2.6132 - accuracy: 0.4826 - val_loss: 1.6194 - val_accuracy: 0.3887\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 10s 387us/step - loss: 2.6008 - accuracy: 0.4836 - val_loss: 1.6184 - val_accuracy: 0.4027\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    history7 = model7.fit(X_train_n, Y_train_n, epochs=10, batch_size=256, validation_data = (X_dev_n, Y_dev_n), class_weight=class_weight_log)\n",
    "    history7_all.append(history7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 8: BRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_9 (Masking)          (None, 30, 10)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 200)               88800     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                3216      \n",
      "=================================================================\n",
      "Total params: 92,016\n",
      "Trainable params: 92,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model8 = Sequential()\n",
    "model8.add(Masking(mask_value=0., input_shape=(30, 10)))\n",
    "model8.add(Bidirectional(LSTM(100, activation='relu'), input_shape=(30, 10)))\n",
    "model8.add(Dense(16, activation='softmax'))\n",
    "model8.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model8.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "history8_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 15s 621us/step - loss: 3.9674 - accuracy: 0.3392 - val_loss: 1.7704 - val_accuracy: 0.3467\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 15s 609us/step - loss: 3.6358 - accuracy: 0.3582 - val_loss: 1.7125 - val_accuracy: 0.3517\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 15s 617us/step - loss: 3.5001 - accuracy: 0.3693 - val_loss: 1.6225 - val_accuracy: 0.3670\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 15s 611us/step - loss: 3.4102 - accuracy: 0.3794 - val_loss: 1.5838 - val_accuracy: 0.3920\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 15s 612us/step - loss: 3.3388 - accuracy: 0.3840 - val_loss: 1.5761 - val_accuracy: 0.3910\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 15s 608us/step - loss: 3.2960 - accuracy: 0.3885 - val_loss: 1.5834 - val_accuracy: 0.3883\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 16s 653us/step - loss: 3.2632 - accuracy: 0.3883 - val_loss: 1.5345 - val_accuracy: 0.4037\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 15s 616us/step - loss: 3.2242 - accuracy: 0.3943 - val_loss: 1.5720 - val_accuracy: 0.3913\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 24s 978us/step - loss: 3.1998 - accuracy: 0.3979 - val_loss: 1.5648 - val_accuracy: 0.3843\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 19s 765us/step - loss: 3.1778 - accuracy: 0.3991 - val_loss: 1.5760 - val_accuracy: 0.3810\n"
     ]
    }
   ],
   "source": [
    "history8 = model8.fit(X_train_n, Y_train_n, epochs=10, batch_size=256, validation_data = (X_dev_n, Y_dev_n), class_weight=class_weight_log)\n",
    "history8_all.append(history8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 16s 641us/step - loss: 3.1558 - accuracy: 0.3999 - val_loss: 1.5291 - val_accuracy: 0.3977\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 16s 642us/step - loss: 3.1490 - accuracy: 0.4062 - val_loss: 1.5197 - val_accuracy: 0.3950\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 16s 640us/step - loss: 3.1156 - accuracy: 0.4061 - val_loss: 1.5369 - val_accuracy: 0.3920\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 16s 640us/step - loss: 3.1052 - accuracy: 0.4090 - val_loss: 1.5532 - val_accuracy: 0.3867\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 16s 644us/step - loss: 3.0932 - accuracy: 0.4098 - val_loss: 1.5313 - val_accuracy: 0.3957\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 16s 630us/step - loss: 3.0885 - accuracy: 0.4059 - val_loss: 1.4998 - val_accuracy: 0.4017\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 15s 616us/step - loss: 3.0595 - accuracy: 0.4121 - val_loss: 1.5162 - val_accuracy: 0.3923\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 15s 626us/step - loss: 3.0491 - accuracy: 0.4142 - val_loss: 1.5581 - val_accuracy: 0.3883\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 16s 635us/step - loss: 3.0289 - accuracy: 0.4165 - val_loss: 1.5530 - val_accuracy: 0.3833\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 16s 633us/step - loss: 3.0138 - accuracy: 0.4171 - val_loss: 1.5229 - val_accuracy: 0.3913\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 15s 620us/step - loss: 2.9900 - accuracy: 0.4212 - val_loss: 1.5585 - val_accuracy: 0.3910\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 15s 625us/step - loss: 2.9731 - accuracy: 0.4247 - val_loss: 1.5275 - val_accuracy: 0.3890\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 16s 635us/step - loss: 2.9664 - accuracy: 0.4264 - val_loss: 1.5168 - val_accuracy: 0.3917\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 16s 656us/step - loss: 2.9435 - accuracy: 0.4293 - val_loss: 1.6418 - val_accuracy: 0.3393\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 15s 606us/step - loss: 2.9404 - accuracy: 0.4305 - val_loss: 1.5335 - val_accuracy: 0.3953\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 15s 617us/step - loss: 2.9166 - accuracy: 0.4322 - val_loss: 1.5260 - val_accuracy: 0.3993\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 16s 657us/step - loss: 2.8998 - accuracy: 0.4366 - val_loss: 1.5658 - val_accuracy: 0.3707\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 14s 553us/step - loss: 2.8825 - accuracy: 0.4364 - val_loss: 1.5341 - val_accuracy: 0.4103\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 13s 546us/step - loss: 2.8647 - accuracy: 0.4391 - val_loss: 1.5415 - val_accuracy: 0.3900\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 14s 578us/step - loss: 2.8430 - accuracy: 0.4432 - val_loss: 1.5665 - val_accuracy: 0.3903\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 15s 601us/step - loss: 2.8381 - accuracy: 0.4427 - val_loss: 1.5787 - val_accuracy: 0.3740\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 16s 655us/step - loss: 2.8133 - accuracy: 0.4504 - val_loss: 1.6394 - val_accuracy: 0.3707\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 18s 713us/step - loss: 2.8704 - accuracy: 0.4423 - val_loss: 1.5355 - val_accuracy: 0.4003\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 21s 857us/step - loss: 2.8311 - accuracy: 0.4419 - val_loss: 1.5837 - val_accuracy: 0.3743\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 14s 561us/step - loss: 2.7740 - accuracy: 0.4539 - val_loss: 1.5757 - val_accuracy: 0.3827\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 14s 561us/step - loss: 2.7675 - accuracy: 0.4536 - val_loss: 1.6039 - val_accuracy: 0.3637\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 14s 556us/step - loss: 2.7402 - accuracy: 0.4613 - val_loss: 1.5989 - val_accuracy: 0.3753\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 14s 564us/step - loss: 2.7171 - accuracy: 0.4632 - val_loss: 1.5935 - val_accuracy: 0.3750\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 14s 555us/step - loss: 2.7040 - accuracy: 0.4662 - val_loss: 1.5810 - val_accuracy: 0.3807\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 14s 589us/step - loss: 2.6747 - accuracy: 0.4736 - val_loss: 1.6042 - val_accuracy: 0.3887\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 14s 570us/step - loss: 2.6740 - accuracy: 0.4722 - val_loss: 1.6696 - val_accuracy: 0.3497\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 14s 556us/step - loss: 2.6510 - accuracy: 0.4743 - val_loss: 1.6034 - val_accuracy: 0.3757\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 14s 583us/step - loss: 2.6301 - accuracy: 0.4756 - val_loss: 1.6055 - val_accuracy: 0.3943\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 18s 715us/step - loss: 2.6071 - accuracy: 0.4826 - val_loss: 1.6084 - val_accuracy: 0.3867\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 16s 660us/step - loss: 2.5933 - accuracy: 0.4857 - val_loss: 1.6641 - val_accuracy: 0.3703\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 22s 879us/step - loss: 2.5824 - accuracy: 0.4865 - val_loss: 1.6667 - val_accuracy: 0.3640\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 23s 934us/step - loss: 2.5432 - accuracy: 0.4894 - val_loss: 1.6671 - val_accuracy: 0.3683\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 20s 819us/step - loss: 2.7441 - accuracy: 0.4774 - val_loss: 1.7350 - val_accuracy: 0.3527\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 21s 865us/step - loss: 4.8384 - accuracy: 0.4234 - val_loss: 1.5924 - val_accuracy: 0.3810\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 16s 652us/step - loss: 2.9899 - accuracy: 0.4277 - val_loss: 1.5622 - val_accuracy: 0.3843\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 16s 631us/step - loss: 2.8454 - accuracy: 0.4446 - val_loss: 1.5710 - val_accuracy: 0.3793\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 15s 617us/step - loss: 2.7692 - accuracy: 0.4590 - val_loss: 1.5818 - val_accuracy: 0.3930\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 17s 675us/step - loss: 2.7121 - accuracy: 0.4661 - val_loss: 1.6211 - val_accuracy: 0.3707\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 15s 608us/step - loss: 2.6697 - accuracy: 0.4742 - val_loss: 1.6035 - val_accuracy: 0.3877\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 16s 664us/step - loss: 2.6271 - accuracy: 0.4797 - val_loss: 1.6168 - val_accuracy: 0.3833\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 17s 671us/step - loss: 2.5976 - accuracy: 0.4868 - val_loss: 1.6363 - val_accuracy: 0.3767\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 18s 726us/step - loss: 2.5615 - accuracy: 0.4927 - val_loss: 1.6463 - val_accuracy: 0.3843\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 20s 803us/step - loss: 2.5385 - accuracy: 0.4956 - val_loss: 1.6619 - val_accuracy: 0.3700\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 17s 703us/step - loss: 2.5073 - accuracy: 0.5018 - val_loss: 1.6767 - val_accuracy: 0.3747\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 19s 786us/step - loss: 2.4826 - accuracy: 0.5023 - val_loss: 1.6679 - val_accuracy: 0.3817\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    history8 = model8.fit(X_train_n, Y_train_n, epochs=10, batch_size=256, validation_data = (X_dev_n, Y_dev_n), class_weight=class_weight_log)\n",
    "    history8_all.append(history8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 9: Deep RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_13 (Masking)         (None, 30, 10)            0         \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                528       \n",
      "=================================================================\n",
      "Total params: 51,610\n",
      "Trainable params: 51,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model9 = Sequential()\n",
    "model9.add(Masking(mask_value=0., input_shape=(30, 10)))\n",
    "model9.add(LSTM(100, activation='relu', input_shape=(30, 10)))\n",
    "model9.add(Dense(50))\n",
    "model9.add(Dense(32))\n",
    "model9.add(Dense(16, activation='softmax'))\n",
    "model9.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model9.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "history9_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 10s 421us/step - loss: 4.0150 - accuracy: 0.3189 - val_loss: 1.7347 - val_accuracy: 0.3570\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 10s 386us/step - loss: 3.5680 - accuracy: 0.3648 - val_loss: 1.6705 - val_accuracy: 0.3630\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 9s 382us/step - loss: 3.4294 - accuracy: 0.3789 - val_loss: 1.5936 - val_accuracy: 0.3890\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 9s 382us/step - loss: 3.3583 - accuracy: 0.3859 - val_loss: 1.5857 - val_accuracy: 0.3867\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 9s 382us/step - loss: 3.3223 - accuracy: 0.3866 - val_loss: 1.5380 - val_accuracy: 0.4050\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 10s 424us/step - loss: 3.2766 - accuracy: 0.3928 - val_loss: 1.5729 - val_accuracy: 0.3833\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 10s 402us/step - loss: 3.2504 - accuracy: 0.3943 - val_loss: 1.5658 - val_accuracy: 0.3893\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 11s 432us/step - loss: 3.2301 - accuracy: 0.3979 - val_loss: 1.5679 - val_accuracy: 0.3843\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 13s 541us/step - loss: 3.2161 - accuracy: 0.3987 - val_loss: 1.6144 - val_accuracy: 0.3827\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 13s 510us/step - loss: 3.2087 - accuracy: 0.3982 - val_loss: 1.5394 - val_accuracy: 0.3713\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 11s 443us/step - loss: 3.1753 - accuracy: 0.4000 - val_loss: 1.5171 - val_accuracy: 0.4057\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 10s 400us/step - loss: 3.1619 - accuracy: 0.4048 - val_loss: 1.6354 - val_accuracy: 0.3763\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 10s 389us/step - loss: 3.1616 - accuracy: 0.4012 - val_loss: 1.5051 - val_accuracy: 0.4117\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 12s 472us/step - loss: 3.1445 - accuracy: 0.4056 - val_loss: 1.5160 - val_accuracy: 0.4147\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 10s 406us/step - loss: 3.1429 - accuracy: 0.4035 - val_loss: 1.5567 - val_accuracy: 0.3930\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 11s 465us/step - loss: 3.1332 - accuracy: 0.4044 - val_loss: 1.5288 - val_accuracy: 0.4067\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 10s 389us/step - loss: 3.1085 - accuracy: 0.4071 - val_loss: 1.5151 - val_accuracy: 0.3997\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 10s 389us/step - loss: 3.1049 - accuracy: 0.4079 - val_loss: 1.5338 - val_accuracy: 0.3987\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 13s 517us/step - loss: 3.0919 - accuracy: 0.4085 - val_loss: 1.5348 - val_accuracy: 0.4053\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 12s 484us/step - loss: 3.0826 - accuracy: 0.4055 - val_loss: 1.5204 - val_accuracy: 0.4043\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 11s 428us/step - loss: 3.0682 - accuracy: 0.4119 - val_loss: 1.5283 - val_accuracy: 0.4113\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 16s 649us/step - loss: 3.0567 - accuracy: 0.4117 - val_loss: 1.5101 - val_accuracy: 0.4113\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 13s 511us/step - loss: 3.0609 - accuracy: 0.4093 - val_loss: 1.6103 - val_accuracy: 0.3663\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 11s 430us/step - loss: 3.0410 - accuracy: 0.4143 - val_loss: 1.5157 - val_accuracy: 0.4107\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 13s 529us/step - loss: 3.0363 - accuracy: 0.4111 - val_loss: 1.5686 - val_accuracy: 0.3830\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 10s 391us/step - loss: 3.0267 - accuracy: 0.4102 - val_loss: 1.5777 - val_accuracy: 0.3847\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 9s 361us/step - loss: 3.0079 - accuracy: 0.4132 - val_loss: 1.5292 - val_accuracy: 0.4000\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 9s 355us/step - loss: 3.0115 - accuracy: 0.4148 - val_loss: 1.5843 - val_accuracy: 0.3837\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 9s 358us/step - loss: 3.0030 - accuracy: 0.4157 - val_loss: 1.5641 - val_accuracy: 0.3857\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 10s 401us/step - loss: 2.9837 - accuracy: 0.4176 - val_loss: 1.5181 - val_accuracy: 0.4057\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 9s 360us/step - loss: 2.9847 - accuracy: 0.4176 - val_loss: 1.5077 - val_accuracy: 0.4060\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 10s 425us/step - loss: 2.9644 - accuracy: 0.4187 - val_loss: 1.5297 - val_accuracy: 0.4073\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 11s 456us/step - loss: 2.9600 - accuracy: 0.4200 - val_loss: 1.5812 - val_accuracy: 0.3870\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 10s 393us/step - loss: 2.9484 - accuracy: 0.4218 - val_loss: 1.5698 - val_accuracy: 0.3773\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 10s 389us/step - loss: 2.9425 - accuracy: 0.4215 - val_loss: 1.6230 - val_accuracy: 0.3723\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 9s 383us/step - loss: 2.9381 - accuracy: 0.4170 - val_loss: 1.5775 - val_accuracy: 0.3783\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 10s 421us/step - loss: 2.9383 - accuracy: 0.4199 - val_loss: 1.5008 - val_accuracy: 0.4190\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 10s 405us/step - loss: 2.9148 - accuracy: 0.4249 - val_loss: 1.5301 - val_accuracy: 0.3943\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 10s 386us/step - loss: 2.8989 - accuracy: 0.4221 - val_loss: 1.5316 - val_accuracy: 0.3857\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 10s 391us/step - loss: 2.8957 - accuracy: 0.4257 - val_loss: 1.5485 - val_accuracy: 0.3767\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 14s 559us/step - loss: 2.8863 - accuracy: 0.4257 - val_loss: 1.6035 - val_accuracy: 0.3693\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 14s 554us/step - loss: 2.8733 - accuracy: 0.4292 - val_loss: 1.5931 - val_accuracy: 0.3630\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 11s 449us/step - loss: 2.8614 - accuracy: 0.4297 - val_loss: 1.5571 - val_accuracy: 0.3877\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 14s 569us/step - loss: 2.8673 - accuracy: 0.4250 - val_loss: 1.5365 - val_accuracy: 0.3997\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 10s 394us/step - loss: 2.8325 - accuracy: 0.4279 - val_loss: 1.6020 - val_accuracy: 0.3700\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 10s 386us/step - loss: 2.8323 - accuracy: 0.4322 - val_loss: 1.5479 - val_accuracy: 0.3973\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 13s 522us/step - loss: 2.8357 - accuracy: 0.4302 - val_loss: 1.5485 - val_accuracy: 0.3913\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 10s 425us/step - loss: 2.8064 - accuracy: 0.4358 - val_loss: 1.6212 - val_accuracy: 0.3683\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 10s 421us/step - loss: 2.7949 - accuracy: 0.4369 - val_loss: 1.6186 - val_accuracy: 0.3793\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 10s 412us/step - loss: 2.8103 - accuracy: 0.4344 - val_loss: 1.6132 - val_accuracy: 0.3643\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    history9 = model9.fit(X_train_n, Y_train_n, epochs=10, batch_size=256, validation_data = (X_dev_n, Y_dev_n), class_weight=class_weight_log)\n",
    "    history9_all.append(history9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 10: Deep RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_13 (Masking)         (None, 30, 10)            0         \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                528       \n",
      "=================================================================\n",
      "Total params: 51,610\n",
      "Trainable params: 51,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model10 = Sequential()\n",
    "model10.add(Masking(mask_value=0., input_shape=(30, 10)))\n",
    "model10.add(LSTM(100, activation='relu', input_shape=(30, 10)))\n",
    "model10.add(Dense(100))\n",
    "model10.add(Dense(100))\n",
    "model10.add(Dense(50))\n",
    "model10.add(Dense(16, activation='softmax'))\n",
    "model10.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_14 (Masking)         (None, 30, 10)            0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 16)                816       \n",
      "=================================================================\n",
      "Total params: 70,466\n",
      "Trainable params: 70,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model10.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "history10_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 20s 806us/step - loss: 3.0823 - accuracy: 0.4019 - val_loss: 1.5195 - val_accuracy: 0.4067\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 19s 778us/step - loss: 2.9631 - accuracy: 0.4145 - val_loss: 1.5513 - val_accuracy: 0.3760\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 20s 807us/step - loss: 2.9296 - accuracy: 0.4158 - val_loss: 1.5342 - val_accuracy: 0.3970\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 19s 790us/step - loss: 2.9092 - accuracy: 0.4206 - val_loss: 1.5466 - val_accuracy: 0.3953\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 20s 812us/step - loss: 2.8921 - accuracy: 0.4223 - val_loss: 1.5716 - val_accuracy: 0.3810\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 19s 781us/step - loss: 2.8556 - accuracy: 0.4284 - val_loss: 1.5405 - val_accuracy: 0.3970\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 20s 800us/step - loss: 2.8280 - accuracy: 0.4308 - val_loss: 1.5913 - val_accuracy: 0.3723\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 20s 815us/step - loss: 2.8124 - accuracy: 0.4316 - val_loss: 1.5631 - val_accuracy: 0.3800\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 20s 795us/step - loss: 2.7971 - accuracy: 0.4325 - val_loss: 1.7472 - val_accuracy: 0.3293\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 19s 791us/step - loss: 2.7670 - accuracy: 0.4361 - val_loss: 1.6538 - val_accuracy: 0.3320\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 20s 810us/step - loss: 2.7423 - accuracy: 0.4375 - val_loss: 1.6357 - val_accuracy: 0.3627\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 20s 800us/step - loss: 2.7155 - accuracy: 0.4458 - val_loss: 1.6586 - val_accuracy: 0.3567\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 20s 801us/step - loss: 2.7085 - accuracy: 0.4456 - val_loss: 1.6208 - val_accuracy: 0.3790\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 20s 805us/step - loss: 2.6708 - accuracy: 0.4486 - val_loss: 1.5996 - val_accuracy: 0.3950\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 20s 822us/step - loss: 2.6336 - accuracy: 0.4530 - val_loss: 1.6393 - val_accuracy: 0.3840\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 22s 890us/step - loss: 2.6128 - accuracy: 0.4591 - val_loss: 1.6399 - val_accuracy: 0.3993\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 21s 857us/step - loss: 2.5978 - accuracy: 0.4621 - val_loss: 1.7374 - val_accuracy: 0.3643\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 20s 825us/step - loss: 2.5710 - accuracy: 0.4639 - val_loss: 1.6609 - val_accuracy: 0.4007\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 20s 810us/step - loss: 2.5352 - accuracy: 0.4692 - val_loss: 1.7187 - val_accuracy: 0.3673\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 20s 800us/step - loss: 2.5098 - accuracy: 0.4753 - val_loss: 1.7129 - val_accuracy: 0.3637\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 22s 883us/step - loss: 2.4966 - accuracy: 0.4780 - val_loss: 1.6866 - val_accuracy: 0.3857\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 24s 960us/step - loss: 2.4659 - accuracy: 0.4786 - val_loss: 1.7645 - val_accuracy: 0.3703\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 24s 962us/step - loss: 2.4177 - accuracy: 0.4864 - val_loss: 1.7645 - val_accuracy: 0.3890\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 20s 826us/step - loss: 2.4069 - accuracy: 0.4905 - val_loss: 1.7633 - val_accuracy: 0.3800\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 19s 770us/step - loss: 2.3851 - accuracy: 0.4956 - val_loss: 1.7984 - val_accuracy: 0.3553\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 20s 815us/step - loss: 2.3557 - accuracy: 0.4960 - val_loss: 1.8634 - val_accuracy: 0.3660\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 21s 861us/step - loss: 2.3207 - accuracy: 0.5077 - val_loss: 1.8529 - val_accuracy: 0.3713\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 21s 844us/step - loss: 2.3062 - accuracy: 0.5106 - val_loss: 1.9006 - val_accuracy: 0.3540\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 21s 833us/step - loss: 2.2558 - accuracy: 0.5153 - val_loss: 1.8792 - val_accuracy: 0.3617\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 20s 824us/step - loss: 2.2432 - accuracy: 0.5149 - val_loss: 1.9438 - val_accuracy: 0.3547\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 20s 824us/step - loss: 2.2219 - accuracy: 0.5255 - val_loss: 1.9588 - val_accuracy: 0.3597\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 21s 840us/step - loss: 2.1970 - accuracy: 0.5243 - val_loss: 1.9974 - val_accuracy: 0.3557\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 23s 950us/step - loss: 2.2007 - accuracy: 0.5251 - val_loss: 2.0116 - val_accuracy: 0.3620\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 25s 1ms/step - loss: 2.1628 - accuracy: 0.5336 - val_loss: 1.9829 - val_accuracy: 0.3753\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 22s 882us/step - loss: 2.1126 - accuracy: 0.5422 - val_loss: 2.0788 - val_accuracy: 0.3463\n",
      "Epoch 6/10\n",
      "22880/24634 [==========================>...] - ETA: 1s - loss: 2.0642 - accuracy: 0.5480"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-ae44907c9af7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mhistory10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_dev_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_dev_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mhistory10_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    history10 = model9.fit(X_train_n, Y_train_n, epochs=10, batch_size=32, validation_data = (X_dev_n, Y_dev_n), class_weight=class_weight_log)\n",
    "    history10_all.append(history10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 21s 844us/step - loss: 2.0470 - accuracy: 0.5524 - val_loss: 2.1450 - val_accuracy: 0.3723\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 20s 806us/step - loss: 2.0140 - accuracy: 0.5546 - val_loss: 2.1187 - val_accuracy: 0.3727\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 20s 829us/step - loss: 2.0005 - accuracy: 0.5583 - val_loss: 2.2037 - val_accuracy: 0.3417\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 20s 824us/step - loss: 1.9711 - accuracy: 0.5643 - val_loss: 2.2503 - val_accuracy: 0.3450\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 20s 815us/step - loss: 1.9466 - accuracy: 0.5682 - val_loss: 2.3056 - val_accuracy: 0.3507\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 21s 835us/step - loss: 1.9263 - accuracy: 0.5721 - val_loss: 2.3545 - val_accuracy: 0.3413\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 20s 824us/step - loss: 1.9111 - accuracy: 0.5736 - val_loss: 2.3203 - val_accuracy: 0.3513\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 22s 891us/step - loss: 1.8706 - accuracy: 0.5830 - val_loss: 2.3814 - val_accuracy: 0.3307\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 27s 1ms/step - loss: 1.8543 - accuracy: 0.5895 - val_loss: 2.3996 - val_accuracy: 0.3303\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 18s 749us/step - loss: 1.7981 - accuracy: 0.5983 - val_loss: 2.5193 - val_accuracy: 0.3453\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 19s 752us/step - loss: 1.7979 - accuracy: 0.5971 - val_loss: 2.4652 - val_accuracy: 0.3380\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 18s 748us/step - loss: 1.8051 - accuracy: 0.5975 - val_loss: 2.4067 - val_accuracy: 0.3673\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 20s 810us/step - loss: 1.7954 - accuracy: 0.5988 - val_loss: 2.5441 - val_accuracy: 0.3493\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 21s 865us/step - loss: 1.7493 - accuracy: 0.6068 - val_loss: 2.5911 - val_accuracy: 0.3717\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 19s 757us/step - loss: 1.7288 - accuracy: 0.6131 - val_loss: 2.6253 - val_accuracy: 0.3573\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 21s 846us/step - loss: 1.6904 - accuracy: 0.6175 - val_loss: 2.6456 - val_accuracy: 0.3573\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 19s 788us/step - loss: 1.6427 - accuracy: 0.6257 - val_loss: 2.7829 - val_accuracy: 0.3263\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 20s 816us/step - loss: 1.6304 - accuracy: 0.6293 - val_loss: 2.7542 - val_accuracy: 0.3393\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 19s 778us/step - loss: 1.6435 - accuracy: 0.6309 - val_loss: 2.7414 - val_accuracy: 0.3597\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 19s 785us/step - loss: 1.5823 - accuracy: 0.6373 - val_loss: 2.8702 - val_accuracy: 0.3623\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 20s 815us/step - loss: 1.6116 - accuracy: 0.6319 - val_loss: 2.9251 - val_accuracy: 0.3210\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 18s 744us/step - loss: 1.5670 - accuracy: 0.6430 - val_loss: 2.8788 - val_accuracy: 0.3657\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 19s 790us/step - loss: 1.5643 - accuracy: 0.6450 - val_loss: 3.0764 - val_accuracy: 0.3437\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 19s 788us/step - loss: 1.5240 - accuracy: 0.6501 - val_loss: 3.0662 - val_accuracy: 0.3397\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 20s 804us/step - loss: 1.5302 - accuracy: 0.6494 - val_loss: 3.0147 - val_accuracy: 0.3377\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 20s 812us/step - loss: 1.5494 - accuracy: 0.6515 - val_loss: 2.6907 - val_accuracy: 0.3563\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 20s 826us/step - loss: 1.4832 - accuracy: 0.6570 - val_loss: 3.0081 - val_accuracy: 0.3717\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 20s 819us/step - loss: 1.4762 - accuracy: 0.6637 - val_loss: 3.0586 - val_accuracy: 0.3503\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 20s 823us/step - loss: 1.5097 - accuracy: 0.6582 - val_loss: 3.1727 - val_accuracy: 0.3583\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 19s 768us/step - loss: 1.4311 - accuracy: 0.6722 - val_loss: 3.1841 - val_accuracy: 0.3547\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 19s 773us/step - loss: 1.4914 - accuracy: 0.6620 - val_loss: 3.2486 - val_accuracy: 0.3543\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 20s 795us/step - loss: 1.3729 - accuracy: 0.6821 - val_loss: 3.3327 - val_accuracy: 0.3387\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 20s 802us/step - loss: 1.3892 - accuracy: 0.6793 - val_loss: 3.3741 - val_accuracy: 0.3373\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 20s 823us/step - loss: 1.3415 - accuracy: 0.6877 - val_loss: 3.4995 - val_accuracy: 0.3323\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 20s 828us/step - loss: 1.3535 - accuracy: 0.6873 - val_loss: 3.4623 - val_accuracy: 0.3500\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 20s 801us/step - loss: 1.3227 - accuracy: 0.6923 - val_loss: 3.5758 - val_accuracy: 0.3473\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 20s 812us/step - loss: 1.3048 - accuracy: 0.6955 - val_loss: 3.4683 - val_accuracy: 0.3407\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 19s 786us/step - loss: 1.4759 - accuracy: 0.6675 - val_loss: 3.4768 - val_accuracy: 0.3250\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 20s 829us/step - loss: 1.3824 - accuracy: 0.6893 - val_loss: 3.2000 - val_accuracy: 0.3467\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 21s 833us/step - loss: 2.4133 - accuracy: 0.5768 - val_loss: 2.0908 - val_accuracy: 0.3343\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 21s 860us/step - loss: 2.6539 - accuracy: 0.4867 - val_loss: 1.9028 - val_accuracy: 0.3527\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 20s 801us/step - loss: 2.5137 - accuracy: 0.5050 - val_loss: 1.8598 - val_accuracy: 0.3463\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 19s 769us/step - loss: 2.4250 - accuracy: 0.5065 - val_loss: 1.9405 - val_accuracy: 0.3510\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 21s 835us/step - loss: 2.5185 - accuracy: 0.5013 - val_loss: 1.8778 - val_accuracy: 0.3443\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 23s 924us/step - loss: 3.1531 - accuracy: 0.4408 - val_loss: 2.3874 - val_accuracy: 0.2723\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 20s 804us/step - loss: 3.8563 - accuracy: 0.3537 - val_loss: 1.9399 - val_accuracy: 0.3430\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 20s 824us/step - loss: 3.5118 - accuracy: 0.3706 - val_loss: 1.7396 - val_accuracy: 0.3607\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 20s 802us/step - loss: 3.3323 - accuracy: 0.3770 - val_loss: 1.7588 - val_accuracy: 0.3413\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 20s 807us/step - loss: 3.2930 - accuracy: 0.3875 - val_loss: 1.7336 - val_accuracy: 0.3450\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 20s 811us/step - loss: 3.4786 - accuracy: 0.3723 - val_loss: 1.7558 - val_accuracy: 0.3527\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 20s 807us/step - loss: 3.9211 - accuracy: 0.3346 - val_loss: 1.9290 - val_accuracy: 0.2903\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 20s 811us/step - loss: 3.7700 - accuracy: 0.3363 - val_loss: 1.8055 - val_accuracy: 0.3397\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 19s 789us/step - loss: 3.6597 - accuracy: 0.3407 - val_loss: 1.8689 - val_accuracy: 0.3507\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 20s 823us/step - loss: 3.8186 - accuracy: 0.3330 - val_loss: 1.8177 - val_accuracy: 0.3347\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 20s 818us/step - loss: 3.6979 - accuracy: 0.3429 - val_loss: 1.8205 - val_accuracy: 0.3353\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 20s 815us/step - loss: 3.7065 - accuracy: 0.3341 - val_loss: 1.8566 - val_accuracy: 0.3230\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 20s 818us/step - loss: 3.6908 - accuracy: 0.3407 - val_loss: 1.8200 - val_accuracy: 0.3433\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 20s 802us/step - loss: 3.6889 - accuracy: 0.3369 - val_loss: 1.7906 - val_accuracy: 0.3197\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 19s 774us/step - loss: 3.6205 - accuracy: 0.3392 - val_loss: 1.7978 - val_accuracy: 0.3303\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 19s 779us/step - loss: 3.6705 - accuracy: 0.3364 - val_loss: 1.8111 - val_accuracy: 0.3170\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 20s 804us/step - loss: 3.6536 - accuracy: 0.3411 - val_loss: 1.8006 - val_accuracy: 0.3320\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 23s 914us/step - loss: 3.6048 - accuracy: 0.3429 - val_loss: 1.8586 - val_accuracy: 0.3250\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 24s 992us/step - loss: 3.7818 - accuracy: 0.3313 - val_loss: 1.8363 - val_accuracy: 0.3257\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 22s 899us/step - loss: 3.8198 - accuracy: 0.3267 - val_loss: 3.0231 - val_accuracy: 0.1900\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 21s 854us/step - loss: 5.0557 - accuracy: 0.2613 - val_loss: 2.0288 - val_accuracy: 0.3003\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 21s 858us/step - loss: 4.3337 - accuracy: 0.2801 - val_loss: 1.9043 - val_accuracy: 0.3183\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 21s 853us/step - loss: 4.3328 - accuracy: 0.2845 - val_loss: 2.0823 - val_accuracy: 0.2887\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 22s 883us/step - loss: 4.6507 - accuracy: 0.2642 - val_loss: 2.1070 - val_accuracy: 0.2683\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 21s 857us/step - loss: 4.4920 - accuracy: 0.2678 - val_loss: 2.3381 - val_accuracy: 0.2267\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 21s 856us/step - loss: 4.3314 - accuracy: 0.2758 - val_loss: 2.0411 - val_accuracy: 0.2703\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      " 9824/24634 [==========>...................] - ETA: 12s - loss: 4.2368 - accuracy: 0.2854"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-ae44907c9af7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mhistory10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_dev_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_dev_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mhistory10_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    history10 = model9.fit(X_train_n, Y_train_n, epochs=10, batch_size=32, validation_data = (X_dev_n, Y_dev_n), class_weight=class_weight_log)\n",
    "    history10_all.append(history10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 11: deep RNN, not using weighted sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_17 (Masking)         (None, 30, 10)            0         \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 16)                816       \n",
      "=================================================================\n",
      "Total params: 70,466\n",
      "Trainable params: 70,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model11 = Sequential()\n",
    "model11.add(Masking(mask_value=0., input_shape=(30, 10)))\n",
    "model11.add(LSTM(100, activation='relu', input_shape=(30, 10)))\n",
    "model11.add(Dense(100))\n",
    "model11.add(Dense(100))\n",
    "model11.add(Dense(50))\n",
    "model11.add(Dense(16, activation='softmax'))\n",
    "model11.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "print(model11.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "history11_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 22s 879us/step - loss: 1.6528 - sparse_categorical_accuracy: 0.3787 - val_loss: 1.5721 - val_sparse_categorical_accuracy: 0.3990\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 24s 994us/step - loss: 1.5526 - sparse_categorical_accuracy: 0.3997 - val_loss: 1.5372 - val_sparse_categorical_accuracy: 0.4033\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 22s 874us/step - loss: 1.5312 - sparse_categorical_accuracy: 0.4056 - val_loss: 1.5455 - val_sparse_categorical_accuracy: 0.4030\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 21s 868us/step - loss: 1.5175 - sparse_categorical_accuracy: 0.4103 - val_loss: 1.5048 - val_sparse_categorical_accuracy: 0.4130\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 21s 832us/step - loss: 1.5056 - sparse_categorical_accuracy: 0.4113 - val_loss: 1.5216 - val_sparse_categorical_accuracy: 0.4057\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 21s 867us/step - loss: 1.4923 - sparse_categorical_accuracy: 0.4126 - val_loss: 1.5057 - val_sparse_categorical_accuracy: 0.4213\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 28s 1ms/step - loss: 1.4860 - sparse_categorical_accuracy: 0.4130 - val_loss: 1.5257 - val_sparse_categorical_accuracy: 0.4163\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 26s 1ms/step - loss: 1.4757 - sparse_categorical_accuracy: 0.4177 - val_loss: 1.4933 - val_sparse_categorical_accuracy: 0.4157\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 22s 888us/step - loss: 1.4645 - sparse_categorical_accuracy: 0.4225 - val_loss: 1.5151 - val_sparse_categorical_accuracy: 0.4140\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 19s 766us/step - loss: 1.4564 - sparse_categorical_accuracy: 0.4224 - val_loss: 1.4902 - val_sparse_categorical_accuracy: 0.4127\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 19s 782us/step - loss: 1.4520 - sparse_categorical_accuracy: 0.4246 - val_loss: 1.4792 - val_sparse_categorical_accuracy: 0.4217\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 19s 787us/step - loss: 1.4407 - sparse_categorical_accuracy: 0.4290 - val_loss: 1.4876 - val_sparse_categorical_accuracy: 0.4177\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 20s 792us/step - loss: 1.4314 - sparse_categorical_accuracy: 0.4275 - val_loss: 1.4862 - val_sparse_categorical_accuracy: 0.4183\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 18s 745us/step - loss: 1.4224 - sparse_categorical_accuracy: 0.4307 - val_loss: 1.5310 - val_sparse_categorical_accuracy: 0.4127\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 20s 812us/step - loss: 1.4170 - sparse_categorical_accuracy: 0.4339 - val_loss: 1.5093 - val_sparse_categorical_accuracy: 0.4073\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 21s 843us/step - loss: 1.4081 - sparse_categorical_accuracy: 0.4336 - val_loss: 1.4772 - val_sparse_categorical_accuracy: 0.4260\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 21s 836us/step - loss: 1.3995 - sparse_categorical_accuracy: 0.4380 - val_loss: 1.4780 - val_sparse_categorical_accuracy: 0.4193\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 21s 861us/step - loss: 1.3906 - sparse_categorical_accuracy: 0.4394 - val_loss: 1.4897 - val_sparse_categorical_accuracy: 0.4230\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 22s 885us/step - loss: 1.3832 - sparse_categorical_accuracy: 0.4430 - val_loss: 1.5054 - val_sparse_categorical_accuracy: 0.4153\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 24s 967us/step - loss: 1.3737 - sparse_categorical_accuracy: 0.4443 - val_loss: 1.5011 - val_sparse_categorical_accuracy: 0.4233\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 22s 886us/step - loss: 1.3624 - sparse_categorical_accuracy: 0.4513 - val_loss: 1.5046 - val_sparse_categorical_accuracy: 0.4180\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 20s 803us/step - loss: 1.3571 - sparse_categorical_accuracy: 0.4512 - val_loss: 1.5186 - val_sparse_categorical_accuracy: 0.3973\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 19s 757us/step - loss: 1.3588 - sparse_categorical_accuracy: 0.4505 - val_loss: 1.5336 - val_sparse_categorical_accuracy: 0.4117\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 21s 871us/step - loss: 1.3357 - sparse_categorical_accuracy: 0.4560 - val_loss: 1.5303 - val_sparse_categorical_accuracy: 0.4160\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 20s 802us/step - loss: 1.3272 - sparse_categorical_accuracy: 0.4611 - val_loss: 1.5403 - val_sparse_categorical_accuracy: 0.4093\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 20s 812us/step - loss: 1.3166 - sparse_categorical_accuracy: 0.4655 - val_loss: 1.5285 - val_sparse_categorical_accuracy: 0.4080\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 19s 778us/step - loss: 1.3084 - sparse_categorical_accuracy: 0.4686 - val_loss: 1.5561 - val_sparse_categorical_accuracy: 0.4050\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 24s 957us/step - loss: 1.2975 - sparse_categorical_accuracy: 0.4743 - val_loss: 1.5434 - val_sparse_categorical_accuracy: 0.4027\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 22s 885us/step - loss: 1.2882 - sparse_categorical_accuracy: 0.4773 - val_loss: 1.5788 - val_sparse_categorical_accuracy: 0.4110\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 20s 812us/step - loss: 1.2776 - sparse_categorical_accuracy: 0.4783 - val_loss: 1.5824 - val_sparse_categorical_accuracy: 0.4083\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 19s 773us/step - loss: 1.2628 - sparse_categorical_accuracy: 0.4861 - val_loss: 1.5998 - val_sparse_categorical_accuracy: 0.4020\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 19s 758us/step - loss: 1.2543 - sparse_categorical_accuracy: 0.4883 - val_loss: 1.6190 - val_sparse_categorical_accuracy: 0.4127\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 20s 805us/step - loss: 1.2429 - sparse_categorical_accuracy: 0.4952 - val_loss: 1.6535 - val_sparse_categorical_accuracy: 0.3783\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 23s 953us/step - loss: 1.2311 - sparse_categorical_accuracy: 0.4998 - val_loss: 1.6260 - val_sparse_categorical_accuracy: 0.3910\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 19s 771us/step - loss: 1.2163 - sparse_categorical_accuracy: 0.5039 - val_loss: 1.6572 - val_sparse_categorical_accuracy: 0.3963\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 19s 785us/step - loss: 1.2067 - sparse_categorical_accuracy: 0.5078 - val_loss: 1.6502 - val_sparse_categorical_accuracy: 0.3897\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 19s 763us/step - loss: 1.1905 - sparse_categorical_accuracy: 0.5161 - val_loss: 1.6595 - val_sparse_categorical_accuracy: 0.3983\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 18s 749us/step - loss: 1.1811 - sparse_categorical_accuracy: 0.5177 - val_loss: 1.6980 - val_sparse_categorical_accuracy: 0.3913\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 19s 758us/step - loss: 1.1666 - sparse_categorical_accuracy: 0.5202 - val_loss: 1.7017 - val_sparse_categorical_accuracy: 0.3953\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 21s 869us/step - loss: 1.1547 - sparse_categorical_accuracy: 0.5290 - val_loss: 1.6969 - val_sparse_categorical_accuracy: 0.3853\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 27s 1ms/step - loss: 1.1399 - sparse_categorical_accuracy: 0.5371 - val_loss: 1.7348 - val_sparse_categorical_accuracy: 0.3900\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 21s 865us/step - loss: 1.1305 - sparse_categorical_accuracy: 0.5376 - val_loss: 1.7499 - val_sparse_categorical_accuracy: 0.3867\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 22s 895us/step - loss: 1.1160 - sparse_categorical_accuracy: 0.5437 - val_loss: 1.7861 - val_sparse_categorical_accuracy: 0.3740\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 23s 932us/step - loss: 1.1047 - sparse_categorical_accuracy: 0.5477 - val_loss: 1.8901 - val_sparse_categorical_accuracy: 0.3857\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 23s 933us/step - loss: 1.0892 - sparse_categorical_accuracy: 0.5534 - val_loss: 1.8664 - val_sparse_categorical_accuracy: 0.3927\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 24s 971us/step - loss: 1.0738 - sparse_categorical_accuracy: 0.5631 - val_loss: 1.8993 - val_sparse_categorical_accuracy: 0.3893\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 24s 966us/step - loss: 1.0630 - sparse_categorical_accuracy: 0.5675 - val_loss: 1.8926 - val_sparse_categorical_accuracy: 0.3900\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 19s 754us/step - loss: 1.0472 - sparse_categorical_accuracy: 0.5759 - val_loss: 1.9014 - val_sparse_categorical_accuracy: 0.3767\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 18s 746us/step - loss: 1.0322 - sparse_categorical_accuracy: 0.5783 - val_loss: 1.9409 - val_sparse_categorical_accuracy: 0.3877\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 19s 753us/step - loss: 1.0223 - sparse_categorical_accuracy: 0.5828 - val_loss: 1.9897 - val_sparse_categorical_accuracy: 0.3803\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 19s 752us/step - loss: 1.0120 - sparse_categorical_accuracy: 0.5857 - val_loss: 2.0190 - val_sparse_categorical_accuracy: 0.3703\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 18s 747us/step - loss: 0.9908 - sparse_categorical_accuracy: 0.5992 - val_loss: 2.1731 - val_sparse_categorical_accuracy: 0.3760\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 23s 925us/step - loss: 0.9872 - sparse_categorical_accuracy: 0.5949 - val_loss: 2.0820 - val_sparse_categorical_accuracy: 0.3770\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 19s 774us/step - loss: 0.9708 - sparse_categorical_accuracy: 0.6082 - val_loss: 2.1201 - val_sparse_categorical_accuracy: 0.3683\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 18s 743us/step - loss: 0.9518 - sparse_categorical_accuracy: 0.6119 - val_loss: 2.1264 - val_sparse_categorical_accuracy: 0.3573\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 19s 760us/step - loss: 0.9388 - sparse_categorical_accuracy: 0.6193 - val_loss: 2.2659 - val_sparse_categorical_accuracy: 0.3750\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 19s 754us/step - loss: 0.9303 - sparse_categorical_accuracy: 0.6227 - val_loss: 2.2087 - val_sparse_categorical_accuracy: 0.3690\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 19s 759us/step - loss: 0.9136 - sparse_categorical_accuracy: 0.6267 - val_loss: 2.3782 - val_sparse_categorical_accuracy: 0.3733\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 18s 738us/step - loss: 0.8991 - sparse_categorical_accuracy: 0.6350 - val_loss: 2.3342 - val_sparse_categorical_accuracy: 0.3703\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 21s 869us/step - loss: 0.8958 - sparse_categorical_accuracy: 0.6382 - val_loss: 2.3736 - val_sparse_categorical_accuracy: 0.3560\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 22s 897us/step - loss: 0.8776 - sparse_categorical_accuracy: 0.6465 - val_loss: 2.4162 - val_sparse_categorical_accuracy: 0.3807\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 23s 938us/step - loss: 0.8680 - sparse_categorical_accuracy: 0.6463 - val_loss: 2.4918 - val_sparse_categorical_accuracy: 0.3693\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 19s 788us/step - loss: 0.8724 - sparse_categorical_accuracy: 0.6475 - val_loss: 2.5137 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 18s 738us/step - loss: 0.8359 - sparse_categorical_accuracy: 0.6595 - val_loss: 2.6237 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 20s 801us/step - loss: 0.8308 - sparse_categorical_accuracy: 0.6639 - val_loss: 2.5840 - val_sparse_categorical_accuracy: 0.3570\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 20s 799us/step - loss: 0.8081 - sparse_categorical_accuracy: 0.6708 - val_loss: 2.6989 - val_sparse_categorical_accuracy: 0.3643\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 19s 773us/step - loss: 0.8198 - sparse_categorical_accuracy: 0.6700 - val_loss: 2.6573 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 19s 779us/step - loss: 0.8004 - sparse_categorical_accuracy: 0.6766 - val_loss: 2.6702 - val_sparse_categorical_accuracy: 0.3573\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 19s 789us/step - loss: 0.7878 - sparse_categorical_accuracy: 0.6834 - val_loss: 2.8294 - val_sparse_categorical_accuracy: 0.3633\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 20s 803us/step - loss: 0.7770 - sparse_categorical_accuracy: 0.6886 - val_loss: 2.8258 - val_sparse_categorical_accuracy: 0.3557\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 20s 803us/step - loss: 0.8091 - sparse_categorical_accuracy: 0.6754 - val_loss: 2.6756 - val_sparse_categorical_accuracy: 0.3587\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 19s 771us/step - loss: 0.7653 - sparse_categorical_accuracy: 0.6918 - val_loss: 2.9213 - val_sparse_categorical_accuracy: 0.3650\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 20s 792us/step - loss: 0.7443 - sparse_categorical_accuracy: 0.6975 - val_loss: 3.0120 - val_sparse_categorical_accuracy: 0.3590\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 20s 802us/step - loss: 0.7376 - sparse_categorical_accuracy: 0.7037 - val_loss: 3.0396 - val_sparse_categorical_accuracy: 0.3463\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 22s 877us/step - loss: 0.7274 - sparse_categorical_accuracy: 0.7073 - val_loss: 3.1524 - val_sparse_categorical_accuracy: 0.3590\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 23s 932us/step - loss: 0.7168 - sparse_categorical_accuracy: 0.7094 - val_loss: 3.0902 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 23s 915us/step - loss: 0.7109 - sparse_categorical_accuracy: 0.7114 - val_loss: 3.2053 - val_sparse_categorical_accuracy: 0.3547\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 24s 956us/step - loss: 0.6959 - sparse_categorical_accuracy: 0.7210 - val_loss: 3.2777 - val_sparse_categorical_accuracy: 0.3470\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 24s 967us/step - loss: 0.7381 - sparse_categorical_accuracy: 0.7056 - val_loss: 3.1605 - val_sparse_categorical_accuracy: 0.3433\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 23s 942us/step - loss: 0.6803 - sparse_categorical_accuracy: 0.7265 - val_loss: 3.6432 - val_sparse_categorical_accuracy: 0.3507\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 25s 1ms/step - loss: 0.6805 - sparse_categorical_accuracy: 0.7263 - val_loss: 3.2908 - val_sparse_categorical_accuracy: 0.3583\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 24s 992us/step - loss: 0.6501 - sparse_categorical_accuracy: 0.7368 - val_loss: 3.6364 - val_sparse_categorical_accuracy: 0.3367\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 20s 829us/step - loss: 0.6623 - sparse_categorical_accuracy: 0.7362 - val_loss: 3.5453 - val_sparse_categorical_accuracy: 0.3623\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 20s 817us/step - loss: 0.6557 - sparse_categorical_accuracy: 0.7392 - val_loss: 3.5507 - val_sparse_categorical_accuracy: 0.3457\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 22s 900us/step - loss: 0.6358 - sparse_categorical_accuracy: 0.7457 - val_loss: 3.7212 - val_sparse_categorical_accuracy: 0.3563\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 22s 873us/step - loss: 0.6925 - sparse_categorical_accuracy: 0.7255 - val_loss: 3.6602 - val_sparse_categorical_accuracy: 0.3423\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 21s 869us/step - loss: 0.6655 - sparse_categorical_accuracy: 0.7371 - val_loss: 3.5492 - val_sparse_categorical_accuracy: 0.3437\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 20s 820us/step - loss: 0.6085 - sparse_categorical_accuracy: 0.7565 - val_loss: 3.8509 - val_sparse_categorical_accuracy: 0.3557\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 20s 808us/step - loss: 0.5920 - sparse_categorical_accuracy: 0.7654 - val_loss: 4.0308 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 21s 849us/step - loss: 0.5943 - sparse_categorical_accuracy: 0.7642 - val_loss: 4.0120 - val_sparse_categorical_accuracy: 0.3610\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 19s 774us/step - loss: 0.5912 - sparse_categorical_accuracy: 0.7627 - val_loss: 4.0367 - val_sparse_categorical_accuracy: 0.3610\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 19s 779us/step - loss: 0.6356 - sparse_categorical_accuracy: 0.7475 - val_loss: 3.9581 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 19s 773us/step - loss: 0.5975 - sparse_categorical_accuracy: 0.7607 - val_loss: 3.7600 - val_sparse_categorical_accuracy: 0.3473\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 20s 826us/step - loss: 0.5906 - sparse_categorical_accuracy: 0.7648 - val_loss: 4.1119 - val_sparse_categorical_accuracy: 0.3423\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 20s 810us/step - loss: 0.5606 - sparse_categorical_accuracy: 0.7757 - val_loss: 4.3016 - val_sparse_categorical_accuracy: 0.3340\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 19s 787us/step - loss: 0.5534 - sparse_categorical_accuracy: 0.7799 - val_loss: 4.2465 - val_sparse_categorical_accuracy: 0.3453\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 19s 780us/step - loss: 0.5496 - sparse_categorical_accuracy: 0.7827 - val_loss: 4.3948 - val_sparse_categorical_accuracy: 0.3487\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 19s 788us/step - loss: 0.5485 - sparse_categorical_accuracy: 0.7819 - val_loss: 4.2726 - val_sparse_categorical_accuracy: 0.3500\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 20s 801us/step - loss: 0.5407 - sparse_categorical_accuracy: 0.7863 - val_loss: 4.4802 - val_sparse_categorical_accuracy: 0.3523\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 20s 827us/step - loss: 0.5270 - sparse_categorical_accuracy: 0.7950 - val_loss: 4.6274 - val_sparse_categorical_accuracy: 0.3520\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    history11 = model11.fit(X_train_n, Y_train_n, epochs=10, batch_size=32, validation_data = (X_dev_n, Y_dev_n))\n",
    "    history11_all.append(history11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 12: deep RNN, specifying activation function and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_18 (Masking)         (None, 30, 10)            0         \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 16)                816       \n",
      "=================================================================\n",
      "Total params: 70,466\n",
      "Trainable params: 70,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model12 = Sequential()\n",
    "model12.add(Masking(mask_value=0., input_shape=(30, 10)))\n",
    "model12.add(LSTM(100, activation='relu', input_shape=(30, 10), kernel_initializer='glorot_normal'))\n",
    "model12.add(Dense(100, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model12.add(Dense(100, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model12.add(Dense(50, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model12.add(Dense(16, activation='softmax'))\n",
    "model12.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "print(model12.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "history12_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 24s 968us/step - loss: 1.6923 - sparse_categorical_accuracy: 0.3730 - val_loss: 1.5856 - val_sparse_categorical_accuracy: 0.3957\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 23s 925us/step - loss: 1.5617 - sparse_categorical_accuracy: 0.3977 - val_loss: 1.5465 - val_sparse_categorical_accuracy: 0.4087\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 24s 961us/step - loss: 1.5339 - sparse_categorical_accuracy: 0.4026 - val_loss: 1.5168 - val_sparse_categorical_accuracy: 0.4067\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 20s 822us/step - loss: 1.5140 - sparse_categorical_accuracy: 0.4103 - val_loss: 1.5236 - val_sparse_categorical_accuracy: 0.4050\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 32s 1ms/step - loss: 1.4976 - sparse_categorical_accuracy: 0.4151 - val_loss: 1.5040 - val_sparse_categorical_accuracy: 0.4080\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 26s 1ms/step - loss: 1.4846 - sparse_categorical_accuracy: 0.4174 - val_loss: 1.4842 - val_sparse_categorical_accuracy: 0.4207\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 28s 1ms/step - loss: 1.4768 - sparse_categorical_accuracy: 0.4177 - val_loss: 1.4908 - val_sparse_categorical_accuracy: 0.4150\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 29s 1ms/step - loss: 1.4702 - sparse_categorical_accuracy: 0.4194 - val_loss: 1.4698 - val_sparse_categorical_accuracy: 0.4257\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 25s 1ms/step - loss: 1.4555 - sparse_categorical_accuracy: 0.4221 - val_loss: 1.5008 - val_sparse_categorical_accuracy: 0.4093\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 20s 796us/step - loss: 1.4471 - sparse_categorical_accuracy: 0.4234 - val_loss: 1.4865 - val_sparse_categorical_accuracy: 0.4197\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 20s 800us/step - loss: 1.4392 - sparse_categorical_accuracy: 0.4294 - val_loss: 1.4721 - val_sparse_categorical_accuracy: 0.4223\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 19s 790us/step - loss: 1.4288 - sparse_categorical_accuracy: 0.4261 - val_loss: 1.4719 - val_sparse_categorical_accuracy: 0.4220\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 20s 815us/step - loss: 1.4258 - sparse_categorical_accuracy: 0.4306 - val_loss: 1.4637 - val_sparse_categorical_accuracy: 0.4260\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 21s 838us/step - loss: 1.4200 - sparse_categorical_accuracy: 0.4367 - val_loss: 1.4828 - val_sparse_categorical_accuracy: 0.4077\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 20s 822us/step - loss: 1.4090 - sparse_categorical_accuracy: 0.4376 - val_loss: 1.4867 - val_sparse_categorical_accuracy: 0.4093\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 19s 759us/step - loss: 1.3987 - sparse_categorical_accuracy: 0.4412 - val_loss: 1.4803 - val_sparse_categorical_accuracy: 0.4230\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 20s 812us/step - loss: 1.3909 - sparse_categorical_accuracy: 0.4430 - val_loss: 1.5104 - val_sparse_categorical_accuracy: 0.4197\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 21s 860us/step - loss: 1.3860 - sparse_categorical_accuracy: 0.4416 - val_loss: 1.4908 - val_sparse_categorical_accuracy: 0.4183\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 20s 793us/step - loss: 1.3733 - sparse_categorical_accuracy: 0.4482 - val_loss: 1.4880 - val_sparse_categorical_accuracy: 0.4193\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 20s 798us/step - loss: 1.3646 - sparse_categorical_accuracy: 0.4502 - val_loss: 1.4882 - val_sparse_categorical_accuracy: 0.4097\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 20s 819us/step - loss: 1.3552 - sparse_categorical_accuracy: 0.4520 - val_loss: 1.4944 - val_sparse_categorical_accuracy: 0.4143\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 21s 837us/step - loss: 1.3480 - sparse_categorical_accuracy: 0.4544 - val_loss: 1.4933 - val_sparse_categorical_accuracy: 0.4097\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 21s 835us/step - loss: 1.3360 - sparse_categorical_accuracy: 0.4587 - val_loss: 1.5144 - val_sparse_categorical_accuracy: 0.3947\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 21s 840us/step - loss: 1.3295 - sparse_categorical_accuracy: 0.4641 - val_loss: 1.5046 - val_sparse_categorical_accuracy: 0.4167\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 22s 910us/step - loss: 1.3129 - sparse_categorical_accuracy: 0.4650 - val_loss: 1.5447 - val_sparse_categorical_accuracy: 0.3927\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 21s 851us/step - loss: 1.3000 - sparse_categorical_accuracy: 0.4716 - val_loss: 1.5321 - val_sparse_categorical_accuracy: 0.4097\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 21s 842us/step - loss: 1.2887 - sparse_categorical_accuracy: 0.4754 - val_loss: 1.5626 - val_sparse_categorical_accuracy: 0.4130\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 21s 833us/step - loss: 1.2748 - sparse_categorical_accuracy: 0.4843 - val_loss: 1.5901 - val_sparse_categorical_accuracy: 0.3963\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 19s 781us/step - loss: 1.2644 - sparse_categorical_accuracy: 0.4847 - val_loss: 1.5857 - val_sparse_categorical_accuracy: 0.3957\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 19s 767us/step - loss: 1.2516 - sparse_categorical_accuracy: 0.4886 - val_loss: 1.5770 - val_sparse_categorical_accuracy: 0.4103\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 19s 760us/step - loss: 1.2334 - sparse_categorical_accuracy: 0.4952 - val_loss: 1.6011 - val_sparse_categorical_accuracy: 0.3967\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 20s 830us/step - loss: 1.2241 - sparse_categorical_accuracy: 0.4996 - val_loss: 1.6877 - val_sparse_categorical_accuracy: 0.4080\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 19s 773us/step - loss: 1.2064 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.6028 - val_sparse_categorical_accuracy: 0.4020\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 20s 824us/step - loss: 1.1914 - sparse_categorical_accuracy: 0.5142 - val_loss: 1.6675 - val_sparse_categorical_accuracy: 0.3980\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 21s 856us/step - loss: 1.1713 - sparse_categorical_accuracy: 0.5202 - val_loss: 1.6606 - val_sparse_categorical_accuracy: 0.3940\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 21s 847us/step - loss: 1.1589 - sparse_categorical_accuracy: 0.5283 - val_loss: 1.7184 - val_sparse_categorical_accuracy: 0.3880\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 22s 875us/step - loss: 1.1402 - sparse_categorical_accuracy: 0.5303 - val_loss: 1.7038 - val_sparse_categorical_accuracy: 0.3920\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 21s 852us/step - loss: 1.1229 - sparse_categorical_accuracy: 0.5404 - val_loss: 1.7865 - val_sparse_categorical_accuracy: 0.3963\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 21s 855us/step - loss: 1.1005 - sparse_categorical_accuracy: 0.5493 - val_loss: 1.7804 - val_sparse_categorical_accuracy: 0.3823\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 21s 850us/step - loss: 1.0887 - sparse_categorical_accuracy: 0.5572 - val_loss: 1.7976 - val_sparse_categorical_accuracy: 0.3977\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 21s 844us/step - loss: 1.0663 - sparse_categorical_accuracy: 0.5674 - val_loss: 1.8366 - val_sparse_categorical_accuracy: 0.3897\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 21s 859us/step - loss: 1.0471 - sparse_categorical_accuracy: 0.5709 - val_loss: 1.9457 - val_sparse_categorical_accuracy: 0.3853\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 21s 838us/step - loss: 1.0249 - sparse_categorical_accuracy: 0.5810 - val_loss: 1.8922 - val_sparse_categorical_accuracy: 0.3883\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 21s 842us/step - loss: 1.0051 - sparse_categorical_accuracy: 0.5916 - val_loss: 2.0758 - val_sparse_categorical_accuracy: 0.3867\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 20s 823us/step - loss: 0.9883 - sparse_categorical_accuracy: 0.5987 - val_loss: 2.0704 - val_sparse_categorical_accuracy: 0.3913\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 21s 843us/step - loss: 0.9659 - sparse_categorical_accuracy: 0.6092 - val_loss: 2.0703 - val_sparse_categorical_accuracy: 0.3877\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 21s 843us/step - loss: 0.9484 - sparse_categorical_accuracy: 0.6170 - val_loss: 2.1193 - val_sparse_categorical_accuracy: 0.3833\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 21s 835us/step - loss: 0.9296 - sparse_categorical_accuracy: 0.6238 - val_loss: 2.1737 - val_sparse_categorical_accuracy: 0.3840\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 19s 773us/step - loss: 0.9137 - sparse_categorical_accuracy: 0.6314 - val_loss: 2.2312 - val_sparse_categorical_accuracy: 0.3753\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 19s 770us/step - loss: 0.8910 - sparse_categorical_accuracy: 0.6401 - val_loss: 2.2300 - val_sparse_categorical_accuracy: 0.3820\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 19s 782us/step - loss: 0.8622 - sparse_categorical_accuracy: 0.6513 - val_loss: 2.2908 - val_sparse_categorical_accuracy: 0.3760\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 19s 782us/step - loss: 0.8525 - sparse_categorical_accuracy: 0.6604 - val_loss: 2.4743 - val_sparse_categorical_accuracy: 0.3900\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 19s 779us/step - loss: 0.8268 - sparse_categorical_accuracy: 0.6686 - val_loss: 2.4716 - val_sparse_categorical_accuracy: 0.3720\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 19s 771us/step - loss: 0.8165 - sparse_categorical_accuracy: 0.6734 - val_loss: 2.4418 - val_sparse_categorical_accuracy: 0.3733\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 19s 760us/step - loss: 0.7921 - sparse_categorical_accuracy: 0.6823 - val_loss: 2.5437 - val_sparse_categorical_accuracy: 0.3713\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 20s 804us/step - loss: 0.7693 - sparse_categorical_accuracy: 0.6957 - val_loss: 2.6303 - val_sparse_categorical_accuracy: 0.3833\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 24s 960us/step - loss: 0.7620 - sparse_categorical_accuracy: 0.6985 - val_loss: 2.6847 - val_sparse_categorical_accuracy: 0.3690\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 24s 966us/step - loss: 0.7404 - sparse_categorical_accuracy: 0.7105 - val_loss: 2.7904 - val_sparse_categorical_accuracy: 0.3590\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 22s 878us/step - loss: 0.7233 - sparse_categorical_accuracy: 0.7138 - val_loss: 2.8415 - val_sparse_categorical_accuracy: 0.3870\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 23s 940us/step - loss: 0.7057 - sparse_categorical_accuracy: 0.7207 - val_loss: 2.8761 - val_sparse_categorical_accuracy: 0.3773\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 22s 883us/step - loss: 0.6951 - sparse_categorical_accuracy: 0.7287 - val_loss: 2.8860 - val_sparse_categorical_accuracy: 0.3763\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 20s 826us/step - loss: 0.6762 - sparse_categorical_accuracy: 0.7339 - val_loss: 2.9637 - val_sparse_categorical_accuracy: 0.3807\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 22s 885us/step - loss: 0.6562 - sparse_categorical_accuracy: 0.7418 - val_loss: 3.1205 - val_sparse_categorical_accuracy: 0.3710\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 21s 844us/step - loss: 0.6475 - sparse_categorical_accuracy: 0.7464 - val_loss: 3.0660 - val_sparse_categorical_accuracy: 0.3730\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 21s 861us/step - loss: 0.6280 - sparse_categorical_accuracy: 0.7524 - val_loss: 3.2089 - val_sparse_categorical_accuracy: 0.3653\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 21s 834us/step - loss: 0.6099 - sparse_categorical_accuracy: 0.7591 - val_loss: 3.2925 - val_sparse_categorical_accuracy: 0.3793\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 21s 856us/step - loss: 0.6072 - sparse_categorical_accuracy: 0.7642 - val_loss: 3.5362 - val_sparse_categorical_accuracy: 0.3860\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 20s 820us/step - loss: 0.5898 - sparse_categorical_accuracy: 0.7705 - val_loss: 3.4227 - val_sparse_categorical_accuracy: 0.3653\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 20s 829us/step - loss: 0.5703 - sparse_categorical_accuracy: 0.7755 - val_loss: 3.4669 - val_sparse_categorical_accuracy: 0.3553\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 20s 824us/step - loss: 0.5772 - sparse_categorical_accuracy: 0.7744 - val_loss: 3.5161 - val_sparse_categorical_accuracy: 0.3787\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 21s 833us/step - loss: 0.5413 - sparse_categorical_accuracy: 0.7913 - val_loss: 3.6508 - val_sparse_categorical_accuracy: 0.3573\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 20s 815us/step - loss: 0.5561 - sparse_categorical_accuracy: 0.7848 - val_loss: 3.5605 - val_sparse_categorical_accuracy: 0.3737\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 20s 813us/step - loss: 0.5358 - sparse_categorical_accuracy: 0.7909 - val_loss: 3.7142 - val_sparse_categorical_accuracy: 0.3577\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 19s 787us/step - loss: 0.5140 - sparse_categorical_accuracy: 0.8012 - val_loss: 3.7177 - val_sparse_categorical_accuracy: 0.3687\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 21s 858us/step - loss: 0.5075 - sparse_categorical_accuracy: 0.8051 - val_loss: 3.7897 - val_sparse_categorical_accuracy: 0.3770\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 22s 907us/step - loss: 0.5140 - sparse_categorical_accuracy: 0.8032 - val_loss: 3.8444 - val_sparse_categorical_accuracy: 0.3760\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 25s 1ms/step - loss: 0.4830 - sparse_categorical_accuracy: 0.8127 - val_loss: 3.9541 - val_sparse_categorical_accuracy: 0.3800\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 22s 904us/step - loss: 0.4753 - sparse_categorical_accuracy: 0.8162 - val_loss: 4.0055 - val_sparse_categorical_accuracy: 0.3667\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 22s 893us/step - loss: 0.4743 - sparse_categorical_accuracy: 0.8184 - val_loss: 4.1040 - val_sparse_categorical_accuracy: 0.3700\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 21s 869us/step - loss: 0.4569 - sparse_categorical_accuracy: 0.8243 - val_loss: 4.3375 - val_sparse_categorical_accuracy: 0.3647\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 22s 879us/step - loss: 0.4525 - sparse_categorical_accuracy: 0.8246 - val_loss: 4.3750 - val_sparse_categorical_accuracy: 0.3620\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 20s 819us/step - loss: 0.4528 - sparse_categorical_accuracy: 0.8244 - val_loss: 4.1882 - val_sparse_categorical_accuracy: 0.3777\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 20s 828us/step - loss: 0.4383 - sparse_categorical_accuracy: 0.8342 - val_loss: 4.5024 - val_sparse_categorical_accuracy: 0.3693\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 22s 875us/step - loss: 0.4492 - sparse_categorical_accuracy: 0.8315 - val_loss: 4.3324 - val_sparse_categorical_accuracy: 0.3753\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 20s 820us/step - loss: 0.4002 - sparse_categorical_accuracy: 0.8473 - val_loss: 4.4521 - val_sparse_categorical_accuracy: 0.3737\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 20s 826us/step - loss: 0.4209 - sparse_categorical_accuracy: 0.8408 - val_loss: 4.4689 - val_sparse_categorical_accuracy: 0.3660\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 22s 906us/step - loss: 0.4074 - sparse_categorical_accuracy: 0.8479 - val_loss: 4.5768 - val_sparse_categorical_accuracy: 0.3563\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 22s 895us/step - loss: 0.4031 - sparse_categorical_accuracy: 0.8465 - val_loss: 4.5266 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 20s 829us/step - loss: 0.3612 - sparse_categorical_accuracy: 0.8640 - val_loss: 4.8744 - val_sparse_categorical_accuracy: 0.3627\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 21s 856us/step - loss: 0.3651 - sparse_categorical_accuracy: 0.8645 - val_loss: 4.8039 - val_sparse_categorical_accuracy: 0.3657\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 21s 852us/step - loss: 0.3891 - sparse_categorical_accuracy: 0.8539 - val_loss: 4.8820 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 22s 894us/step - loss: 0.3756 - sparse_categorical_accuracy: 0.8574 - val_loss: 4.9443 - val_sparse_categorical_accuracy: 0.3647\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 21s 861us/step - loss: 0.3563 - sparse_categorical_accuracy: 0.8679 - val_loss: 5.0131 - val_sparse_categorical_accuracy: 0.3623\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 22s 877us/step - loss: 0.3990 - sparse_categorical_accuracy: 0.8507 - val_loss: 4.9287 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 22s 888us/step - loss: 0.3571 - sparse_categorical_accuracy: 0.8693 - val_loss: 4.9419 - val_sparse_categorical_accuracy: 0.3620\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 30s 1ms/step - loss: 0.3365 - sparse_categorical_accuracy: 0.8749 - val_loss: 4.9666 - val_sparse_categorical_accuracy: 0.3630\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 22s 884us/step - loss: 0.3678 - sparse_categorical_accuracy: 0.8646 - val_loss: 5.0893 - val_sparse_categorical_accuracy: 0.3680\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 22s 902us/step - loss: 0.3382 - sparse_categorical_accuracy: 0.8754 - val_loss: 5.2619 - val_sparse_categorical_accuracy: 0.3690\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 22s 873us/step - loss: 0.3273 - sparse_categorical_accuracy: 0.8785 - val_loss: 5.1193 - val_sparse_categorical_accuracy: 0.3657\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 21s 844us/step - loss: 0.3238 - sparse_categorical_accuracy: 0.8790 - val_loss: 5.5261 - val_sparse_categorical_accuracy: 0.3450\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    history12 = model12.fit(X_train_n, Y_train_n, epochs=10, batch_size=32, validation_data = (X_dev_n, Y_dev_n))\n",
    "    history12_all.append(history12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 13: try CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cnn_set_path = parent_wd + '/preprocessing/training_set_cnn'\n",
    "dev_cnn_set_path = parent_wd + '/preprocessing/dev_set_cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_cnn_set_path, 'rb') as f:\n",
    "    training_set_cnn = pickle.load(f)\n",
    "with open(dev_cnn_set_path, 'rb') as f:\n",
    "    dev_set_cnn = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = training_set_cnn['X']\n",
    "Y_train_cnn = training_set_cnn['Y']\n",
    "X_dev_cnn = dev_set_cnn['X']\n",
    "Y_dev_cnn = dev_set_cnn['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 4, 11, 64)         36928     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 9, 32)          18464     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 16)                9232      \n",
      "=================================================================\n",
      "Total params: 64,624\n",
      "Trainable params: 64,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model13 = Sequential()\n",
    "model13.add(Conv2D(64, kernel_size=8, activation='relu', input_shape=(11, 18, 9), kernel_initializer='glorot_normal'))\n",
    "model13.add(Conv2D(32, kernel_size=3, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model13.add(Flatten())\n",
    "model13.add(Dense(16, activation='softmax', kernel_initializer='he_normal'))\n",
    "model13.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "print(model13.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "history13_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 6s 250us/step - loss: 1.7317 - sparse_categorical_accuracy: 0.3593 - val_loss: 1.6198 - val_sparse_categorical_accuracy: 0.3847\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 7s 264us/step - loss: 1.5949 - sparse_categorical_accuracy: 0.3869 - val_loss: 1.5700 - val_sparse_categorical_accuracy: 0.3937\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 7s 283us/step - loss: 1.5620 - sparse_categorical_accuracy: 0.3976 - val_loss: 1.5246 - val_sparse_categorical_accuracy: 0.4130\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 8s 313us/step - loss: 1.5378 - sparse_categorical_accuracy: 0.4045 - val_loss: 1.5240 - val_sparse_categorical_accuracy: 0.4120\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 198us/step - loss: 1.5202 - sparse_categorical_accuracy: 0.4065 - val_loss: 1.5099 - val_sparse_categorical_accuracy: 0.4113\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 217us/step - loss: 1.5050 - sparse_categorical_accuracy: 0.4117 - val_loss: 1.5587 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 210us/step - loss: 1.4912 - sparse_categorical_accuracy: 0.4152 - val_loss: 1.5332 - val_sparse_categorical_accuracy: 0.4053\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 6s 231us/step - loss: 1.4816 - sparse_categorical_accuracy: 0.4172 - val_loss: 1.5147 - val_sparse_categorical_accuracy: 0.4153\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 6s 230us/step - loss: 1.4724 - sparse_categorical_accuracy: 0.4209 - val_loss: 1.5046 - val_sparse_categorical_accuracy: 0.4100\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 6s 249us/step - loss: 1.4688 - sparse_categorical_accuracy: 0.4225 - val_loss: 1.5217 - val_sparse_categorical_accuracy: 0.3980\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 6s 232us/step - loss: 1.4541 - sparse_categorical_accuracy: 0.4259 - val_loss: 1.5064 - val_sparse_categorical_accuracy: 0.4170\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 6s 252us/step - loss: 1.4475 - sparse_categorical_accuracy: 0.4297 - val_loss: 1.5509 - val_sparse_categorical_accuracy: 0.4070\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 6s 244us/step - loss: 1.4358 - sparse_categorical_accuracy: 0.4330 - val_loss: 1.5037 - val_sparse_categorical_accuracy: 0.4157\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 6s 226us/step - loss: 1.4279 - sparse_categorical_accuracy: 0.4383 - val_loss: 1.5170 - val_sparse_categorical_accuracy: 0.4037\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 6s 235us/step - loss: 1.4204 - sparse_categorical_accuracy: 0.4388 - val_loss: 1.5507 - val_sparse_categorical_accuracy: 0.3947\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 6s 225us/step - loss: 1.4100 - sparse_categorical_accuracy: 0.4434 - val_loss: 1.5396 - val_sparse_categorical_accuracy: 0.3997\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 6s 236us/step - loss: 1.4006 - sparse_categorical_accuracy: 0.4445 - val_loss: 1.5199 - val_sparse_categorical_accuracy: 0.4077\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 210us/step - loss: 1.3943 - sparse_categorical_accuracy: 0.4491 - val_loss: 1.5279 - val_sparse_categorical_accuracy: 0.3993\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 211us/step - loss: 1.3827 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.5480 - val_sparse_categorical_accuracy: 0.4017\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 221us/step - loss: 1.3746 - sparse_categorical_accuracy: 0.4592 - val_loss: 1.5637 - val_sparse_categorical_accuracy: 0.4030\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 217us/step - loss: 1.3625 - sparse_categorical_accuracy: 0.4610 - val_loss: 1.5642 - val_sparse_categorical_accuracy: 0.4060\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 6s 238us/step - loss: 1.3546 - sparse_categorical_accuracy: 0.4638 - val_loss: 1.5581 - val_sparse_categorical_accuracy: 0.3990\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 205us/step - loss: 1.3438 - sparse_categorical_accuracy: 0.4713 - val_loss: 1.5627 - val_sparse_categorical_accuracy: 0.4033\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 6s 224us/step - loss: 1.3356 - sparse_categorical_accuracy: 0.4757 - val_loss: 1.5888 - val_sparse_categorical_accuracy: 0.4010\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 198us/step - loss: 1.3238 - sparse_categorical_accuracy: 0.4785 - val_loss: 1.5967 - val_sparse_categorical_accuracy: 0.3917\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 207us/step - loss: 1.3139 - sparse_categorical_accuracy: 0.4821 - val_loss: 1.5863 - val_sparse_categorical_accuracy: 0.4013\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 215us/step - loss: 1.3044 - sparse_categorical_accuracy: 0.4823 - val_loss: 1.5842 - val_sparse_categorical_accuracy: 0.3953\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 186us/step - loss: 1.2963 - sparse_categorical_accuracy: 0.4859 - val_loss: 1.6123 - val_sparse_categorical_accuracy: 0.3867\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 213us/step - loss: 1.2845 - sparse_categorical_accuracy: 0.4942 - val_loss: 1.5967 - val_sparse_categorical_accuracy: 0.4007\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 211us/step - loss: 1.2757 - sparse_categorical_accuracy: 0.4992 - val_loss: 1.5975 - val_sparse_categorical_accuracy: 0.3963\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 223us/step - loss: 1.2663 - sparse_categorical_accuracy: 0.5032 - val_loss: 1.6031 - val_sparse_categorical_accuracy: 0.4003\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 206us/step - loss: 1.2585 - sparse_categorical_accuracy: 0.5077 - val_loss: 1.6108 - val_sparse_categorical_accuracy: 0.4037\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 199us/step - loss: 1.2483 - sparse_categorical_accuracy: 0.5057 - val_loss: 1.6584 - val_sparse_categorical_accuracy: 0.3800\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 6s 224us/step - loss: 1.2403 - sparse_categorical_accuracy: 0.5114 - val_loss: 1.6380 - val_sparse_categorical_accuracy: 0.3857\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 206us/step - loss: 1.2292 - sparse_categorical_accuracy: 0.5185 - val_loss: 1.6761 - val_sparse_categorical_accuracy: 0.3983\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 206us/step - loss: 1.2206 - sparse_categorical_accuracy: 0.5218 - val_loss: 1.7084 - val_sparse_categorical_accuracy: 0.3920\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 7s 274us/step - loss: 1.2109 - sparse_categorical_accuracy: 0.5233 - val_loss: 1.7026 - val_sparse_categorical_accuracy: 0.3820\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 6s 262us/step - loss: 1.2052 - sparse_categorical_accuracy: 0.5289 - val_loss: 1.6929 - val_sparse_categorical_accuracy: 0.4003\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 6s 256us/step - loss: 1.1949 - sparse_categorical_accuracy: 0.5328 - val_loss: 1.7438 - val_sparse_categorical_accuracy: 0.3830\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 7s 276us/step - loss: 1.1840 - sparse_categorical_accuracy: 0.5369 - val_loss: 1.7454 - val_sparse_categorical_accuracy: 0.3857\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 7s 293us/step - loss: 1.1781 - sparse_categorical_accuracy: 0.5391 - val_loss: 1.7489 - val_sparse_categorical_accuracy: 0.3910\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 7s 276us/step - loss: 1.1744 - sparse_categorical_accuracy: 0.5417 - val_loss: 1.7488 - val_sparse_categorical_accuracy: 0.3707\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 6s 244us/step - loss: 1.1662 - sparse_categorical_accuracy: 0.5424 - val_loss: 1.7261 - val_sparse_categorical_accuracy: 0.3893\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 6s 264us/step - loss: 1.1526 - sparse_categorical_accuracy: 0.5507 - val_loss: 1.7918 - val_sparse_categorical_accuracy: 0.3683\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 7s 270us/step - loss: 1.1484 - sparse_categorical_accuracy: 0.5484 - val_loss: 1.8110 - val_sparse_categorical_accuracy: 0.3897\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 6s 259us/step - loss: 1.1353 - sparse_categorical_accuracy: 0.5577 - val_loss: 1.8136 - val_sparse_categorical_accuracy: 0.3733\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 204us/step - loss: 1.1270 - sparse_categorical_accuracy: 0.5602 - val_loss: 1.7884 - val_sparse_categorical_accuracy: 0.3940\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 215us/step - loss: 1.1261 - sparse_categorical_accuracy: 0.5617 - val_loss: 1.8375 - val_sparse_categorical_accuracy: 0.3913\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 196us/step - loss: 1.1155 - sparse_categorical_accuracy: 0.5671 - val_loss: 1.8376 - val_sparse_categorical_accuracy: 0.3893\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 189us/step - loss: 1.1120 - sparse_categorical_accuracy: 0.5652 - val_loss: 1.8271 - val_sparse_categorical_accuracy: 0.3827\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 207us/step - loss: 1.1007 - sparse_categorical_accuracy: 0.5744 - val_loss: 1.8094 - val_sparse_categorical_accuracy: 0.3830\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 211us/step - loss: 1.0962 - sparse_categorical_accuracy: 0.5770 - val_loss: 1.8684 - val_sparse_categorical_accuracy: 0.3890\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 6s 226us/step - loss: 1.0895 - sparse_categorical_accuracy: 0.5768 - val_loss: 1.8380 - val_sparse_categorical_accuracy: 0.3850\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 209us/step - loss: 1.0823 - sparse_categorical_accuracy: 0.5800 - val_loss: 1.8938 - val_sparse_categorical_accuracy: 0.3780\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 6s 227us/step - loss: 1.0710 - sparse_categorical_accuracy: 0.5858 - val_loss: 1.9028 - val_sparse_categorical_accuracy: 0.3793\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 183us/step - loss: 1.0677 - sparse_categorical_accuracy: 0.5869 - val_loss: 1.9639 - val_sparse_categorical_accuracy: 0.3830\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 220us/step - loss: 1.0602 - sparse_categorical_accuracy: 0.5893 - val_loss: 1.9382 - val_sparse_categorical_accuracy: 0.3887\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 208us/step - loss: 1.0532 - sparse_categorical_accuracy: 0.5906 - val_loss: 1.9982 - val_sparse_categorical_accuracy: 0.3823\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 203us/step - loss: 1.0516 - sparse_categorical_accuracy: 0.5928 - val_loss: 1.9504 - val_sparse_categorical_accuracy: 0.3890\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 207us/step - loss: 1.0465 - sparse_categorical_accuracy: 0.5929 - val_loss: 1.9788 - val_sparse_categorical_accuracy: 0.3707\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 210us/step - loss: 1.0317 - sparse_categorical_accuracy: 0.6009 - val_loss: 2.0307 - val_sparse_categorical_accuracy: 0.3790\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 185us/step - loss: 1.0289 - sparse_categorical_accuracy: 0.5975 - val_loss: 1.9801 - val_sparse_categorical_accuracy: 0.3727\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 189us/step - loss: 1.0218 - sparse_categorical_accuracy: 0.6024 - val_loss: 2.0773 - val_sparse_categorical_accuracy: 0.3800\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 184us/step - loss: 1.0150 - sparse_categorical_accuracy: 0.6053 - val_loss: 2.0058 - val_sparse_categorical_accuracy: 0.3903\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 187us/step - loss: 1.0066 - sparse_categorical_accuracy: 0.6074 - val_loss: 2.0932 - val_sparse_categorical_accuracy: 0.3823\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 198us/step - loss: 1.0017 - sparse_categorical_accuracy: 0.6090 - val_loss: 2.0221 - val_sparse_categorical_accuracy: 0.3903\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 187us/step - loss: 0.9965 - sparse_categorical_accuracy: 0.6146 - val_loss: 2.0553 - val_sparse_categorical_accuracy: 0.3760\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 186us/step - loss: 0.9898 - sparse_categorical_accuracy: 0.6172 - val_loss: 2.0608 - val_sparse_categorical_accuracy: 0.3743\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 211us/step - loss: 0.9847 - sparse_categorical_accuracy: 0.6146 - val_loss: 2.1393 - val_sparse_categorical_accuracy: 0.3790\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 220us/step - loss: 0.9837 - sparse_categorical_accuracy: 0.6197 - val_loss: 2.0839 - val_sparse_categorical_accuracy: 0.3727\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 186us/step - loss: 0.9713 - sparse_categorical_accuracy: 0.6268 - val_loss: 2.1437 - val_sparse_categorical_accuracy: 0.3770\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 208us/step - loss: 0.9735 - sparse_categorical_accuracy: 0.6239 - val_loss: 2.1161 - val_sparse_categorical_accuracy: 0.3790\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 187us/step - loss: 0.9603 - sparse_categorical_accuracy: 0.6269 - val_loss: 2.1786 - val_sparse_categorical_accuracy: 0.3737\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 4s 182us/step - loss: 0.9609 - sparse_categorical_accuracy: 0.6287 - val_loss: 2.2341 - val_sparse_categorical_accuracy: 0.3743\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 217us/step - loss: 0.9520 - sparse_categorical_accuracy: 0.6324 - val_loss: 2.1629 - val_sparse_categorical_accuracy: 0.3787\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 186us/step - loss: 0.9480 - sparse_categorical_accuracy: 0.6294 - val_loss: 2.2061 - val_sparse_categorical_accuracy: 0.3670\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 189us/step - loss: 0.9422 - sparse_categorical_accuracy: 0.6349 - val_loss: 2.2530 - val_sparse_categorical_accuracy: 0.3810\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 212us/step - loss: 0.9361 - sparse_categorical_accuracy: 0.6352 - val_loss: 2.2786 - val_sparse_categorical_accuracy: 0.3773\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 219us/step - loss: 0.9319 - sparse_categorical_accuracy: 0.6393 - val_loss: 2.2219 - val_sparse_categorical_accuracy: 0.3797\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 205us/step - loss: 0.9272 - sparse_categorical_accuracy: 0.6437 - val_loss: 2.2447 - val_sparse_categorical_accuracy: 0.3797\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 208us/step - loss: 0.9204 - sparse_categorical_accuracy: 0.6421 - val_loss: 2.3263 - val_sparse_categorical_accuracy: 0.3650\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 217us/step - loss: 0.9197 - sparse_categorical_accuracy: 0.6447 - val_loss: 2.2746 - val_sparse_categorical_accuracy: 0.3640\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 7s 293us/step - loss: 0.9121 - sparse_categorical_accuracy: 0.6480 - val_loss: 2.3479 - val_sparse_categorical_accuracy: 0.3763\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 7s 271us/step - loss: 0.9083 - sparse_categorical_accuracy: 0.6481 - val_loss: 2.3602 - val_sparse_categorical_accuracy: 0.3620\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 201us/step - loss: 0.9020 - sparse_categorical_accuracy: 0.6500 - val_loss: 2.3513 - val_sparse_categorical_accuracy: 0.3687\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 193us/step - loss: 0.8989 - sparse_categorical_accuracy: 0.6527 - val_loss: 2.3492 - val_sparse_categorical_accuracy: 0.3813\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 195us/step - loss: 0.8955 - sparse_categorical_accuracy: 0.6537 - val_loss: 2.3709 - val_sparse_categorical_accuracy: 0.3587\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 191us/step - loss: 0.8924 - sparse_categorical_accuracy: 0.6558 - val_loss: 2.3790 - val_sparse_categorical_accuracy: 0.3800\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 192us/step - loss: 0.8914 - sparse_categorical_accuracy: 0.6563 - val_loss: 2.3134 - val_sparse_categorical_accuracy: 0.3680\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 6s 231us/step - loss: 0.8831 - sparse_categorical_accuracy: 0.6586 - val_loss: 2.4190 - val_sparse_categorical_accuracy: 0.3683\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 220us/step - loss: 0.8813 - sparse_categorical_accuracy: 0.6580 - val_loss: 2.3930 - val_sparse_categorical_accuracy: 0.3857\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 6s 235us/step - loss: 0.8774 - sparse_categorical_accuracy: 0.6612 - val_loss: 2.4285 - val_sparse_categorical_accuracy: 0.3693\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 214us/step - loss: 0.8729 - sparse_categorical_accuracy: 0.6635 - val_loss: 2.4572 - val_sparse_categorical_accuracy: 0.3647\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 198us/step - loss: 0.8672 - sparse_categorical_accuracy: 0.6638 - val_loss: 2.4628 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 197us/step - loss: 0.8671 - sparse_categorical_accuracy: 0.6616 - val_loss: 2.4632 - val_sparse_categorical_accuracy: 0.3747\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 6s 228us/step - loss: 0.8573 - sparse_categorical_accuracy: 0.6687 - val_loss: 2.5236 - val_sparse_categorical_accuracy: 0.3700\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 198us/step - loss: 0.8587 - sparse_categorical_accuracy: 0.6669 - val_loss: 2.4874 - val_sparse_categorical_accuracy: 0.3687\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 214us/step - loss: 0.8546 - sparse_categorical_accuracy: 0.6702 - val_loss: 2.5585 - val_sparse_categorical_accuracy: 0.3633\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 216us/step - loss: 0.8502 - sparse_categorical_accuracy: 0.6720 - val_loss: 2.5044 - val_sparse_categorical_accuracy: 0.3730\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 212us/step - loss: 0.8464 - sparse_categorical_accuracy: 0.6702 - val_loss: 2.5698 - val_sparse_categorical_accuracy: 0.3837\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    history13 = model13.fit(X_train_cnn, Y_train_cnn, epochs=10, batch_size=32, validation_data = (X_dev_cnn, Y_dev_cnn))\n",
    "    history13_all.append(history13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 6s 239us/step - loss: 0.8493 - sparse_categorical_accuracy: 0.6693 - val_loss: 2.5985 - val_sparse_categorical_accuracy: 0.3720\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 205us/step - loss: 0.8384 - sparse_categorical_accuracy: 0.6751 - val_loss: 2.6133 - val_sparse_categorical_accuracy: 0.3657\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 212us/step - loss: 0.8415 - sparse_categorical_accuracy: 0.6736 - val_loss: 2.5684 - val_sparse_categorical_accuracy: 0.3793\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 209us/step - loss: 0.8350 - sparse_categorical_accuracy: 0.6763 - val_loss: 2.6087 - val_sparse_categorical_accuracy: 0.3653\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 197us/step - loss: 0.8294 - sparse_categorical_accuracy: 0.6774 - val_loss: 2.5735 - val_sparse_categorical_accuracy: 0.3697\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 202us/step - loss: 0.8270 - sparse_categorical_accuracy: 0.6773 - val_loss: 2.6888 - val_sparse_categorical_accuracy: 0.3673\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 205us/step - loss: 0.8274 - sparse_categorical_accuracy: 0.6825 - val_loss: 2.6091 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 6s 231us/step - loss: 0.8236 - sparse_categorical_accuracy: 0.6800 - val_loss: 2.6499 - val_sparse_categorical_accuracy: 0.3743\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 214us/step - loss: 0.8190 - sparse_categorical_accuracy: 0.6835 - val_loss: 2.6594 - val_sparse_categorical_accuracy: 0.3667\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 220us/step - loss: 0.8171 - sparse_categorical_accuracy: 0.6836 - val_loss: 2.6936 - val_sparse_categorical_accuracy: 0.3713\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 220us/step - loss: 0.8140 - sparse_categorical_accuracy: 0.6846 - val_loss: 2.8408 - val_sparse_categorical_accuracy: 0.3700\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 6s 230us/step - loss: 0.8159 - sparse_categorical_accuracy: 0.6873 - val_loss: 2.6667 - val_sparse_categorical_accuracy: 0.3800\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 216us/step - loss: 0.8086 - sparse_categorical_accuracy: 0.6834 - val_loss: 2.6719 - val_sparse_categorical_accuracy: 0.3703\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 6s 250us/step - loss: 0.8044 - sparse_categorical_accuracy: 0.6867 - val_loss: 2.7004 - val_sparse_categorical_accuracy: 0.3757\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 221us/step - loss: 0.8031 - sparse_categorical_accuracy: 0.6867 - val_loss: 2.7501 - val_sparse_categorical_accuracy: 0.3787\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 6s 244us/step - loss: 0.7975 - sparse_categorical_accuracy: 0.6896 - val_loss: 2.7666 - val_sparse_categorical_accuracy: 0.3653\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 6s 223us/step - loss: 0.8057 - sparse_categorical_accuracy: 0.6897 - val_loss: 2.7635 - val_sparse_categorical_accuracy: 0.3707\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 221us/step - loss: 0.7915 - sparse_categorical_accuracy: 0.6954 - val_loss: 2.8412 - val_sparse_categorical_accuracy: 0.3757\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 6s 236us/step - loss: 0.7957 - sparse_categorical_accuracy: 0.6918 - val_loss: 2.7837 - val_sparse_categorical_accuracy: 0.3823\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 6s 245us/step - loss: 0.7929 - sparse_categorical_accuracy: 0.6921 - val_loss: 2.7771 - val_sparse_categorical_accuracy: 0.3667\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 208us/step - loss: 0.7826 - sparse_categorical_accuracy: 0.6972 - val_loss: 2.8398 - val_sparse_categorical_accuracy: 0.3643\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 209us/step - loss: 0.7939 - sparse_categorical_accuracy: 0.6941 - val_loss: 2.8270 - val_sparse_categorical_accuracy: 0.3630\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 199us/step - loss: 0.7853 - sparse_categorical_accuracy: 0.6917 - val_loss: 2.7473 - val_sparse_categorical_accuracy: 0.3693\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 213us/step - loss: 0.7812 - sparse_categorical_accuracy: 0.6972 - val_loss: 2.8759 - val_sparse_categorical_accuracy: 0.3787\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 201us/step - loss: 0.7754 - sparse_categorical_accuracy: 0.7009 - val_loss: 2.9399 - val_sparse_categorical_accuracy: 0.3633\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 7s 294us/step - loss: 0.7867 - sparse_categorical_accuracy: 0.6967 - val_loss: 2.7925 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 6s 250us/step - loss: 0.7735 - sparse_categorical_accuracy: 0.7022 - val_loss: 2.8707 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 7s 271us/step - loss: 0.7709 - sparse_categorical_accuracy: 0.7010 - val_loss: 2.8976 - val_sparse_categorical_accuracy: 0.3673\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 198us/step - loss: 0.7720 - sparse_categorical_accuracy: 0.6981 - val_loss: 2.9141 - val_sparse_categorical_accuracy: 0.3570\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 195us/step - loss: 0.7672 - sparse_categorical_accuracy: 0.6994 - val_loss: 2.9055 - val_sparse_categorical_accuracy: 0.3673\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 216us/step - loss: 0.7589 - sparse_categorical_accuracy: 0.7085 - val_loss: 3.0333 - val_sparse_categorical_accuracy: 0.3790\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 198us/step - loss: 0.7679 - sparse_categorical_accuracy: 0.7057 - val_loss: 2.9674 - val_sparse_categorical_accuracy: 0.3663\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 209us/step - loss: 0.7560 - sparse_categorical_accuracy: 0.7067 - val_loss: 3.0250 - val_sparse_categorical_accuracy: 0.3673\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 199us/step - loss: 0.7502 - sparse_categorical_accuracy: 0.7093 - val_loss: 3.0583 - val_sparse_categorical_accuracy: 0.3707\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 213us/step - loss: 0.7585 - sparse_categorical_accuracy: 0.7035 - val_loss: 2.8625 - val_sparse_categorical_accuracy: 0.3893\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 6s 232us/step - loss: 0.7555 - sparse_categorical_accuracy: 0.7067 - val_loss: 3.0660 - val_sparse_categorical_accuracy: 0.3740\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 6s 248us/step - loss: 0.7441 - sparse_categorical_accuracy: 0.7129 - val_loss: 3.0439 - val_sparse_categorical_accuracy: 0.3570\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 6s 237us/step - loss: 0.7502 - sparse_categorical_accuracy: 0.7103 - val_loss: 3.0523 - val_sparse_categorical_accuracy: 0.3590\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 6s 243us/step - loss: 0.7493 - sparse_categorical_accuracy: 0.7104 - val_loss: 2.9747 - val_sparse_categorical_accuracy: 0.3693\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 6s 238us/step - loss: 0.7417 - sparse_categorical_accuracy: 0.7128 - val_loss: 3.0608 - val_sparse_categorical_accuracy: 0.3660\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 193us/step - loss: 0.7425 - sparse_categorical_accuracy: 0.7123 - val_loss: 3.0051 - val_sparse_categorical_accuracy: 0.3577\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 217us/step - loss: 0.7412 - sparse_categorical_accuracy: 0.7148 - val_loss: 3.1176 - val_sparse_categorical_accuracy: 0.3643\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 7s 301us/step - loss: 0.7418 - sparse_categorical_accuracy: 0.7141 - val_loss: 3.0893 - val_sparse_categorical_accuracy: 0.3613\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 6s 246us/step - loss: 0.7361 - sparse_categorical_accuracy: 0.7152 - val_loss: 3.1070 - val_sparse_categorical_accuracy: 0.3740\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 6s 231us/step - loss: 0.7318 - sparse_categorical_accuracy: 0.7181 - val_loss: 3.0882 - val_sparse_categorical_accuracy: 0.3653\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 217us/step - loss: 0.7339 - sparse_categorical_accuracy: 0.7136 - val_loss: 3.1682 - val_sparse_categorical_accuracy: 0.3657\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 6s 235us/step - loss: 0.7314 - sparse_categorical_accuracy: 0.7158 - val_loss: 3.1663 - val_sparse_categorical_accuracy: 0.3783\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 6s 251us/step - loss: 0.7310 - sparse_categorical_accuracy: 0.7151 - val_loss: 3.1633 - val_sparse_categorical_accuracy: 0.3693\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 6s 227us/step - loss: 0.7292 - sparse_categorical_accuracy: 0.7188 - val_loss: 3.1438 - val_sparse_categorical_accuracy: 0.3613\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 6s 230us/step - loss: 0.7257 - sparse_categorical_accuracy: 0.7192 - val_loss: 3.2070 - val_sparse_categorical_accuracy: 0.3750\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 218us/step - loss: 0.7192 - sparse_categorical_accuracy: 0.7201 - val_loss: 3.2877 - val_sparse_categorical_accuracy: 0.3660\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 217us/step - loss: 0.7189 - sparse_categorical_accuracy: 0.7171 - val_loss: 3.1721 - val_sparse_categorical_accuracy: 0.3727\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 6s 241us/step - loss: 0.7206 - sparse_categorical_accuracy: 0.7228 - val_loss: 3.3013 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 211us/step - loss: 0.7145 - sparse_categorical_accuracy: 0.7222 - val_loss: 3.1431 - val_sparse_categorical_accuracy: 0.3623\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 203us/step - loss: 0.7199 - sparse_categorical_accuracy: 0.7210 - val_loss: 3.2385 - val_sparse_categorical_accuracy: 0.3637\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 6s 232us/step - loss: 0.7149 - sparse_categorical_accuracy: 0.7224 - val_loss: 3.2535 - val_sparse_categorical_accuracy: 0.3743\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 209us/step - loss: 0.7084 - sparse_categorical_accuracy: 0.7260 - val_loss: 3.3663 - val_sparse_categorical_accuracy: 0.3693\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 210us/step - loss: 0.7183 - sparse_categorical_accuracy: 0.7200 - val_loss: 3.3345 - val_sparse_categorical_accuracy: 0.3650\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 202us/step - loss: 0.7170 - sparse_categorical_accuracy: 0.7219 - val_loss: 3.4159 - val_sparse_categorical_accuracy: 0.3570\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 203us/step - loss: 0.7062 - sparse_categorical_accuracy: 0.7250 - val_loss: 3.1997 - val_sparse_categorical_accuracy: 0.3643\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 200us/step - loss: 0.7043 - sparse_categorical_accuracy: 0.7277 - val_loss: 3.3750 - val_sparse_categorical_accuracy: 0.3643\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 198us/step - loss: 0.7040 - sparse_categorical_accuracy: 0.7254 - val_loss: 3.2556 - val_sparse_categorical_accuracy: 0.3643\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 219us/step - loss: 0.7065 - sparse_categorical_accuracy: 0.7270 - val_loss: 3.3704 - val_sparse_categorical_accuracy: 0.3563\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 222us/step - loss: 0.7018 - sparse_categorical_accuracy: 0.7267 - val_loss: 3.4095 - val_sparse_categorical_accuracy: 0.3713\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 206us/step - loss: 0.7014 - sparse_categorical_accuracy: 0.7267 - val_loss: 3.3890 - val_sparse_categorical_accuracy: 0.3600\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 6s 229us/step - loss: 0.6988 - sparse_categorical_accuracy: 0.7277 - val_loss: 3.4151 - val_sparse_categorical_accuracy: 0.3640\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 6s 242us/step - loss: 0.7017 - sparse_categorical_accuracy: 0.7288 - val_loss: 3.5156 - val_sparse_categorical_accuracy: 0.3467\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 6s 224us/step - loss: 0.6916 - sparse_categorical_accuracy: 0.7305 - val_loss: 3.4255 - val_sparse_categorical_accuracy: 0.3663\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 201us/step - loss: 0.6896 - sparse_categorical_accuracy: 0.7320 - val_loss: 3.5091 - val_sparse_categorical_accuracy: 0.3767\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 196us/step - loss: 0.6847 - sparse_categorical_accuracy: 0.7342 - val_loss: 3.4088 - val_sparse_categorical_accuracy: 0.3610\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 190us/step - loss: 0.6936 - sparse_categorical_accuracy: 0.7317 - val_loss: 3.3720 - val_sparse_categorical_accuracy: 0.3653\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 206us/step - loss: 0.6847 - sparse_categorical_accuracy: 0.7361 - val_loss: 3.4217 - val_sparse_categorical_accuracy: 0.3663\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 205us/step - loss: 0.6913 - sparse_categorical_accuracy: 0.7347 - val_loss: 3.4408 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 221us/step - loss: 0.6838 - sparse_categorical_accuracy: 0.7370 - val_loss: 3.4736 - val_sparse_categorical_accuracy: 0.3657\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 6s 242us/step - loss: 0.6875 - sparse_categorical_accuracy: 0.7349 - val_loss: 3.4928 - val_sparse_categorical_accuracy: 0.3607\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 6s 225us/step - loss: 0.6758 - sparse_categorical_accuracy: 0.7407 - val_loss: 3.4264 - val_sparse_categorical_accuracy: 0.3627\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 6s 241us/step - loss: 0.6844 - sparse_categorical_accuracy: 0.7341 - val_loss: 3.6341 - val_sparse_categorical_accuracy: 0.3703\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 200us/step - loss: 0.6798 - sparse_categorical_accuracy: 0.7398 - val_loss: 3.5122 - val_sparse_categorical_accuracy: 0.3583\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 213us/step - loss: 0.6893 - sparse_categorical_accuracy: 0.7320 - val_loss: 3.5590 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 215us/step - loss: 0.6680 - sparse_categorical_accuracy: 0.7415 - val_loss: 3.6497 - val_sparse_categorical_accuracy: 0.3637\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 6s 236us/step - loss: 0.6758 - sparse_categorical_accuracy: 0.7406 - val_loss: 3.6963 - val_sparse_categorical_accuracy: 0.3627\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 192us/step - loss: 0.6812 - sparse_categorical_accuracy: 0.7355 - val_loss: 3.5163 - val_sparse_categorical_accuracy: 0.3553\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 6s 236us/step - loss: 0.6683 - sparse_categorical_accuracy: 0.7423 - val_loss: 3.5913 - val_sparse_categorical_accuracy: 0.3573\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 191us/step - loss: 0.6769 - sparse_categorical_accuracy: 0.7385 - val_loss: 3.5372 - val_sparse_categorical_accuracy: 0.3650\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 6s 233us/step - loss: 0.6614 - sparse_categorical_accuracy: 0.7441 - val_loss: 3.6474 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 215us/step - loss: 0.6762 - sparse_categorical_accuracy: 0.7385 - val_loss: 3.5805 - val_sparse_categorical_accuracy: 0.3583\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 212us/step - loss: 0.6657 - sparse_categorical_accuracy: 0.7417 - val_loss: 3.7080 - val_sparse_categorical_accuracy: 0.3670\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 6s 224us/step - loss: 0.6686 - sparse_categorical_accuracy: 0.7412 - val_loss: 3.6452 - val_sparse_categorical_accuracy: 0.3680\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 202us/step - loss: 0.6610 - sparse_categorical_accuracy: 0.7459 - val_loss: 3.7583 - val_sparse_categorical_accuracy: 0.3573\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 221us/step - loss: 0.6569 - sparse_categorical_accuracy: 0.7458 - val_loss: 3.6619 - val_sparse_categorical_accuracy: 0.3640\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 201us/step - loss: 0.6713 - sparse_categorical_accuracy: 0.7412 - val_loss: 3.6431 - val_sparse_categorical_accuracy: 0.3650\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 211us/step - loss: 0.6555 - sparse_categorical_accuracy: 0.7477 - val_loss: 3.7511 - val_sparse_categorical_accuracy: 0.3590\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 213us/step - loss: 0.6530 - sparse_categorical_accuracy: 0.7488 - val_loss: 3.5759 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 6s 233us/step - loss: 0.6565 - sparse_categorical_accuracy: 0.7474 - val_loss: 3.5892 - val_sparse_categorical_accuracy: 0.3677\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 217us/step - loss: 0.6641 - sparse_categorical_accuracy: 0.7442 - val_loss: 3.7679 - val_sparse_categorical_accuracy: 0.3527\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 7s 282us/step - loss: 0.6645 - sparse_categorical_accuracy: 0.7433 - val_loss: 3.7978 - val_sparse_categorical_accuracy: 0.3643\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 6s 246us/step - loss: 0.6541 - sparse_categorical_accuracy: 0.7469 - val_loss: 3.7934 - val_sparse_categorical_accuracy: 0.3647\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 222us/step - loss: 0.6503 - sparse_categorical_accuracy: 0.7483 - val_loss: 3.8038 - val_sparse_categorical_accuracy: 0.3570\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 219us/step - loss: 0.6531 - sparse_categorical_accuracy: 0.7478 - val_loss: 3.8241 - val_sparse_categorical_accuracy: 0.3607\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 213us/step - loss: 0.6438 - sparse_categorical_accuracy: 0.7490 - val_loss: 3.8095 - val_sparse_categorical_accuracy: 0.3697\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    history13 = model13.fit(X_train_cnn, Y_train_cnn, epochs=10, batch_size=32, validation_data = (X_dev_cnn, Y_dev_cnn))\n",
    "    history13_all.append(history13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 6s 254us/step - loss: 0.6526 - sparse_categorical_accuracy: 0.7458 - val_loss: 3.8604 - val_sparse_categorical_accuracy: 0.3460\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 6s 241us/step - loss: 0.6405 - sparse_categorical_accuracy: 0.7510 - val_loss: 3.9844 - val_sparse_categorical_accuracy: 0.3620\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 6s 244us/step - loss: 0.6429 - sparse_categorical_accuracy: 0.7508 - val_loss: 3.8931 - val_sparse_categorical_accuracy: 0.3573\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 214us/step - loss: 0.6501 - sparse_categorical_accuracy: 0.7488 - val_loss: 3.8619 - val_sparse_categorical_accuracy: 0.3510\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 6s 235us/step - loss: 0.6430 - sparse_categorical_accuracy: 0.7498 - val_loss: 3.8486 - val_sparse_categorical_accuracy: 0.3563\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 217us/step - loss: 0.6503 - sparse_categorical_accuracy: 0.7459 - val_loss: 3.7981 - val_sparse_categorical_accuracy: 0.3700\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 196us/step - loss: 0.6371 - sparse_categorical_accuracy: 0.7536 - val_loss: 3.9689 - val_sparse_categorical_accuracy: 0.3573\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 217us/step - loss: 0.6486 - sparse_categorical_accuracy: 0.7506 - val_loss: 3.8066 - val_sparse_categorical_accuracy: 0.3587\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 217us/step - loss: 0.6261 - sparse_categorical_accuracy: 0.7579 - val_loss: 3.9476 - val_sparse_categorical_accuracy: 0.3620\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 203us/step - loss: 0.6416 - sparse_categorical_accuracy: 0.7499 - val_loss: 4.0157 - val_sparse_categorical_accuracy: 0.3530\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 211us/step - loss: 0.6422 - sparse_categorical_accuracy: 0.7540 - val_loss: 3.9977 - val_sparse_categorical_accuracy: 0.3620\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 201us/step - loss: 0.6525 - sparse_categorical_accuracy: 0.7452 - val_loss: 3.9781 - val_sparse_categorical_accuracy: 0.3570\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 6s 251us/step - loss: 0.6277 - sparse_categorical_accuracy: 0.7562 - val_loss: 3.8616 - val_sparse_categorical_accuracy: 0.3547\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 6s 224us/step - loss: 0.6409 - sparse_categorical_accuracy: 0.7555 - val_loss: 3.9676 - val_sparse_categorical_accuracy: 0.3537\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 6s 260us/step - loss: 0.6353 - sparse_categorical_accuracy: 0.7560 - val_loss: 4.0276 - val_sparse_categorical_accuracy: 0.3597\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 8s 323us/step - loss: 0.6258 - sparse_categorical_accuracy: 0.7595 - val_loss: 4.0143 - val_sparse_categorical_accuracy: 0.3617\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 6s 251us/step - loss: 0.6273 - sparse_categorical_accuracy: 0.7551 - val_loss: 3.9189 - val_sparse_categorical_accuracy: 0.3587\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 200us/step - loss: 0.6310 - sparse_categorical_accuracy: 0.7570 - val_loss: 4.0079 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 212us/step - loss: 0.6315 - sparse_categorical_accuracy: 0.7556 - val_loss: 4.0256 - val_sparse_categorical_accuracy: 0.3667\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 204us/step - loss: 0.6255 - sparse_categorical_accuracy: 0.7581 - val_loss: 4.0493 - val_sparse_categorical_accuracy: 0.3590\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 217us/step - loss: 0.6416 - sparse_categorical_accuracy: 0.7523 - val_loss: 3.9606 - val_sparse_categorical_accuracy: 0.3590\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 190us/step - loss: 0.6265 - sparse_categorical_accuracy: 0.7580 - val_loss: 4.1790 - val_sparse_categorical_accuracy: 0.3610\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 210us/step - loss: 0.6212 - sparse_categorical_accuracy: 0.7603 - val_loss: 4.0857 - val_sparse_categorical_accuracy: 0.3607\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 187us/step - loss: 0.6300 - sparse_categorical_accuracy: 0.7532 - val_loss: 4.3073 - val_sparse_categorical_accuracy: 0.3630\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 185us/step - loss: 0.6257 - sparse_categorical_accuracy: 0.7589 - val_loss: 4.0862 - val_sparse_categorical_accuracy: 0.3627\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 197us/step - loss: 0.6232 - sparse_categorical_accuracy: 0.7577 - val_loss: 4.0558 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 190us/step - loss: 0.6202 - sparse_categorical_accuracy: 0.7603 - val_loss: 4.0310 - val_sparse_categorical_accuracy: 0.3630\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 192us/step - loss: 0.6248 - sparse_categorical_accuracy: 0.7577 - val_loss: 4.0618 - val_sparse_categorical_accuracy: 0.3687\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 6s 233us/step - loss: 0.6201 - sparse_categorical_accuracy: 0.7615 - val_loss: 4.1478 - val_sparse_categorical_accuracy: 0.3610\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 206us/step - loss: 0.6156 - sparse_categorical_accuracy: 0.7615 - val_loss: 4.1852 - val_sparse_categorical_accuracy: 0.3647\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 201us/step - loss: 0.6167 - sparse_categorical_accuracy: 0.7616 - val_loss: 4.0971 - val_sparse_categorical_accuracy: 0.3457\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 221us/step - loss: 0.6209 - sparse_categorical_accuracy: 0.7613 - val_loss: 4.1239 - val_sparse_categorical_accuracy: 0.3630\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 211us/step - loss: 0.6157 - sparse_categorical_accuracy: 0.7635 - val_loss: 4.2576 - val_sparse_categorical_accuracy: 0.3583\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 6s 242us/step - loss: 0.6195 - sparse_categorical_accuracy: 0.7596 - val_loss: 4.3416 - val_sparse_categorical_accuracy: 0.3567\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 190us/step - loss: 0.6121 - sparse_categorical_accuracy: 0.7609 - val_loss: 4.3438 - val_sparse_categorical_accuracy: 0.3617\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 216us/step - loss: 0.6117 - sparse_categorical_accuracy: 0.7616 - val_loss: 4.3175 - val_sparse_categorical_accuracy: 0.3587\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 6s 228us/step - loss: 0.6103 - sparse_categorical_accuracy: 0.7634 - val_loss: 4.3805 - val_sparse_categorical_accuracy: 0.3457\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 6s 225us/step - loss: 0.6090 - sparse_categorical_accuracy: 0.7630 - val_loss: 4.1715 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 196us/step - loss: 0.6065 - sparse_categorical_accuracy: 0.7660 - val_loss: 4.2879 - val_sparse_categorical_accuracy: 0.3627\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 198us/step - loss: 0.6142 - sparse_categorical_accuracy: 0.7606 - val_loss: 4.1343 - val_sparse_categorical_accuracy: 0.3550\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 199us/step - loss: 0.6152 - sparse_categorical_accuracy: 0.7615 - val_loss: 4.3127 - val_sparse_categorical_accuracy: 0.3650\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 6s 236us/step - loss: 0.6224 - sparse_categorical_accuracy: 0.7596 - val_loss: 4.3470 - val_sparse_categorical_accuracy: 0.3660\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 210us/step - loss: 0.5972 - sparse_categorical_accuracy: 0.7694 - val_loss: 4.2862 - val_sparse_categorical_accuracy: 0.3577\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 6s 225us/step - loss: 0.6022 - sparse_categorical_accuracy: 0.7674 - val_loss: 4.3272 - val_sparse_categorical_accuracy: 0.3553\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 6s 235us/step - loss: 0.6072 - sparse_categorical_accuracy: 0.7666 - val_loss: 4.3103 - val_sparse_categorical_accuracy: 0.3440\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 6s 237us/step - loss: 0.6108 - sparse_categorical_accuracy: 0.7656 - val_loss: 4.4487 - val_sparse_categorical_accuracy: 0.3657\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 220us/step - loss: 0.6071 - sparse_categorical_accuracy: 0.7657 - val_loss: 4.4690 - val_sparse_categorical_accuracy: 0.3647\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 6s 227us/step - loss: 0.5976 - sparse_categorical_accuracy: 0.7702 - val_loss: 4.3445 - val_sparse_categorical_accuracy: 0.3563\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 206us/step - loss: 0.6102 - sparse_categorical_accuracy: 0.7666 - val_loss: 4.3380 - val_sparse_categorical_accuracy: 0.3620\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 219us/step - loss: 0.6007 - sparse_categorical_accuracy: 0.7690 - val_loss: 4.5452 - val_sparse_categorical_accuracy: 0.3640\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 214us/step - loss: 0.5930 - sparse_categorical_accuracy: 0.7707 - val_loss: 4.2367 - val_sparse_categorical_accuracy: 0.3390\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 207us/step - loss: 0.6061 - sparse_categorical_accuracy: 0.7640 - val_loss: 4.3230 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 196us/step - loss: 0.5986 - sparse_categorical_accuracy: 0.7679 - val_loss: 4.3982 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 215us/step - loss: 0.5898 - sparse_categorical_accuracy: 0.7705 - val_loss: 4.3536 - val_sparse_categorical_accuracy: 0.3500\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 215us/step - loss: 0.5992 - sparse_categorical_accuracy: 0.7667 - val_loss: 4.5325 - val_sparse_categorical_accuracy: 0.3667\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 212us/step - loss: 0.5992 - sparse_categorical_accuracy: 0.7671 - val_loss: 4.3817 - val_sparse_categorical_accuracy: 0.3587\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 219us/step - loss: 0.5949 - sparse_categorical_accuracy: 0.7700 - val_loss: 4.4933 - val_sparse_categorical_accuracy: 0.3613\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 223us/step - loss: 0.6024 - sparse_categorical_accuracy: 0.7668 - val_loss: 4.4539 - val_sparse_categorical_accuracy: 0.3600\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 7s 297us/step - loss: 0.6029 - sparse_categorical_accuracy: 0.7672 - val_loss: 4.5201 - val_sparse_categorical_accuracy: 0.3553\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 7s 278us/step - loss: 0.5880 - sparse_categorical_accuracy: 0.7751 - val_loss: 4.3889 - val_sparse_categorical_accuracy: 0.3533\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 184us/step - loss: 0.5846 - sparse_categorical_accuracy: 0.7736 - val_loss: 4.6254 - val_sparse_categorical_accuracy: 0.3583\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 205us/step - loss: 0.5956 - sparse_categorical_accuracy: 0.7695 - val_loss: 4.3841 - val_sparse_categorical_accuracy: 0.3547\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 218us/step - loss: 0.5808 - sparse_categorical_accuracy: 0.7746 - val_loss: 4.5920 - val_sparse_categorical_accuracy: 0.3643\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 204us/step - loss: 0.5840 - sparse_categorical_accuracy: 0.7734 - val_loss: 4.5506 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 6s 228us/step - loss: 0.5922 - sparse_categorical_accuracy: 0.7698 - val_loss: 4.5864 - val_sparse_categorical_accuracy: 0.3657\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 208us/step - loss: 0.5927 - sparse_categorical_accuracy: 0.7726 - val_loss: 4.5295 - val_sparse_categorical_accuracy: 0.3550\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 203us/step - loss: 0.5877 - sparse_categorical_accuracy: 0.7737 - val_loss: 4.5853 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 193us/step - loss: 0.5769 - sparse_categorical_accuracy: 0.7755 - val_loss: 4.6746 - val_sparse_categorical_accuracy: 0.3517\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 6s 228us/step - loss: 0.5831 - sparse_categorical_accuracy: 0.7773 - val_loss: 4.5382 - val_sparse_categorical_accuracy: 0.3563\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 201us/step - loss: 0.5773 - sparse_categorical_accuracy: 0.7780 - val_loss: 4.5412 - val_sparse_categorical_accuracy: 0.3537\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 196us/step - loss: 0.5877 - sparse_categorical_accuracy: 0.7723 - val_loss: 4.6162 - val_sparse_categorical_accuracy: 0.3487\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 6s 232us/step - loss: 0.5871 - sparse_categorical_accuracy: 0.7747 - val_loss: 4.6086 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 6s 243us/step - loss: 0.5870 - sparse_categorical_accuracy: 0.7735 - val_loss: 4.5379 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 6s 227us/step - loss: 0.5786 - sparse_categorical_accuracy: 0.7749 - val_loss: 4.6211 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 6s 229us/step - loss: 0.5713 - sparse_categorical_accuracy: 0.7783 - val_loss: 4.8234 - val_sparse_categorical_accuracy: 0.3653\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 220us/step - loss: 0.5812 - sparse_categorical_accuracy: 0.7747 - val_loss: 4.6093 - val_sparse_categorical_accuracy: 0.3617\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 209us/step - loss: 0.5783 - sparse_categorical_accuracy: 0.7767 - val_loss: 4.7423 - val_sparse_categorical_accuracy: 0.3707\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 198us/step - loss: 0.5734 - sparse_categorical_accuracy: 0.7773 - val_loss: 4.7279 - val_sparse_categorical_accuracy: 0.3513\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 202us/step - loss: 0.5861 - sparse_categorical_accuracy: 0.7730 - val_loss: 4.8046 - val_sparse_categorical_accuracy: 0.3480\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 206us/step - loss: 0.5912 - sparse_categorical_accuracy: 0.7696 - val_loss: 4.6454 - val_sparse_categorical_accuracy: 0.3487\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 207us/step - loss: 0.5733 - sparse_categorical_accuracy: 0.7786 - val_loss: 4.7112 - val_sparse_categorical_accuracy: 0.3630\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 216us/step - loss: 0.5633 - sparse_categorical_accuracy: 0.7822 - val_loss: 4.6100 - val_sparse_categorical_accuracy: 0.3643\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 6s 246us/step - loss: 0.5732 - sparse_categorical_accuracy: 0.7792 - val_loss: 4.7750 - val_sparse_categorical_accuracy: 0.3653\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 211us/step - loss: 0.5810 - sparse_categorical_accuracy: 0.7771 - val_loss: 4.6406 - val_sparse_categorical_accuracy: 0.3537\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 9s 345us/step - loss: 0.5795 - sparse_categorical_accuracy: 0.7810 - val_loss: 4.7860 - val_sparse_categorical_accuracy: 0.3663\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 7s 284us/step - loss: 0.5594 - sparse_categorical_accuracy: 0.7848 - val_loss: 4.7897 - val_sparse_categorical_accuracy: 0.3520\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 208us/step - loss: 0.5793 - sparse_categorical_accuracy: 0.7781 - val_loss: 4.6601 - val_sparse_categorical_accuracy: 0.3657\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 6s 238us/step - loss: 0.5670 - sparse_categorical_accuracy: 0.7795 - val_loss: 4.6857 - val_sparse_categorical_accuracy: 0.3690\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 196us/step - loss: 0.5744 - sparse_categorical_accuracy: 0.7800 - val_loss: 4.8203 - val_sparse_categorical_accuracy: 0.3650\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 222us/step - loss: 0.5648 - sparse_categorical_accuracy: 0.7816 - val_loss: 4.9637 - val_sparse_categorical_accuracy: 0.3477\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 192us/step - loss: 0.5707 - sparse_categorical_accuracy: 0.7825 - val_loss: 4.6743 - val_sparse_categorical_accuracy: 0.3567\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 201us/step - loss: 0.5727 - sparse_categorical_accuracy: 0.7783 - val_loss: 4.7324 - val_sparse_categorical_accuracy: 0.3403\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 197us/step - loss: 0.5637 - sparse_categorical_accuracy: 0.7828 - val_loss: 4.7632 - val_sparse_categorical_accuracy: 0.3563\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 218us/step - loss: 0.5662 - sparse_categorical_accuracy: 0.7821 - val_loss: 4.8887 - val_sparse_categorical_accuracy: 0.3563\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 192us/step - loss: 0.5668 - sparse_categorical_accuracy: 0.7827 - val_loss: 5.0646 - val_sparse_categorical_accuracy: 0.3707\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 210us/step - loss: 0.5694 - sparse_categorical_accuracy: 0.7837 - val_loss: 4.7946 - val_sparse_categorical_accuracy: 0.3460\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 6s 224us/step - loss: 0.5474 - sparse_categorical_accuracy: 0.7896 - val_loss: 5.0436 - val_sparse_categorical_accuracy: 0.3497\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 6s 224us/step - loss: 0.5626 - sparse_categorical_accuracy: 0.7833 - val_loss: 4.7909 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 6s 224us/step - loss: 0.5665 - sparse_categorical_accuracy: 0.7840 - val_loss: 4.9561 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 201us/step - loss: 0.5615 - sparse_categorical_accuracy: 0.7816 - val_loss: 4.7880 - val_sparse_categorical_accuracy: 0.3600\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    history13 = model13.fit(X_train_cnn, Y_train_cnn, epochs=10, batch_size=32, validation_data = (X_dev_cnn, Y_dev_cnn))\n",
    "    history13_all.append(history13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 7s 269us/step - loss: 0.5635 - sparse_categorical_accuracy: 0.7835 - val_loss: 4.9909 - val_sparse_categorical_accuracy: 0.3700\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 8s 319us/step - loss: 0.5696 - sparse_categorical_accuracy: 0.7810 - val_loss: 4.7726 - val_sparse_categorical_accuracy: 0.3687\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 6s 244us/step - loss: 0.5607 - sparse_categorical_accuracy: 0.7861 - val_loss: 4.8519 - val_sparse_categorical_accuracy: 0.3567\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 208us/step - loss: 0.5626 - sparse_categorical_accuracy: 0.7818 - val_loss: 5.1971 - val_sparse_categorical_accuracy: 0.3527\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 186us/step - loss: 0.5586 - sparse_categorical_accuracy: 0.7835 - val_loss: 5.0055 - val_sparse_categorical_accuracy: 0.3567\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 195us/step - loss: 0.5590 - sparse_categorical_accuracy: 0.7872 - val_loss: 5.0803 - val_sparse_categorical_accuracy: 0.3560\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 196us/step - loss: 0.5556 - sparse_categorical_accuracy: 0.7861 - val_loss: 4.9371 - val_sparse_categorical_accuracy: 0.3527\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 214us/step - loss: 0.5620 - sparse_categorical_accuracy: 0.7828 - val_loss: 5.1016 - val_sparse_categorical_accuracy: 0.3457\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 186us/step - loss: 0.5618 - sparse_categorical_accuracy: 0.7829 - val_loss: 4.8859 - val_sparse_categorical_accuracy: 0.3577\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 196us/step - loss: 0.5560 - sparse_categorical_accuracy: 0.7850 - val_loss: 4.9336 - val_sparse_categorical_accuracy: 0.3523\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 217us/step - loss: 0.5795 - sparse_categorical_accuracy: 0.7791 - val_loss: 5.0045 - val_sparse_categorical_accuracy: 0.3527\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 217us/step - loss: 0.5495 - sparse_categorical_accuracy: 0.7914 - val_loss: 4.9783 - val_sparse_categorical_accuracy: 0.3427\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 199us/step - loss: 0.5591 - sparse_categorical_accuracy: 0.7830 - val_loss: 5.0141 - val_sparse_categorical_accuracy: 0.3560\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 215us/step - loss: 0.5585 - sparse_categorical_accuracy: 0.7834 - val_loss: 4.9393 - val_sparse_categorical_accuracy: 0.3570\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 202us/step - loss: 0.5472 - sparse_categorical_accuracy: 0.7868 - val_loss: 4.9573 - val_sparse_categorical_accuracy: 0.3600\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 201us/step - loss: 0.5492 - sparse_categorical_accuracy: 0.7892 - val_loss: 4.9176 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 203us/step - loss: 0.5614 - sparse_categorical_accuracy: 0.7817 - val_loss: 5.0213 - val_sparse_categorical_accuracy: 0.3423\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 219us/step - loss: 0.5452 - sparse_categorical_accuracy: 0.7917 - val_loss: 4.8629 - val_sparse_categorical_accuracy: 0.3550\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 203us/step - loss: 0.5517 - sparse_categorical_accuracy: 0.7911 - val_loss: 5.1685 - val_sparse_categorical_accuracy: 0.3590\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 6s 242us/step - loss: 0.5536 - sparse_categorical_accuracy: 0.7900 - val_loss: 5.1964 - val_sparse_categorical_accuracy: 0.3537\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 6s 225us/step - loss: 0.5425 - sparse_categorical_accuracy: 0.7920 - val_loss: 5.1871 - val_sparse_categorical_accuracy: 0.3523\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 6s 254us/step - loss: 0.5506 - sparse_categorical_accuracy: 0.7892 - val_loss: 5.0747 - val_sparse_categorical_accuracy: 0.3523\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 6s 252us/step - loss: 0.5570 - sparse_categorical_accuracy: 0.7855 - val_loss: 5.1288 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 7s 270us/step - loss: 0.5420 - sparse_categorical_accuracy: 0.7911 - val_loss: 5.2337 - val_sparse_categorical_accuracy: 0.3510\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 6s 250us/step - loss: 0.5423 - sparse_categorical_accuracy: 0.7906 - val_loss: 5.4073 - val_sparse_categorical_accuracy: 0.3493\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 6s 223us/step - loss: 0.5680 - sparse_categorical_accuracy: 0.7840 - val_loss: 5.1689 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 210us/step - loss: 0.5513 - sparse_categorical_accuracy: 0.7873 - val_loss: 5.1020 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 189us/step - loss: 0.5426 - sparse_categorical_accuracy: 0.7903 - val_loss: 5.2103 - val_sparse_categorical_accuracy: 0.3527\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 6s 228us/step - loss: 0.5437 - sparse_categorical_accuracy: 0.7928 - val_loss: 5.1481 - val_sparse_categorical_accuracy: 0.3610\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 218us/step - loss: 0.5406 - sparse_categorical_accuracy: 0.7877 - val_loss: 5.0916 - val_sparse_categorical_accuracy: 0.3560\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 206us/step - loss: 0.5491 - sparse_categorical_accuracy: 0.7886 - val_loss: 5.1799 - val_sparse_categorical_accuracy: 0.3530\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 202us/step - loss: 0.5500 - sparse_categorical_accuracy: 0.7887 - val_loss: 5.2725 - val_sparse_categorical_accuracy: 0.3447\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 198us/step - loss: 0.5403 - sparse_categorical_accuracy: 0.7944 - val_loss: 5.0914 - val_sparse_categorical_accuracy: 0.3463\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 213us/step - loss: 0.5479 - sparse_categorical_accuracy: 0.7891 - val_loss: 5.2823 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 192us/step - loss: 0.5502 - sparse_categorical_accuracy: 0.7900 - val_loss: 5.1934 - val_sparse_categorical_accuracy: 0.3530\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 210us/step - loss: 0.5394 - sparse_categorical_accuracy: 0.7908 - val_loss: 5.2570 - val_sparse_categorical_accuracy: 0.3560\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 207us/step - loss: 0.5408 - sparse_categorical_accuracy: 0.7896 - val_loss: 5.2626 - val_sparse_categorical_accuracy: 0.3493\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 196us/step - loss: 0.5512 - sparse_categorical_accuracy: 0.7905 - val_loss: 5.3484 - val_sparse_categorical_accuracy: 0.3590\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 197us/step - loss: 0.5543 - sparse_categorical_accuracy: 0.7864 - val_loss: 5.2172 - val_sparse_categorical_accuracy: 0.3500\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 189us/step - loss: 0.5315 - sparse_categorical_accuracy: 0.7961 - val_loss: 5.2427 - val_sparse_categorical_accuracy: 0.3620\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 6s 224us/step - loss: 0.5382 - sparse_categorical_accuracy: 0.7934 - val_loss: 5.3030 - val_sparse_categorical_accuracy: 0.3590\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 192us/step - loss: 0.5506 - sparse_categorical_accuracy: 0.7870 - val_loss: 5.2981 - val_sparse_categorical_accuracy: 0.3523\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 220us/step - loss: 0.5351 - sparse_categorical_accuracy: 0.7939 - val_loss: 5.3203 - val_sparse_categorical_accuracy: 0.3470\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 197us/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7913 - val_loss: 5.4340 - val_sparse_categorical_accuracy: 0.3430\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 199us/step - loss: 0.5403 - sparse_categorical_accuracy: 0.7946 - val_loss: 5.5120 - val_sparse_categorical_accuracy: 0.3453\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 195us/step - loss: 0.5312 - sparse_categorical_accuracy: 0.7937 - val_loss: 5.2636 - val_sparse_categorical_accuracy: 0.3467\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 211us/step - loss: 0.5454 - sparse_categorical_accuracy: 0.7933 - val_loss: 5.4001 - val_sparse_categorical_accuracy: 0.3563\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 184us/step - loss: 0.5397 - sparse_categorical_accuracy: 0.7922 - val_loss: 5.5976 - val_sparse_categorical_accuracy: 0.3523\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 213us/step - loss: 0.5350 - sparse_categorical_accuracy: 0.7933 - val_loss: 5.1287 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 201us/step - loss: 0.5354 - sparse_categorical_accuracy: 0.7907 - val_loss: 5.3954 - val_sparse_categorical_accuracy: 0.3633\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 215us/step - loss: 0.5449 - sparse_categorical_accuracy: 0.7920 - val_loss: 5.2226 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 6s 241us/step - loss: 0.5283 - sparse_categorical_accuracy: 0.7959 - val_loss: 5.3488 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 6s 232us/step - loss: 0.5460 - sparse_categorical_accuracy: 0.7910 - val_loss: 5.3111 - val_sparse_categorical_accuracy: 0.3533\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 7s 279us/step - loss: 0.5294 - sparse_categorical_accuracy: 0.7972 - val_loss: 5.4025 - val_sparse_categorical_accuracy: 0.3523\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 7s 282us/step - loss: 0.5574 - sparse_categorical_accuracy: 0.7877 - val_loss: 5.3297 - val_sparse_categorical_accuracy: 0.3490\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 202us/step - loss: 0.5339 - sparse_categorical_accuracy: 0.7982 - val_loss: 5.5091 - val_sparse_categorical_accuracy: 0.3583\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 207us/step - loss: 0.5222 - sparse_categorical_accuracy: 0.7980 - val_loss: 5.4891 - val_sparse_categorical_accuracy: 0.3480\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 207us/step - loss: 0.5233 - sparse_categorical_accuracy: 0.7996 - val_loss: 5.5463 - val_sparse_categorical_accuracy: 0.3530\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 223us/step - loss: 0.5398 - sparse_categorical_accuracy: 0.7942 - val_loss: 5.4482 - val_sparse_categorical_accuracy: 0.3537\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 214us/step - loss: 0.5487 - sparse_categorical_accuracy: 0.7892 - val_loss: 5.3950 - val_sparse_categorical_accuracy: 0.3540\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 202us/step - loss: 0.5267 - sparse_categorical_accuracy: 0.7981 - val_loss: 5.4840 - val_sparse_categorical_accuracy: 0.3443\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 218us/step - loss: 0.5342 - sparse_categorical_accuracy: 0.7959 - val_loss: 5.4734 - val_sparse_categorical_accuracy: 0.3550\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 217us/step - loss: 0.5352 - sparse_categorical_accuracy: 0.7960 - val_loss: 5.4791 - val_sparse_categorical_accuracy: 0.3610\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 193us/step - loss: 0.5197 - sparse_categorical_accuracy: 0.8000 - val_loss: 5.3572 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 202us/step - loss: 0.5454 - sparse_categorical_accuracy: 0.7923 - val_loss: 5.3320 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 203us/step - loss: 0.5234 - sparse_categorical_accuracy: 0.7984 - val_loss: 5.3943 - val_sparse_categorical_accuracy: 0.3547\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 195us/step - loss: 0.5327 - sparse_categorical_accuracy: 0.7937 - val_loss: 5.4946 - val_sparse_categorical_accuracy: 0.3587\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 206us/step - loss: 0.5334 - sparse_categorical_accuracy: 0.7971 - val_loss: 5.5950 - val_sparse_categorical_accuracy: 0.3480\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 208us/step - loss: 0.5277 - sparse_categorical_accuracy: 0.7992 - val_loss: 5.4859 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 212us/step - loss: 0.5226 - sparse_categorical_accuracy: 0.7999 - val_loss: 5.5792 - val_sparse_categorical_accuracy: 0.3577\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 203us/step - loss: 0.5304 - sparse_categorical_accuracy: 0.7963 - val_loss: 5.5233 - val_sparse_categorical_accuracy: 0.3610\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 205us/step - loss: 0.5147 - sparse_categorical_accuracy: 0.8042 - val_loss: 5.3441 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 190us/step - loss: 0.5305 - sparse_categorical_accuracy: 0.7964 - val_loss: 5.5440 - val_sparse_categorical_accuracy: 0.3597\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 207us/step - loss: 0.5269 - sparse_categorical_accuracy: 0.7970 - val_loss: 5.5749 - val_sparse_categorical_accuracy: 0.3587\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 210us/step - loss: 0.5307 - sparse_categorical_accuracy: 0.7965 - val_loss: 5.6996 - val_sparse_categorical_accuracy: 0.3527\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 205us/step - loss: 0.5248 - sparse_categorical_accuracy: 0.8008 - val_loss: 5.6937 - val_sparse_categorical_accuracy: 0.3527\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 202us/step - loss: 0.5215 - sparse_categorical_accuracy: 0.8010 - val_loss: 5.6511 - val_sparse_categorical_accuracy: 0.3510\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 6s 236us/step - loss: 0.5236 - sparse_categorical_accuracy: 0.8006 - val_loss: 5.6372 - val_sparse_categorical_accuracy: 0.3447\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 204us/step - loss: 0.5295 - sparse_categorical_accuracy: 0.7977 - val_loss: 5.6223 - val_sparse_categorical_accuracy: 0.3560\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 204us/step - loss: 0.5231 - sparse_categorical_accuracy: 0.7979 - val_loss: 5.8452 - val_sparse_categorical_accuracy: 0.3433\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 6s 227us/step - loss: 0.5207 - sparse_categorical_accuracy: 0.7989 - val_loss: 5.5738 - val_sparse_categorical_accuracy: 0.3537\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 215us/step - loss: 0.5179 - sparse_categorical_accuracy: 0.7985 - val_loss: 5.6998 - val_sparse_categorical_accuracy: 0.3433\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 5s 188us/step - loss: 0.5253 - sparse_categorical_accuracy: 0.7994 - val_loss: 5.6985 - val_sparse_categorical_accuracy: 0.3490\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 186us/step - loss: 0.5286 - sparse_categorical_accuracy: 0.8012 - val_loss: 5.6989 - val_sparse_categorical_accuracy: 0.3523\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 215us/step - loss: 0.5228 - sparse_categorical_accuracy: 0.8015 - val_loss: 5.6746 - val_sparse_categorical_accuracy: 0.3530\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 221us/step - loss: 0.5138 - sparse_categorical_accuracy: 0.8013 - val_loss: 5.6971 - val_sparse_categorical_accuracy: 0.3470\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 216us/step - loss: 0.5198 - sparse_categorical_accuracy: 0.8025 - val_loss: 5.7392 - val_sparse_categorical_accuracy: 0.3470\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 206us/step - loss: 0.5318 - sparse_categorical_accuracy: 0.7981 - val_loss: 5.7570 - val_sparse_categorical_accuracy: 0.3587\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 203us/step - loss: 0.5140 - sparse_categorical_accuracy: 0.8022 - val_loss: 5.6938 - val_sparse_categorical_accuracy: 0.3537\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 6s 226us/step - loss: 0.5355 - sparse_categorical_accuracy: 0.7965 - val_loss: 5.7499 - val_sparse_categorical_accuracy: 0.3443\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 5s 213us/step - loss: 0.5109 - sparse_categorical_accuracy: 0.8038 - val_loss: 5.7564 - val_sparse_categorical_accuracy: 0.3553\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 5s 214us/step - loss: 0.5245 - sparse_categorical_accuracy: 0.7998 - val_loss: 5.9617 - val_sparse_categorical_accuracy: 0.3667\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 6s 237us/step - loss: 0.5244 - sparse_categorical_accuracy: 0.8023 - val_loss: 5.7412 - val_sparse_categorical_accuracy: 0.3610\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 5s 201us/step - loss: 0.5029 - sparse_categorical_accuracy: 0.8058 - val_loss: 5.8416 - val_sparse_categorical_accuracy: 0.3480\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 5s 209us/step - loss: 0.5189 - sparse_categorical_accuracy: 0.8014 - val_loss: 5.8615 - val_sparse_categorical_accuracy: 0.3507\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 5s 202us/step - loss: 0.5127 - sparse_categorical_accuracy: 0.8047 - val_loss: 5.8593 - val_sparse_categorical_accuracy: 0.3500\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 5s 208us/step - loss: 0.5186 - sparse_categorical_accuracy: 0.8006 - val_loss: 5.8887 - val_sparse_categorical_accuracy: 0.3487\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 5s 199us/step - loss: 0.5165 - sparse_categorical_accuracy: 0.8004 - val_loss: 5.7263 - val_sparse_categorical_accuracy: 0.3427\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 5s 194us/step - loss: 0.5165 - sparse_categorical_accuracy: 0.8023 - val_loss: 5.8722 - val_sparse_categorical_accuracy: 0.3383\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 5s 208us/step - loss: 0.5275 - sparse_categorical_accuracy: 0.7989 - val_loss: 5.7665 - val_sparse_categorical_accuracy: 0.3393\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    history13 = model13.fit(X_train_cnn, Y_train_cnn, epochs=10, batch_size=32, validation_data = (X_dev_cnn, Y_dev_cnn))\n",
    "    history13_all.append(history13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 14: deeper CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 11, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 18, 64)        102464    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 18, 32)        51232     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6336)              0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 32)                202784    \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 16)                528       \n",
      "=================================================================\n",
      "Total params: 393,936\n",
      "Trainable params: 393,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model14 = Sequential()\n",
    "model14.add(Conv2D(64, kernel_size=8, padding = 'same', activation='relu', input_shape=(11, 18, 9), kernel_initializer='glorot_normal'))\n",
    "model14.add(Conv2D(64, kernel_size=5, padding = 'same', activation='relu', kernel_initializer='glorot_normal'))\n",
    "model14.add(Conv2D(32, kernel_size=5, padding = 'same', activation='relu', kernel_initializer='glorot_normal'))\n",
    "model14.add(Flatten())\n",
    "model14.add(Dense(32, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model14.add(Dense(16, activation='softmax', kernel_initializer='he_normal'))\n",
    "model14.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "print(model14.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "history14_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 67s 3ms/step - loss: 1.7109 - sparse_categorical_accuracy: 0.3693 - val_loss: 1.6609 - val_sparse_categorical_accuracy: 0.3633\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 71s 3ms/step - loss: 1.5495 - sparse_categorical_accuracy: 0.3997 - val_loss: 1.4953 - val_sparse_categorical_accuracy: 0.4220\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 73s 3ms/step - loss: 1.5088 - sparse_categorical_accuracy: 0.4117 - val_loss: 1.5863 - val_sparse_categorical_accuracy: 0.3967\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 73s 3ms/step - loss: 1.4802 - sparse_categorical_accuracy: 0.4205 - val_loss: 1.5487 - val_sparse_categorical_accuracy: 0.3860\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 69s 3ms/step - loss: 1.4506 - sparse_categorical_accuracy: 0.4268 - val_loss: 1.5200 - val_sparse_categorical_accuracy: 0.3957\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 67s 3ms/step - loss: 1.4298 - sparse_categorical_accuracy: 0.4368 - val_loss: 1.5104 - val_sparse_categorical_accuracy: 0.4107\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 65s 3ms/step - loss: 1.3999 - sparse_categorical_accuracy: 0.4458 - val_loss: 1.5339 - val_sparse_categorical_accuracy: 0.4057\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 65s 3ms/step - loss: 1.3562 - sparse_categorical_accuracy: 0.4663 - val_loss: 1.5309 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 66s 3ms/step - loss: 1.3136 - sparse_categorical_accuracy: 0.4825 - val_loss: 1.5675 - val_sparse_categorical_accuracy: 0.4033\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 75s 3ms/step - loss: 1.2697 - sparse_categorical_accuracy: 0.4981 - val_loss: 1.6288 - val_sparse_categorical_accuracy: 0.3887\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 69s 3ms/step - loss: 1.2080 - sparse_categorical_accuracy: 0.5217 - val_loss: 1.6347 - val_sparse_categorical_accuracy: 0.4083\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 64s 3ms/step - loss: 1.1439 - sparse_categorical_accuracy: 0.5531 - val_loss: 1.6872 - val_sparse_categorical_accuracy: 0.4033\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 66s 3ms/step - loss: 1.0787 - sparse_categorical_accuracy: 0.5770 - val_loss: 1.7796 - val_sparse_categorical_accuracy: 0.4040\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 66s 3ms/step - loss: 1.0020 - sparse_categorical_accuracy: 0.6083 - val_loss: 1.8881 - val_sparse_categorical_accuracy: 0.3777\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 68s 3ms/step - loss: 0.9286 - sparse_categorical_accuracy: 0.6432 - val_loss: 2.0086 - val_sparse_categorical_accuracy: 0.3773\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 71s 3ms/step - loss: 0.8570 - sparse_categorical_accuracy: 0.6718 - val_loss: 2.1681 - val_sparse_categorical_accuracy: 0.3857\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 70s 3ms/step - loss: 0.7933 - sparse_categorical_accuracy: 0.6958 - val_loss: 2.2240 - val_sparse_categorical_accuracy: 0.3727\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 68s 3ms/step - loss: 0.7300 - sparse_categorical_accuracy: 0.7188 - val_loss: 2.3175 - val_sparse_categorical_accuracy: 0.3823\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 68s 3ms/step - loss: 0.6700 - sparse_categorical_accuracy: 0.7449 - val_loss: 2.6016 - val_sparse_categorical_accuracy: 0.3657\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 66s 3ms/step - loss: 0.6153 - sparse_categorical_accuracy: 0.7662 - val_loss: 2.7280 - val_sparse_categorical_accuracy: 0.3590\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 67s 3ms/step - loss: 0.5667 - sparse_categorical_accuracy: 0.7853 - val_loss: 2.9164 - val_sparse_categorical_accuracy: 0.3653\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 70s 3ms/step - loss: 0.5308 - sparse_categorical_accuracy: 0.8001 - val_loss: 3.1399 - val_sparse_categorical_accuracy: 0.3797\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 70s 3ms/step - loss: 0.4868 - sparse_categorical_accuracy: 0.8162 - val_loss: 3.2896 - val_sparse_categorical_accuracy: 0.3753\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 68s 3ms/step - loss: 0.4601 - sparse_categorical_accuracy: 0.8296 - val_loss: 3.3912 - val_sparse_categorical_accuracy: 0.3620\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 66s 3ms/step - loss: 0.4345 - sparse_categorical_accuracy: 0.8407 - val_loss: 3.6406 - val_sparse_categorical_accuracy: 0.3683\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 63s 3ms/step - loss: 0.4193 - sparse_categorical_accuracy: 0.8475 - val_loss: 3.8279 - val_sparse_categorical_accuracy: 0.3713\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 64s 3ms/step - loss: 0.3830 - sparse_categorical_accuracy: 0.8584 - val_loss: 4.2085 - val_sparse_categorical_accuracy: 0.3677\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 68s 3ms/step - loss: 0.3724 - sparse_categorical_accuracy: 0.8668 - val_loss: 4.1505 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 70s 3ms/step - loss: 0.3736 - sparse_categorical_accuracy: 0.8645 - val_loss: 3.9519 - val_sparse_categorical_accuracy: 0.3530\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 71s 3ms/step - loss: 0.3252 - sparse_categorical_accuracy: 0.8813 - val_loss: 4.5909 - val_sparse_categorical_accuracy: 0.3583\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 66s 3ms/step - loss: 0.3311 - sparse_categorical_accuracy: 0.8814 - val_loss: 4.4939 - val_sparse_categorical_accuracy: 0.3583\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 66s 3ms/step - loss: 0.3224 - sparse_categorical_accuracy: 0.8817 - val_loss: 4.4411 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 65s 3ms/step - loss: 0.3081 - sparse_categorical_accuracy: 0.8899 - val_loss: 4.8799 - val_sparse_categorical_accuracy: 0.3747\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 75s 3ms/step - loss: 0.2900 - sparse_categorical_accuracy: 0.8962 - val_loss: 4.8268 - val_sparse_categorical_accuracy: 0.3747\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 72s 3ms/step - loss: 0.2933 - sparse_categorical_accuracy: 0.8973 - val_loss: 4.8512 - val_sparse_categorical_accuracy: 0.3803\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 72s 3ms/step - loss: 0.2761 - sparse_categorical_accuracy: 0.9014 - val_loss: 5.3575 - val_sparse_categorical_accuracy: 0.3667\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 64s 3ms/step - loss: 0.2740 - sparse_categorical_accuracy: 0.9026 - val_loss: 5.2328 - val_sparse_categorical_accuracy: 0.3787\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 66s 3ms/step - loss: 0.2769 - sparse_categorical_accuracy: 0.9035 - val_loss: 5.2387 - val_sparse_categorical_accuracy: 0.3780\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 67s 3ms/step - loss: 0.2514 - sparse_categorical_accuracy: 0.9085 - val_loss: 5.1040 - val_sparse_categorical_accuracy: 0.3747\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 67s 3ms/step - loss: 0.2589 - sparse_categorical_accuracy: 0.9101 - val_loss: 5.4575 - val_sparse_categorical_accuracy: 0.3690\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 60s 2ms/step - loss: 0.2514 - sparse_categorical_accuracy: 0.9143 - val_loss: 5.6749 - val_sparse_categorical_accuracy: 0.3757\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 60s 2ms/step - loss: 0.2512 - sparse_categorical_accuracy: 0.9123 - val_loss: 5.3981 - val_sparse_categorical_accuracy: 0.3630\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 60s 2ms/step - loss: 0.2311 - sparse_categorical_accuracy: 0.9158 - val_loss: 5.6041 - val_sparse_categorical_accuracy: 0.3627\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 60s 2ms/step - loss: 0.2109 - sparse_categorical_accuracy: 0.9272 - val_loss: 5.9570 - val_sparse_categorical_accuracy: 0.3690\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 59s 2ms/step - loss: 0.2417 - sparse_categorical_accuracy: 0.9174 - val_loss: 5.6453 - val_sparse_categorical_accuracy: 0.3617\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 59s 2ms/step - loss: 0.2266 - sparse_categorical_accuracy: 0.9234 - val_loss: 5.8077 - val_sparse_categorical_accuracy: 0.3550\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 60s 2ms/step - loss: 0.2117 - sparse_categorical_accuracy: 0.9264 - val_loss: 5.5123 - val_sparse_categorical_accuracy: 0.3663\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 60s 2ms/step - loss: 0.2274 - sparse_categorical_accuracy: 0.9229 - val_loss: 5.7091 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 60s 2ms/step - loss: 0.2134 - sparse_categorical_accuracy: 0.9260 - val_loss: 6.2394 - val_sparse_categorical_accuracy: 0.3703\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 60s 2ms/step - loss: 0.2202 - sparse_categorical_accuracy: 0.9240 - val_loss: 6.2157 - val_sparse_categorical_accuracy: 0.3630\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 60s 2ms/step - loss: 0.1969 - sparse_categorical_accuracy: 0.9312 - val_loss: 6.2719 - val_sparse_categorical_accuracy: 0.3583\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 60s 2ms/step - loss: 0.1989 - sparse_categorical_accuracy: 0.9344 - val_loss: 6.3508 - val_sparse_categorical_accuracy: 0.3793\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 59s 2ms/step - loss: 0.1912 - sparse_categorical_accuracy: 0.9328 - val_loss: 6.6320 - val_sparse_categorical_accuracy: 0.3750\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 60s 2ms/step - loss: 0.2018 - sparse_categorical_accuracy: 0.9312 - val_loss: 6.3820 - val_sparse_categorical_accuracy: 0.3617\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 62s 3ms/step - loss: 0.1881 - sparse_categorical_accuracy: 0.9359 - val_loss: 6.2052 - val_sparse_categorical_accuracy: 0.3803\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 59s 2ms/step - loss: 0.1949 - sparse_categorical_accuracy: 0.9340 - val_loss: 6.3691 - val_sparse_categorical_accuracy: 0.3747\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 62s 2ms/step - loss: 0.1778 - sparse_categorical_accuracy: 0.9402 - val_loss: 6.4567 - val_sparse_categorical_accuracy: 0.3617\n",
      "Epoch 8/10\n",
      " 3040/24634 [==>...........................] - ETA: 1:03 - loss: 0.1360 - sparse_categorical_accuracy: 0.9507"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-91212a4c46e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mhistory14\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel14\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_dev_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_dev_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mhistory14_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    history14 = model14.fit(X_train_cnn, Y_train_cnn, epochs=10, batch_size=32, validation_data = (X_dev_cnn, Y_dev_cnn))\n",
    "    history14_all.append(history14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 15 RNN + dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_19 (Masking)         (None, 30, 10)            0         \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 16)                816       \n",
      "=================================================================\n",
      "Total params: 70,466\n",
      "Trainable params: 70,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model15 = Sequential()\n",
    "model15.add(Masking(mask_value=0., input_shape=(30, 10)))\n",
    "model15.add(LSTM(100, activation='relu', input_shape=(30, 10), kernel_initializer='glorot_normal'))\n",
    "model15.add(Dropout(0.2))\n",
    "model15.add(Dense(100, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model15.add(Dropout(0.2))\n",
    "model15.add(Dense(100, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model15.add(Dropout(0.2))\n",
    "model15.add(Dense(50, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model15.add(Dropout(0.2))\n",
    "model15.add(Dense(16, activation='softmax'))\n",
    "model15.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "print(model15.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "history15_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 24s 990us/step - loss: 1.7715 - sparse_categorical_accuracy: 0.3483 - val_loss: 1.5911 - val_sparse_categorical_accuracy: 0.3960\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 22s 883us/step - loss: 1.6022 - sparse_categorical_accuracy: 0.3881 - val_loss: 1.5665 - val_sparse_categorical_accuracy: 0.4003\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 20s 817us/step - loss: 1.5658 - sparse_categorical_accuracy: 0.3976 - val_loss: 1.5137 - val_sparse_categorical_accuracy: 0.4110\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 20s 828us/step - loss: 1.5463 - sparse_categorical_accuracy: 0.4016 - val_loss: 1.5339 - val_sparse_categorical_accuracy: 0.4063\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 20s 817us/step - loss: 1.5314 - sparse_categorical_accuracy: 0.4085 - val_loss: 1.5068 - val_sparse_categorical_accuracy: 0.4150\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 19s 789us/step - loss: 1.5238 - sparse_categorical_accuracy: 0.4096 - val_loss: 1.5015 - val_sparse_categorical_accuracy: 0.4100\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 21s 854us/step - loss: 1.5123 - sparse_categorical_accuracy: 0.4108 - val_loss: 1.4879 - val_sparse_categorical_accuracy: 0.4123\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 20s 831us/step - loss: 1.5043 - sparse_categorical_accuracy: 0.4126 - val_loss: 1.4872 - val_sparse_categorical_accuracy: 0.4133\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 21s 856us/step - loss: 1.4942 - sparse_categorical_accuracy: 0.4146 - val_loss: 1.4756 - val_sparse_categorical_accuracy: 0.4257\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 20s 799us/step - loss: 1.4889 - sparse_categorical_accuracy: 0.4192 - val_loss: 1.4900 - val_sparse_categorical_accuracy: 0.4180\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 20s 802us/step - loss: 1.4830 - sparse_categorical_accuracy: 0.4156 - val_loss: 1.4661 - val_sparse_categorical_accuracy: 0.4273\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 20s 806us/step - loss: 1.4797 - sparse_categorical_accuracy: 0.4182 - val_loss: 1.4740 - val_sparse_categorical_accuracy: 0.4167\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 20s 821us/step - loss: 1.4701 - sparse_categorical_accuracy: 0.4192 - val_loss: 1.4641 - val_sparse_categorical_accuracy: 0.4217\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 23s 938us/step - loss: 1.4663 - sparse_categorical_accuracy: 0.4206 - val_loss: 1.5072 - val_sparse_categorical_accuracy: 0.4093\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 23s 920us/step - loss: 1.4591 - sparse_categorical_accuracy: 0.4239 - val_loss: 1.5048 - val_sparse_categorical_accuracy: 0.4023\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 21s 859us/step - loss: 1.4572 - sparse_categorical_accuracy: 0.4209 - val_loss: 1.4600 - val_sparse_categorical_accuracy: 0.4213\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 21s 866us/step - loss: 1.4495 - sparse_categorical_accuracy: 0.4256 - val_loss: 1.4826 - val_sparse_categorical_accuracy: 0.4107\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 23s 949us/step - loss: 1.4446 - sparse_categorical_accuracy: 0.4288 - val_loss: 1.4798 - val_sparse_categorical_accuracy: 0.4230\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 21s 833us/step - loss: 1.4404 - sparse_categorical_accuracy: 0.4295 - val_loss: 1.4825 - val_sparse_categorical_accuracy: 0.4167\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 20s 795us/step - loss: 1.4332 - sparse_categorical_accuracy: 0.4301 - val_loss: 1.4743 - val_sparse_categorical_accuracy: 0.4287\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 21s 852us/step - loss: 1.4272 - sparse_categorical_accuracy: 0.4301 - val_loss: 1.4737 - val_sparse_categorical_accuracy: 0.4337\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 21s 860us/step - loss: 1.4254 - sparse_categorical_accuracy: 0.4324 - val_loss: 1.4679 - val_sparse_categorical_accuracy: 0.4270\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 21s 843us/step - loss: 1.4189 - sparse_categorical_accuracy: 0.4329 - val_loss: 1.5009 - val_sparse_categorical_accuracy: 0.4193\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 20s 823us/step - loss: 1.4115 - sparse_categorical_accuracy: 0.4360 - val_loss: 1.4757 - val_sparse_categorical_accuracy: 0.4270\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 21s 835us/step - loss: 1.4081 - sparse_categorical_accuracy: 0.4347 - val_loss: 1.4692 - val_sparse_categorical_accuracy: 0.4300\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 22s 906us/step - loss: 1.4011 - sparse_categorical_accuracy: 0.4353 - val_loss: 1.4717 - val_sparse_categorical_accuracy: 0.4237\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 21s 832us/step - loss: 1.3969 - sparse_categorical_accuracy: 0.4391 - val_loss: 1.4716 - val_sparse_categorical_accuracy: 0.4307\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 21s 837us/step - loss: 1.3903 - sparse_categorical_accuracy: 0.4415 - val_loss: 1.4921 - val_sparse_categorical_accuracy: 0.4207\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 21s 837us/step - loss: 1.3812 - sparse_categorical_accuracy: 0.4424 - val_loss: 1.4932 - val_sparse_categorical_accuracy: 0.4220\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 20s 830us/step - loss: 1.3792 - sparse_categorical_accuracy: 0.4457 - val_loss: 1.4888 - val_sparse_categorical_accuracy: 0.4257\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 21s 860us/step - loss: 1.3710 - sparse_categorical_accuracy: 0.4473 - val_loss: 1.4965 - val_sparse_categorical_accuracy: 0.4290\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 21s 851us/step - loss: 1.3649 - sparse_categorical_accuracy: 0.4468 - val_loss: 1.5041 - val_sparse_categorical_accuracy: 0.4237\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 23s 922us/step - loss: 1.3585 - sparse_categorical_accuracy: 0.4504 - val_loss: 1.5385 - val_sparse_categorical_accuracy: 0.4260\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 22s 894us/step - loss: 1.3508 - sparse_categorical_accuracy: 0.4521 - val_loss: 1.5058 - val_sparse_categorical_accuracy: 0.4333\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 21s 854us/step - loss: 1.3448 - sparse_categorical_accuracy: 0.4531 - val_loss: 1.5087 - val_sparse_categorical_accuracy: 0.4237\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 21s 871us/step - loss: 1.3376 - sparse_categorical_accuracy: 0.4583 - val_loss: 1.5920 - val_sparse_categorical_accuracy: 0.4240\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 21s 873us/step - loss: 1.3326 - sparse_categorical_accuracy: 0.4617 - val_loss: 1.5286 - val_sparse_categorical_accuracy: 0.4190\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 21s 847us/step - loss: 1.3251 - sparse_categorical_accuracy: 0.4602 - val_loss: 1.5475 - val_sparse_categorical_accuracy: 0.4240\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 22s 903us/step - loss: 1.3195 - sparse_categorical_accuracy: 0.4633 - val_loss: 1.5547 - val_sparse_categorical_accuracy: 0.4193\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 23s 916us/step - loss: 1.3117 - sparse_categorical_accuracy: 0.4685 - val_loss: 1.5708 - val_sparse_categorical_accuracy: 0.4147\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 20s 828us/step - loss: 1.3045 - sparse_categorical_accuracy: 0.4665 - val_loss: 1.5656 - val_sparse_categorical_accuracy: 0.4193\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 20s 832us/step - loss: 1.2982 - sparse_categorical_accuracy: 0.4702 - val_loss: 1.5955 - val_sparse_categorical_accuracy: 0.4193\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 20s 817us/step - loss: 1.2949 - sparse_categorical_accuracy: 0.4704 - val_loss: 1.5761 - val_sparse_categorical_accuracy: 0.4203\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 20s 831us/step - loss: 1.2877 - sparse_categorical_accuracy: 0.4733 - val_loss: 1.6260 - val_sparse_categorical_accuracy: 0.4117\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 20s 818us/step - loss: 1.2795 - sparse_categorical_accuracy: 0.4740 - val_loss: 1.6685 - val_sparse_categorical_accuracy: 0.4163\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 20s 812us/step - loss: 1.2686 - sparse_categorical_accuracy: 0.4789 - val_loss: 1.6339 - val_sparse_categorical_accuracy: 0.4163\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 22s 876us/step - loss: 1.2639 - sparse_categorical_accuracy: 0.4794 - val_loss: 1.6566 - val_sparse_categorical_accuracy: 0.4140\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 23s 949us/step - loss: 1.2675 - sparse_categorical_accuracy: 0.4785 - val_loss: 1.6366 - val_sparse_categorical_accuracy: 0.4010\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 24s 992us/step - loss: 1.2509 - sparse_categorical_accuracy: 0.4859 - val_loss: 1.6209 - val_sparse_categorical_accuracy: 0.4053\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 25s 1ms/step - loss: 1.2457 - sparse_categorical_accuracy: 0.4883 - val_loss: 1.6506 - val_sparse_categorical_accuracy: 0.4100\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 22s 913us/step - loss: 1.2395 - sparse_categorical_accuracy: 0.4875 - val_loss: 1.7079 - val_sparse_categorical_accuracy: 0.4033\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 23s 919us/step - loss: 1.2330 - sparse_categorical_accuracy: 0.4929 - val_loss: 1.6713 - val_sparse_categorical_accuracy: 0.4097\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 22s 908us/step - loss: 1.2552 - sparse_categorical_accuracy: 0.4856 - val_loss: 1.6921 - val_sparse_categorical_accuracy: 0.4120\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 22s 913us/step - loss: 1.2310 - sparse_categorical_accuracy: 0.4950 - val_loss: 1.6832 - val_sparse_categorical_accuracy: 0.4017\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 23s 936us/step - loss: 1.2137 - sparse_categorical_accuracy: 0.4991 - val_loss: 1.7140 - val_sparse_categorical_accuracy: 0.4017\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 23s 916us/step - loss: 1.2090 - sparse_categorical_accuracy: 0.5004 - val_loss: 1.6888 - val_sparse_categorical_accuracy: 0.3813\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 22s 913us/step - loss: 1.2001 - sparse_categorical_accuracy: 0.5036 - val_loss: 1.7824 - val_sparse_categorical_accuracy: 0.4017\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 23s 940us/step - loss: 1.1963 - sparse_categorical_accuracy: 0.5071 - val_loss: 1.7170 - val_sparse_categorical_accuracy: 0.3933\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 23s 915us/step - loss: 1.1877 - sparse_categorical_accuracy: 0.5087 - val_loss: 1.8204 - val_sparse_categorical_accuracy: 0.4067\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 23s 918us/step - loss: 1.1815 - sparse_categorical_accuracy: 0.5116 - val_loss: 1.7933 - val_sparse_categorical_accuracy: 0.3907\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 23s 926us/step - loss: 1.1801 - sparse_categorical_accuracy: 0.5146 - val_loss: 1.7623 - val_sparse_categorical_accuracy: 0.3907\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 23s 919us/step - loss: 1.1728 - sparse_categorical_accuracy: 0.5164 - val_loss: 1.8384 - val_sparse_categorical_accuracy: 0.3977\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 23s 924us/step - loss: 1.1797 - sparse_categorical_accuracy: 0.5117 - val_loss: 1.9236 - val_sparse_categorical_accuracy: 0.3950\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 23s 914us/step - loss: 1.1665 - sparse_categorical_accuracy: 0.5170 - val_loss: 1.8303 - val_sparse_categorical_accuracy: 0.4040\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 23s 926us/step - loss: 1.1523 - sparse_categorical_accuracy: 0.5218 - val_loss: 1.7946 - val_sparse_categorical_accuracy: 0.4017\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 23s 919us/step - loss: 1.1438 - sparse_categorical_accuracy: 0.5294 - val_loss: 1.8682 - val_sparse_categorical_accuracy: 0.3933\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 23s 917us/step - loss: 1.1414 - sparse_categorical_accuracy: 0.5251 - val_loss: 2.0426 - val_sparse_categorical_accuracy: 0.3930\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 23s 949us/step - loss: 1.1389 - sparse_categorical_accuracy: 0.5276 - val_loss: 1.9787 - val_sparse_categorical_accuracy: 0.3897\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 23s 921us/step - loss: 1.1319 - sparse_categorical_accuracy: 0.5304 - val_loss: 1.9152 - val_sparse_categorical_accuracy: 0.3943\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 23s 924us/step - loss: 1.1305 - sparse_categorical_accuracy: 0.5328 - val_loss: 2.0406 - val_sparse_categorical_accuracy: 0.4033\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 23s 930us/step - loss: 1.1136 - sparse_categorical_accuracy: 0.5400 - val_loss: 1.9294 - val_sparse_categorical_accuracy: 0.3950\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 23s 918us/step - loss: 1.1104 - sparse_categorical_accuracy: 0.5395 - val_loss: 2.0568 - val_sparse_categorical_accuracy: 0.3887\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 23s 924us/step - loss: 1.1118 - sparse_categorical_accuracy: 0.5393 - val_loss: 1.9432 - val_sparse_categorical_accuracy: 0.3857\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 23s 936us/step - loss: 1.1043 - sparse_categorical_accuracy: 0.5421 - val_loss: 2.0542 - val_sparse_categorical_accuracy: 0.4030\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 23s 944us/step - loss: 1.0901 - sparse_categorical_accuracy: 0.5453 - val_loss: 1.9920 - val_sparse_categorical_accuracy: 0.3883\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 25s 1ms/step - loss: 1.0845 - sparse_categorical_accuracy: 0.5542 - val_loss: 2.1558 - val_sparse_categorical_accuracy: 0.3780\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 26s 1ms/step - loss: 1.0820 - sparse_categorical_accuracy: 0.5527 - val_loss: 2.0464 - val_sparse_categorical_accuracy: 0.3863\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 24s 992us/step - loss: 1.0812 - sparse_categorical_accuracy: 0.5535 - val_loss: 2.1480 - val_sparse_categorical_accuracy: 0.3957\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 19s 769us/step - loss: 1.0727 - sparse_categorical_accuracy: 0.5595 - val_loss: 2.2660 - val_sparse_categorical_accuracy: 0.4007\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 20s 812us/step - loss: 1.1166 - sparse_categorical_accuracy: 0.5427 - val_loss: 2.0551 - val_sparse_categorical_accuracy: 0.3830\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 26s 1ms/step - loss: 1.0603 - sparse_categorical_accuracy: 0.5572 - val_loss: 2.1348 - val_sparse_categorical_accuracy: 0.3800\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 19s 774us/step - loss: 1.0523 - sparse_categorical_accuracy: 0.5617 - val_loss: 2.4755 - val_sparse_categorical_accuracy: 0.3953\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 24s 968us/step - loss: 1.0461 - sparse_categorical_accuracy: 0.5644 - val_loss: 2.2951 - val_sparse_categorical_accuracy: 0.3787\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 24s 977us/step - loss: 1.0420 - sparse_categorical_accuracy: 0.5678 - val_loss: 2.3089 - val_sparse_categorical_accuracy: 0.3800\n",
      "Epoch 5/10\n",
      "  896/24634 [>.............................] - ETA: 25s - loss: 1.0055 - sparse_categorical_accuracy: 0.5748"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-3b07fa6df624>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mhistory15\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel15\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_dev_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_dev_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mhistory15_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    history15 = model15.fit(X_train_n, Y_train_n, epochs=10, batch_size=32, validation_data = (X_dev_n, Y_dev_n))\n",
    "    history15_all.append(history15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 16 RNN + L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_25 (Masking)         (None, 30, 10)            0         \n",
      "_________________________________________________________________\n",
      "lstm_39 (LSTM)               (None, 30, 100)           44400     \n",
      "_________________________________________________________________\n",
      "lstm_40 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 16)                816       \n",
      "=================================================================\n",
      "Total params: 150,866\n",
      "Trainable params: 150,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model16 = Sequential()\n",
    "model16.add(Masking(mask_value=0., input_shape=(30, 10)))\n",
    "model16.add(LSTM(100, activation='relu', input_shape=(30, 10), kernel_initializer='glorot_normal', return_sequences = 'True'))\n",
    "model16.add(LSTM(100, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model16.add(Dense(100, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model16.add(Dense(100, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model16.add(Dense(50, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model16.add(Dense(16, activation='softmax', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model16.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "print(model16.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "history16_all = []\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 2.2666 - sparse_categorical_accuracy: 0.3416 - val_loss: 1.7954 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 41s 2ms/step - loss: 1.7420 - sparse_categorical_accuracy: 0.3757 - val_loss: 1.6958 - val_sparse_categorical_accuracy: 0.3810\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 41s 2ms/step - loss: 1.6776 - sparse_categorical_accuracy: 0.3874 - val_loss: 1.6574 - val_sparse_categorical_accuracy: 0.3917\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.6454 - sparse_categorical_accuracy: 0.3922 - val_loss: 1.6180 - val_sparse_categorical_accuracy: 0.3903\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.6203 - sparse_categorical_accuracy: 0.3973 - val_loss: 1.6610 - val_sparse_categorical_accuracy: 0.3883\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 41s 2ms/step - loss: 1.6003 - sparse_categorical_accuracy: 0.4038 - val_loss: 1.6071 - val_sparse_categorical_accuracy: 0.4050\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.5893 - sparse_categorical_accuracy: 0.4046 - val_loss: 1.5827 - val_sparse_categorical_accuracy: 0.4080\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.5765 - sparse_categorical_accuracy: 0.4074 - val_loss: 1.5746 - val_sparse_categorical_accuracy: 0.4060\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.5627 - sparse_categorical_accuracy: 0.4106 - val_loss: 1.5794 - val_sparse_categorical_accuracy: 0.4013\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.5543 - sparse_categorical_accuracy: 0.4126 - val_loss: 1.5608 - val_sparse_categorical_accuracy: 0.4037\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.5446 - sparse_categorical_accuracy: 0.4099 - val_loss: 1.6083 - val_sparse_categorical_accuracy: 0.3993\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.5379 - sparse_categorical_accuracy: 0.4159 - val_loss: 1.5496 - val_sparse_categorical_accuracy: 0.4057\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.5302 - sparse_categorical_accuracy: 0.4167 - val_loss: 1.5603 - val_sparse_categorical_accuracy: 0.4127\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.5210 - sparse_categorical_accuracy: 0.4156 - val_loss: 1.5548 - val_sparse_categorical_accuracy: 0.4083\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.5152 - sparse_categorical_accuracy: 0.4201 - val_loss: 1.5490 - val_sparse_categorical_accuracy: 0.4097\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.5098 - sparse_categorical_accuracy: 0.4200 - val_loss: 1.5591 - val_sparse_categorical_accuracy: 0.4063\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.5009 - sparse_categorical_accuracy: 0.4220 - val_loss: 1.5600 - val_sparse_categorical_accuracy: 0.4043\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.4964 - sparse_categorical_accuracy: 0.4235 - val_loss: 1.5465 - val_sparse_categorical_accuracy: 0.4180\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.4870 - sparse_categorical_accuracy: 0.4282 - val_loss: 1.5409 - val_sparse_categorical_accuracy: 0.4137\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.4809 - sparse_categorical_accuracy: 0.4295 - val_loss: 1.5542 - val_sparse_categorical_accuracy: 0.4097\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.4746 - sparse_categorical_accuracy: 0.4318 - val_loss: 1.5477 - val_sparse_categorical_accuracy: 0.4117\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.4676 - sparse_categorical_accuracy: 0.4337 - val_loss: 1.5570 - val_sparse_categorical_accuracy: 0.4180\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.4576 - sparse_categorical_accuracy: 0.4346 - val_loss: 1.5646 - val_sparse_categorical_accuracy: 0.4097\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.4517 - sparse_categorical_accuracy: 0.4375 - val_loss: 1.5631 - val_sparse_categorical_accuracy: 0.4163\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.4411 - sparse_categorical_accuracy: 0.4399 - val_loss: 1.5648 - val_sparse_categorical_accuracy: 0.4137\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.4370 - sparse_categorical_accuracy: 0.4416 - val_loss: 1.5630 - val_sparse_categorical_accuracy: 0.4180\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.4269 - sparse_categorical_accuracy: 0.4449 - val_loss: 1.5673 - val_sparse_categorical_accuracy: 0.4143\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.4188 - sparse_categorical_accuracy: 0.4483 - val_loss: 1.5731 - val_sparse_categorical_accuracy: 0.4033\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.4077 - sparse_categorical_accuracy: 0.4500 - val_loss: 1.5716 - val_sparse_categorical_accuracy: 0.4120\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.3983 - sparse_categorical_accuracy: 0.4536 - val_loss: 1.5915 - val_sparse_categorical_accuracy: 0.4023\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.3934 - sparse_categorical_accuracy: 0.4545 - val_loss: 1.6118 - val_sparse_categorical_accuracy: 0.4103\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.3829 - sparse_categorical_accuracy: 0.4618 - val_loss: 1.6140 - val_sparse_categorical_accuracy: 0.4093\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.3744 - sparse_categorical_accuracy: 0.4620 - val_loss: 1.6023 - val_sparse_categorical_accuracy: 0.4037\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.3665 - sparse_categorical_accuracy: 0.4650 - val_loss: 1.7029 - val_sparse_categorical_accuracy: 0.4120\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.3596 - sparse_categorical_accuracy: 0.4703 - val_loss: 1.6185 - val_sparse_categorical_accuracy: 0.4053\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.3486 - sparse_categorical_accuracy: 0.4707 - val_loss: 1.6615 - val_sparse_categorical_accuracy: 0.4160\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 47s 2ms/step - loss: 1.3426 - sparse_categorical_accuracy: 0.4752 - val_loss: 1.6569 - val_sparse_categorical_accuracy: 0.3913\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.3328 - sparse_categorical_accuracy: 0.4763 - val_loss: 1.6942 - val_sparse_categorical_accuracy: 0.3907\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.3188 - sparse_categorical_accuracy: 0.4847 - val_loss: 1.7134 - val_sparse_categorical_accuracy: 0.3803\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.3210 - sparse_categorical_accuracy: 0.4861 - val_loss: 1.6869 - val_sparse_categorical_accuracy: 0.3887\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.3108 - sparse_categorical_accuracy: 0.4849 - val_loss: 1.7419 - val_sparse_categorical_accuracy: 0.4093\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.3005 - sparse_categorical_accuracy: 0.4913 - val_loss: 1.7776 - val_sparse_categorical_accuracy: 0.4097\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.2928 - sparse_categorical_accuracy: 0.4922 - val_loss: 1.8101 - val_sparse_categorical_accuracy: 0.3980\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.2832 - sparse_categorical_accuracy: 0.4959 - val_loss: 1.8003 - val_sparse_categorical_accuracy: 0.3967\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.2720 - sparse_categorical_accuracy: 0.5044 - val_loss: 1.7324 - val_sparse_categorical_accuracy: 0.3980\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.2601 - sparse_categorical_accuracy: 0.5066 - val_loss: 1.8761 - val_sparse_categorical_accuracy: 0.4103\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.2752 - sparse_categorical_accuracy: 0.5008 - val_loss: 1.7797 - val_sparse_categorical_accuracy: 0.3993\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.2436 - sparse_categorical_accuracy: 0.5151 - val_loss: 1.8954 - val_sparse_categorical_accuracy: 0.3957\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.2361 - sparse_categorical_accuracy: 0.5175 - val_loss: 1.9351 - val_sparse_categorical_accuracy: 0.4023\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.2348 - sparse_categorical_accuracy: 0.5190 - val_loss: 1.7931 - val_sparse_categorical_accuracy: 0.3873\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.2227 - sparse_categorical_accuracy: 0.5222 - val_loss: 1.9605 - val_sparse_categorical_accuracy: 0.4037\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.2110 - sparse_categorical_accuracy: 0.5315 - val_loss: 1.8499 - val_sparse_categorical_accuracy: 0.3900\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.2228 - sparse_categorical_accuracy: 0.5278 - val_loss: 1.8421 - val_sparse_categorical_accuracy: 0.3923\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.2007 - sparse_categorical_accuracy: 0.5373 - val_loss: 1.8795 - val_sparse_categorical_accuracy: 0.3933\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.1970 - sparse_categorical_accuracy: 0.5369 - val_loss: 1.8629 - val_sparse_categorical_accuracy: 0.3617\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.1917 - sparse_categorical_accuracy: 0.5375 - val_loss: 1.9292 - val_sparse_categorical_accuracy: 0.3850\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.1788 - sparse_categorical_accuracy: 0.5440 - val_loss: 1.8686 - val_sparse_categorical_accuracy: 0.3683\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.1656 - sparse_categorical_accuracy: 0.5478 - val_loss: 2.0404 - val_sparse_categorical_accuracy: 0.3980\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.1615 - sparse_categorical_accuracy: 0.5516 - val_loss: 1.9691 - val_sparse_categorical_accuracy: 0.3827\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.1625 - sparse_categorical_accuracy: 0.5503 - val_loss: 1.9933 - val_sparse_categorical_accuracy: 0.3787\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.1526 - sparse_categorical_accuracy: 0.5569 - val_loss: 1.9291 - val_sparse_categorical_accuracy: 0.3917\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 43s 2ms/step - loss: 1.1359 - sparse_categorical_accuracy: 0.5658 - val_loss: 2.0454 - val_sparse_categorical_accuracy: 0.3837\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.1427 - sparse_categorical_accuracy: 0.5593 - val_loss: 1.9953 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.1338 - sparse_categorical_accuracy: 0.5654 - val_loss: 2.1558 - val_sparse_categorical_accuracy: 0.3903\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.1122 - sparse_categorical_accuracy: 0.5740 - val_loss: 2.1036 - val_sparse_categorical_accuracy: 0.3730\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.1240 - sparse_categorical_accuracy: 0.5676 - val_loss: 2.0968 - val_sparse_categorical_accuracy: 0.3833\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.1362 - sparse_categorical_accuracy: 0.5655 - val_loss: 1.9239 - val_sparse_categorical_accuracy: 0.3827\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.1192 - sparse_categorical_accuracy: 0.5707 - val_loss: 2.1843 - val_sparse_categorical_accuracy: 0.3920\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.0924 - sparse_categorical_accuracy: 0.5857 - val_loss: 2.1089 - val_sparse_categorical_accuracy: 0.3810\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.0763 - sparse_categorical_accuracy: 0.5950 - val_loss: 2.1658 - val_sparse_categorical_accuracy: 0.3617\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.0975 - sparse_categorical_accuracy: 0.5858 - val_loss: 2.1698 - val_sparse_categorical_accuracy: 0.3820\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.0681 - sparse_categorical_accuracy: 0.5967 - val_loss: 2.1916 - val_sparse_categorical_accuracy: 0.3767\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.0629 - sparse_categorical_accuracy: 0.5990 - val_loss: 2.1315 - val_sparse_categorical_accuracy: 0.3737\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.0578 - sparse_categorical_accuracy: 0.6042 - val_loss: 2.2737 - val_sparse_categorical_accuracy: 0.3920\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.0436 - sparse_categorical_accuracy: 0.6091 - val_loss: 2.2773 - val_sparse_categorical_accuracy: 0.3657\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.0437 - sparse_categorical_accuracy: 0.6046 - val_loss: 2.2621 - val_sparse_categorical_accuracy: 0.3653\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.0366 - sparse_categorical_accuracy: 0.6125 - val_loss: 2.3215 - val_sparse_categorical_accuracy: 0.3810\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.0333 - sparse_categorical_accuracy: 0.6140 - val_loss: 2.3250 - val_sparse_categorical_accuracy: 0.3683\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.0340 - sparse_categorical_accuracy: 0.6165 - val_loss: 2.3757 - val_sparse_categorical_accuracy: 0.3803\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.0138 - sparse_categorical_accuracy: 0.6263 - val_loss: 2.4847 - val_sparse_categorical_accuracy: 0.3780\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.0165 - sparse_categorical_accuracy: 0.6228 - val_loss: 2.3339 - val_sparse_categorical_accuracy: 0.3697\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 44s 2ms/step - loss: 1.0200 - sparse_categorical_accuracy: 0.6206 - val_loss: 2.5217 - val_sparse_categorical_accuracy: 0.3813\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 45s 2ms/step - loss: 1.0095 - sparse_categorical_accuracy: 0.6248 - val_loss: 2.2861 - val_sparse_categorical_accuracy: 0.3663\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 42s 2ms/step - loss: 1.0052 - sparse_categorical_accuracy: 0.6330 - val_loss: 2.3114 - val_sparse_categorical_accuracy: 0.3600\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.9856 - sparse_categorical_accuracy: 0.6400 - val_loss: 2.3597 - val_sparse_categorical_accuracy: 0.3670\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.9802 - sparse_categorical_accuracy: 0.6395 - val_loss: 2.4844 - val_sparse_categorical_accuracy: 0.3653\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.9804 - sparse_categorical_accuracy: 0.6397 - val_loss: 2.7952 - val_sparse_categorical_accuracy: 0.3767\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.9845 - sparse_categorical_accuracy: 0.6411 - val_loss: 2.3748 - val_sparse_categorical_accuracy: 0.3640\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.9621 - sparse_categorical_accuracy: 0.6526 - val_loss: 2.5239 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.9639 - sparse_categorical_accuracy: 0.6504 - val_loss: 2.5105 - val_sparse_categorical_accuracy: 0.3627\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.9543 - sparse_categorical_accuracy: 0.6568 - val_loss: 2.5136 - val_sparse_categorical_accuracy: 0.3743\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.9447 - sparse_categorical_accuracy: 0.6619 - val_loss: 2.4928 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.9414 - sparse_categorical_accuracy: 0.6631 - val_loss: 2.8284 - val_sparse_categorical_accuracy: 0.3787\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.9543 - sparse_categorical_accuracy: 0.6554 - val_loss: 2.3933 - val_sparse_categorical_accuracy: 0.3587\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.9331 - sparse_categorical_accuracy: 0.6694 - val_loss: 2.6266 - val_sparse_categorical_accuracy: 0.3673\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.9217 - sparse_categorical_accuracy: 0.6769 - val_loss: 2.6005 - val_sparse_categorical_accuracy: 0.3673\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 37s 1ms/step - loss: 0.9244 - sparse_categorical_accuracy: 0.6739 - val_loss: 2.5965 - val_sparse_categorical_accuracy: 0.3700\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.9154 - sparse_categorical_accuracy: 0.6771 - val_loss: 2.5337 - val_sparse_categorical_accuracy: 0.3533\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.9104 - sparse_categorical_accuracy: 0.6778 - val_loss: 2.6278 - val_sparse_categorical_accuracy: 0.3470\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.9109 - sparse_categorical_accuracy: 0.6793 - val_loss: 2.7322 - val_sparse_categorical_accuracy: 0.3720\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.9155 - sparse_categorical_accuracy: 0.6790 - val_loss: 2.8155 - val_sparse_categorical_accuracy: 0.3783\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.9039 - sparse_categorical_accuracy: 0.6807 - val_loss: 2.7474 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8937 - sparse_categorical_accuracy: 0.6893 - val_loss: 2.7726 - val_sparse_categorical_accuracy: 0.3547\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8816 - sparse_categorical_accuracy: 0.6961 - val_loss: 2.8153 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8842 - sparse_categorical_accuracy: 0.6914 - val_loss: 2.7662 - val_sparse_categorical_accuracy: 0.3520\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8845 - sparse_categorical_accuracy: 0.6899 - val_loss: 2.8967 - val_sparse_categorical_accuracy: 0.3737\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8701 - sparse_categorical_accuracy: 0.7018 - val_loss: 2.6172 - val_sparse_categorical_accuracy: 0.3600\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.8833 - sparse_categorical_accuracy: 0.6957 - val_loss: 2.7834 - val_sparse_categorical_accuracy: 0.3743\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8724 - sparse_categorical_accuracy: 0.7018 - val_loss: 2.7975 - val_sparse_categorical_accuracy: 0.3647\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.8762 - sparse_categorical_accuracy: 0.6971 - val_loss: 2.7369 - val_sparse_categorical_accuracy: 0.3593\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8637 - sparse_categorical_accuracy: 0.7045 - val_loss: 2.9740 - val_sparse_categorical_accuracy: 0.3640\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8449 - sparse_categorical_accuracy: 0.7162 - val_loss: 2.8082 - val_sparse_categorical_accuracy: 0.3597\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8608 - sparse_categorical_accuracy: 0.7070 - val_loss: 2.8273 - val_sparse_categorical_accuracy: 0.3657\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8668 - sparse_categorical_accuracy: 0.7049 - val_loss: 2.7159 - val_sparse_categorical_accuracy: 0.3647\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8357 - sparse_categorical_accuracy: 0.7209 - val_loss: 2.9168 - val_sparse_categorical_accuracy: 0.3647\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8377 - sparse_categorical_accuracy: 0.7187 - val_loss: 2.7450 - val_sparse_categorical_accuracy: 0.3433\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.8437 - sparse_categorical_accuracy: 0.7131 - val_loss: 2.8283 - val_sparse_categorical_accuracy: 0.3657\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8254 - sparse_categorical_accuracy: 0.7242 - val_loss: 2.8652 - val_sparse_categorical_accuracy: 0.3470\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8289 - sparse_categorical_accuracy: 0.7252 - val_loss: 2.9196 - val_sparse_categorical_accuracy: 0.3437\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.8134 - sparse_categorical_accuracy: 0.7287 - val_loss: 2.8921 - val_sparse_categorical_accuracy: 0.3683\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8128 - sparse_categorical_accuracy: 0.7297 - val_loss: 2.9562 - val_sparse_categorical_accuracy: 0.3610\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8209 - sparse_categorical_accuracy: 0.7276 - val_loss: 2.8384 - val_sparse_categorical_accuracy: 0.3387\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8110 - sparse_categorical_accuracy: 0.7337 - val_loss: 3.0674 - val_sparse_categorical_accuracy: 0.3583\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8053 - sparse_categorical_accuracy: 0.7337 - val_loss: 2.9845 - val_sparse_categorical_accuracy: 0.3630\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8050 - sparse_categorical_accuracy: 0.7357 - val_loss: 3.0018 - val_sparse_categorical_accuracy: 0.3453\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8012 - sparse_categorical_accuracy: 0.7351 - val_loss: 2.9472 - val_sparse_categorical_accuracy: 0.3547\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8029 - sparse_categorical_accuracy: 0.7345 - val_loss: 2.8962 - val_sparse_categorical_accuracy: 0.3533\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7973 - sparse_categorical_accuracy: 0.7390 - val_loss: 2.8995 - val_sparse_categorical_accuracy: 0.3380\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8088 - sparse_categorical_accuracy: 0.7336 - val_loss: 2.7866 - val_sparse_categorical_accuracy: 0.3613\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7881 - sparse_categorical_accuracy: 0.7435 - val_loss: 2.9965 - val_sparse_categorical_accuracy: 0.3543\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 40s 2ms/step - loss: 0.8189 - sparse_categorical_accuracy: 0.7281 - val_loss: 2.9020 - val_sparse_categorical_accuracy: 0.3697\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7873 - sparse_categorical_accuracy: 0.7406 - val_loss: 3.0646 - val_sparse_categorical_accuracy: 0.3553\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.7799 - sparse_categorical_accuracy: 0.7473 - val_loss: 2.9909 - val_sparse_categorical_accuracy: 0.3490\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.7632 - sparse_categorical_accuracy: 0.7562 - val_loss: 3.1602 - val_sparse_categorical_accuracy: 0.3627\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7699 - sparse_categorical_accuracy: 0.7511 - val_loss: 3.1835 - val_sparse_categorical_accuracy: 0.3573\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.7682 - sparse_categorical_accuracy: 0.7537 - val_loss: 3.1980 - val_sparse_categorical_accuracy: 0.3513\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7613 - sparse_categorical_accuracy: 0.7546 - val_loss: 3.0949 - val_sparse_categorical_accuracy: 0.3487\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.7879 - sparse_categorical_accuracy: 0.7404 - val_loss: 2.9273 - val_sparse_categorical_accuracy: 0.3613\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7655 - sparse_categorical_accuracy: 0.7560 - val_loss: 3.1969 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7740 - sparse_categorical_accuracy: 0.7519 - val_loss: 2.9931 - val_sparse_categorical_accuracy: 0.3517\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7634 - sparse_categorical_accuracy: 0.7536 - val_loss: 3.2467 - val_sparse_categorical_accuracy: 0.3577\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7367 - sparse_categorical_accuracy: 0.7668 - val_loss: 3.2823 - val_sparse_categorical_accuracy: 0.3560\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7430 - sparse_categorical_accuracy: 0.7649 - val_loss: 3.3067 - val_sparse_categorical_accuracy: 0.3620\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7660 - sparse_categorical_accuracy: 0.7519 - val_loss: 3.2245 - val_sparse_categorical_accuracy: 0.3800\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7415 - sparse_categorical_accuracy: 0.7660 - val_loss: 3.2261 - val_sparse_categorical_accuracy: 0.3510\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7450 - sparse_categorical_accuracy: 0.7634 - val_loss: 3.2349 - val_sparse_categorical_accuracy: 0.3630\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7222 - sparse_categorical_accuracy: 0.7743 - val_loss: 3.3282 - val_sparse_categorical_accuracy: 0.3677\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7249 - sparse_categorical_accuracy: 0.7734 - val_loss: 3.2469 - val_sparse_categorical_accuracy: 0.3547\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7336 - sparse_categorical_accuracy: 0.7704 - val_loss: 3.1741 - val_sparse_categorical_accuracy: 0.3813\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7405 - sparse_categorical_accuracy: 0.7618 - val_loss: 3.1284 - val_sparse_categorical_accuracy: 0.3593\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.7192 - sparse_categorical_accuracy: 0.7752 - val_loss: 3.4529 - val_sparse_categorical_accuracy: 0.3647\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7288 - sparse_categorical_accuracy: 0.7697 - val_loss: 3.3141 - val_sparse_categorical_accuracy: 0.3667\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7127 - sparse_categorical_accuracy: 0.7772 - val_loss: 3.0735 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7227 - sparse_categorical_accuracy: 0.7724 - val_loss: 3.4477 - val_sparse_categorical_accuracy: 0.3633\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7299 - sparse_categorical_accuracy: 0.7703 - val_loss: 3.3191 - val_sparse_categorical_accuracy: 0.3730\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7103 - sparse_categorical_accuracy: 0.7798 - val_loss: 3.3391 - val_sparse_categorical_accuracy: 0.3530\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7017 - sparse_categorical_accuracy: 0.7831 - val_loss: 3.5633 - val_sparse_categorical_accuracy: 0.3693\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7281 - sparse_categorical_accuracy: 0.7713 - val_loss: 3.2310 - val_sparse_categorical_accuracy: 0.3607\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.7169 - sparse_categorical_accuracy: 0.7749 - val_loss: 3.1915 - val_sparse_categorical_accuracy: 0.3463\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6978 - sparse_categorical_accuracy: 0.7839 - val_loss: 3.2345 - val_sparse_categorical_accuracy: 0.3403\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7071 - sparse_categorical_accuracy: 0.7816 - val_loss: 3.3662 - val_sparse_categorical_accuracy: 0.3423\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.6955 - sparse_categorical_accuracy: 0.7862 - val_loss: 3.3380 - val_sparse_categorical_accuracy: 0.3657\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6976 - sparse_categorical_accuracy: 0.7873 - val_loss: 3.3823 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6991 - sparse_categorical_accuracy: 0.7857 - val_loss: 3.4510 - val_sparse_categorical_accuracy: 0.3583\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6979 - sparse_categorical_accuracy: 0.7871 - val_loss: 3.2345 - val_sparse_categorical_accuracy: 0.3567\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6810 - sparse_categorical_accuracy: 0.7908 - val_loss: 3.3896 - val_sparse_categorical_accuracy: 0.3467\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.6939 - sparse_categorical_accuracy: 0.7878 - val_loss: 3.4602 - val_sparse_categorical_accuracy: 0.3527\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6863 - sparse_categorical_accuracy: 0.7914 - val_loss: 3.4950 - val_sparse_categorical_accuracy: 0.3613\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6750 - sparse_categorical_accuracy: 0.7948 - val_loss: 3.3157 - val_sparse_categorical_accuracy: 0.3490\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.6928 - sparse_categorical_accuracy: 0.7873 - val_loss: 3.6401 - val_sparse_categorical_accuracy: 0.3590\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7057 - sparse_categorical_accuracy: 0.7795 - val_loss: 3.3144 - val_sparse_categorical_accuracy: 0.3497\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6807 - sparse_categorical_accuracy: 0.7911 - val_loss: 3.4922 - val_sparse_categorical_accuracy: 0.3583\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.6872 - sparse_categorical_accuracy: 0.7898 - val_loss: 3.6608 - val_sparse_categorical_accuracy: 0.3697\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6572 - sparse_categorical_accuracy: 0.8043 - val_loss: 3.4653 - val_sparse_categorical_accuracy: 0.3460\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6687 - sparse_categorical_accuracy: 0.7961 - val_loss: 3.5632 - val_sparse_categorical_accuracy: 0.3527\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6770 - sparse_categorical_accuracy: 0.7965 - val_loss: 3.5345 - val_sparse_categorical_accuracy: 0.3487\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7200 - sparse_categorical_accuracy: 0.7756 - val_loss: 3.0365 - val_sparse_categorical_accuracy: 0.3647\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.7047 - sparse_categorical_accuracy: 0.7815 - val_loss: 3.4313 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6484 - sparse_categorical_accuracy: 0.8098 - val_loss: 3.7668 - val_sparse_categorical_accuracy: 0.3763\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6619 - sparse_categorical_accuracy: 0.8017 - val_loss: 3.4476 - val_sparse_categorical_accuracy: 0.3423\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6882 - sparse_categorical_accuracy: 0.7879 - val_loss: 3.2409 - val_sparse_categorical_accuracy: 0.3620\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.6803 - sparse_categorical_accuracy: 0.7926 - val_loss: 3.4593 - val_sparse_categorical_accuracy: 0.3513\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6560 - sparse_categorical_accuracy: 0.8037 - val_loss: 3.4795 - val_sparse_categorical_accuracy: 0.3553\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6594 - sparse_categorical_accuracy: 0.8024 - val_loss: 3.4737 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6532 - sparse_categorical_accuracy: 0.8075 - val_loss: 3.4554 - val_sparse_categorical_accuracy: 0.3487\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6693 - sparse_categorical_accuracy: 0.7980 - val_loss: 3.5780 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6473 - sparse_categorical_accuracy: 0.8090 - val_loss: 3.4710 - val_sparse_categorical_accuracy: 0.3570\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6604 - sparse_categorical_accuracy: 0.8025 - val_loss: 3.4943 - val_sparse_categorical_accuracy: 0.3683\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6451 - sparse_categorical_accuracy: 0.8094 - val_loss: 3.7354 - val_sparse_categorical_accuracy: 0.3490\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6703 - sparse_categorical_accuracy: 0.7972 - val_loss: 3.6057 - val_sparse_categorical_accuracy: 0.3430\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6609 - sparse_categorical_accuracy: 0.8002 - val_loss: 3.6531 - val_sparse_categorical_accuracy: 0.3477\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6488 - sparse_categorical_accuracy: 0.8071 - val_loss: 3.6932 - val_sparse_categorical_accuracy: 0.3527\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7296 - sparse_categorical_accuracy: 0.7723 - val_loss: 3.4534 - val_sparse_categorical_accuracy: 0.3573\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.6478 - sparse_categorical_accuracy: 0.8095 - val_loss: 3.6637 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6354 - sparse_categorical_accuracy: 0.8131 - val_loss: 3.6214 - val_sparse_categorical_accuracy: 0.3467\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6661 - sparse_categorical_accuracy: 0.8010 - val_loss: 3.5733 - val_sparse_categorical_accuracy: 0.3560\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6347 - sparse_categorical_accuracy: 0.8130 - val_loss: 3.7021 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6443 - sparse_categorical_accuracy: 0.8082 - val_loss: 3.6079 - val_sparse_categorical_accuracy: 0.3467\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6425 - sparse_categorical_accuracy: 0.8122 - val_loss: 3.8323 - val_sparse_categorical_accuracy: 0.3587\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6323 - sparse_categorical_accuracy: 0.8142 - val_loss: 3.9936 - val_sparse_categorical_accuracy: 0.3613\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6545 - sparse_categorical_accuracy: 0.8008 - val_loss: 3.6269 - val_sparse_categorical_accuracy: 0.3610\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6257 - sparse_categorical_accuracy: 0.8178 - val_loss: 3.7178 - val_sparse_categorical_accuracy: 0.3557\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6482 - sparse_categorical_accuracy: 0.8075 - val_loss: 3.5623 - val_sparse_categorical_accuracy: 0.3553\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6315 - sparse_categorical_accuracy: 0.8113 - val_loss: 3.6835 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6235 - sparse_categorical_accuracy: 0.8182 - val_loss: 3.9252 - val_sparse_categorical_accuracy: 0.3623\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6308 - sparse_categorical_accuracy: 0.8119 - val_loss: 3.7143 - val_sparse_categorical_accuracy: 0.3620\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6405 - sparse_categorical_accuracy: 0.8098 - val_loss: 3.7738 - val_sparse_categorical_accuracy: 0.3493\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6362 - sparse_categorical_accuracy: 0.8120 - val_loss: 3.4222 - val_sparse_categorical_accuracy: 0.3430\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6121 - sparse_categorical_accuracy: 0.8232 - val_loss: 3.8378 - val_sparse_categorical_accuracy: 0.3497\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6210 - sparse_categorical_accuracy: 0.8180 - val_loss: 3.7185 - val_sparse_categorical_accuracy: 0.3563\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6307 - sparse_categorical_accuracy: 0.8116 - val_loss: 3.6857 - val_sparse_categorical_accuracy: 0.3620\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6556 - sparse_categorical_accuracy: 0.8040 - val_loss: 3.8543 - val_sparse_categorical_accuracy: 0.3653\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.6240 - sparse_categorical_accuracy: 0.8186 - val_loss: 3.6020 - val_sparse_categorical_accuracy: 0.3617\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6121 - sparse_categorical_accuracy: 0.8240 - val_loss: 3.8245 - val_sparse_categorical_accuracy: 0.3647\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6208 - sparse_categorical_accuracy: 0.8177 - val_loss: 3.5579 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6556 - sparse_categorical_accuracy: 0.8041 - val_loss: 3.5099 - val_sparse_categorical_accuracy: 0.3517\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6194 - sparse_categorical_accuracy: 0.8196 - val_loss: 3.4610 - val_sparse_categorical_accuracy: 0.3437\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6368 - sparse_categorical_accuracy: 0.8127 - val_loss: 4.0694 - val_sparse_categorical_accuracy: 0.3460\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6070 - sparse_categorical_accuracy: 0.8243 - val_loss: 3.8538 - val_sparse_categorical_accuracy: 0.3693\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6141 - sparse_categorical_accuracy: 0.8231 - val_loss: 3.7751 - val_sparse_categorical_accuracy: 0.3580\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6288 - sparse_categorical_accuracy: 0.8141 - val_loss: 4.0030 - val_sparse_categorical_accuracy: 0.3657\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6199 - sparse_categorical_accuracy: 0.8215 - val_loss: 3.4923 - val_sparse_categorical_accuracy: 0.3550\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.6156 - sparse_categorical_accuracy: 0.8239 - val_loss: 3.4976 - val_sparse_categorical_accuracy: 0.3537\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6229 - sparse_categorical_accuracy: 0.8176 - val_loss: 3.5548 - val_sparse_categorical_accuracy: 0.3610\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6173 - sparse_categorical_accuracy: 0.8231 - val_loss: 3.8863 - val_sparse_categorical_accuracy: 0.3500\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6069 - sparse_categorical_accuracy: 0.8232 - val_loss: 3.8371 - val_sparse_categorical_accuracy: 0.3527\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6020 - sparse_categorical_accuracy: 0.8288 - val_loss: 3.4127 - val_sparse_categorical_accuracy: 0.3457\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6568 - sparse_categorical_accuracy: 0.8004 - val_loss: 3.6371 - val_sparse_categorical_accuracy: 0.3530\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6153 - sparse_categorical_accuracy: 0.8216 - val_loss: 3.8415 - val_sparse_categorical_accuracy: 0.3623\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5953 - sparse_categorical_accuracy: 0.8303 - val_loss: 3.7028 - val_sparse_categorical_accuracy: 0.3520\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.6122 - sparse_categorical_accuracy: 0.8224 - val_loss: 3.8306 - val_sparse_categorical_accuracy: 0.3680\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.6043 - sparse_categorical_accuracy: 0.8273 - val_loss: 3.7352 - val_sparse_categorical_accuracy: 0.3430\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.6041 - sparse_categorical_accuracy: 0.8241 - val_loss: 3.8778 - val_sparse_categorical_accuracy: 0.3537\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6034 - sparse_categorical_accuracy: 0.8239 - val_loss: 4.0107 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5996 - sparse_categorical_accuracy: 0.8287 - val_loss: 3.8265 - val_sparse_categorical_accuracy: 0.3570\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6048 - sparse_categorical_accuracy: 0.8244 - val_loss: 3.4985 - val_sparse_categorical_accuracy: 0.3420\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6051 - sparse_categorical_accuracy: 0.8263 - val_loss: 3.9508 - val_sparse_categorical_accuracy: 0.3647\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6163 - sparse_categorical_accuracy: 0.8190 - val_loss: 3.7546 - val_sparse_categorical_accuracy: 0.3473\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5903 - sparse_categorical_accuracy: 0.8338 - val_loss: 4.0732 - val_sparse_categorical_accuracy: 0.3623\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6087 - sparse_categorical_accuracy: 0.8216 - val_loss: 3.8593 - val_sparse_categorical_accuracy: 0.3553\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5913 - sparse_categorical_accuracy: 0.8343 - val_loss: 3.9777 - val_sparse_categorical_accuracy: 0.3387\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5882 - sparse_categorical_accuracy: 0.8346 - val_loss: 3.9128 - val_sparse_categorical_accuracy: 0.3370\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5702 - sparse_categorical_accuracy: 0.8393 - val_loss: 4.0209 - val_sparse_categorical_accuracy: 0.3450\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5934 - sparse_categorical_accuracy: 0.8306 - val_loss: 3.7831 - val_sparse_categorical_accuracy: 0.3533\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5925 - sparse_categorical_accuracy: 0.8307 - val_loss: 4.0628 - val_sparse_categorical_accuracy: 0.3557\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6093 - sparse_categorical_accuracy: 0.8229 - val_loss: 3.7926 - val_sparse_categorical_accuracy: 0.3447\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5941 - sparse_categorical_accuracy: 0.8310 - val_loss: 3.9715 - val_sparse_categorical_accuracy: 0.3570\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5902 - sparse_categorical_accuracy: 0.8318 - val_loss: 3.9367 - val_sparse_categorical_accuracy: 0.3527\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5989 - sparse_categorical_accuracy: 0.8294 - val_loss: 4.0547 - val_sparse_categorical_accuracy: 0.3640\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5792 - sparse_categorical_accuracy: 0.8381 - val_loss: 4.0080 - val_sparse_categorical_accuracy: 0.3593\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5927 - sparse_categorical_accuracy: 0.8338 - val_loss: 3.6924 - val_sparse_categorical_accuracy: 0.3617\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5830 - sparse_categorical_accuracy: 0.8360 - val_loss: 3.7984 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5976 - sparse_categorical_accuracy: 0.8290 - val_loss: 3.6646 - val_sparse_categorical_accuracy: 0.3423\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.5875 - sparse_categorical_accuracy: 0.8340 - val_loss: 4.1269 - val_sparse_categorical_accuracy: 0.3500\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6123 - sparse_categorical_accuracy: 0.8237 - val_loss: 3.8902 - val_sparse_categorical_accuracy: 0.3563\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5911 - sparse_categorical_accuracy: 0.8324 - val_loss: 3.8079 - val_sparse_categorical_accuracy: 0.3500\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6037 - sparse_categorical_accuracy: 0.8276 - val_loss: 4.0605 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5748 - sparse_categorical_accuracy: 0.8397 - val_loss: 3.9725 - val_sparse_categorical_accuracy: 0.3500\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5595 - sparse_categorical_accuracy: 0.8470 - val_loss: 4.1548 - val_sparse_categorical_accuracy: 0.3550\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5713 - sparse_categorical_accuracy: 0.8427 - val_loss: 4.0101 - val_sparse_categorical_accuracy: 0.3507\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.5776 - sparse_categorical_accuracy: 0.8379 - val_loss: 3.8673 - val_sparse_categorical_accuracy: 0.3380\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5818 - sparse_categorical_accuracy: 0.8379 - val_loss: 3.9551 - val_sparse_categorical_accuracy: 0.3627\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5848 - sparse_categorical_accuracy: 0.8377 - val_loss: 4.0416 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6018 - sparse_categorical_accuracy: 0.8281 - val_loss: 4.0513 - val_sparse_categorical_accuracy: 0.3697\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.5729 - sparse_categorical_accuracy: 0.8393 - val_loss: 4.2585 - val_sparse_categorical_accuracy: 0.3550\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5840 - sparse_categorical_accuracy: 0.8355 - val_loss: 4.0880 - val_sparse_categorical_accuracy: 0.3560\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.5748 - sparse_categorical_accuracy: 0.8407 - val_loss: 4.0300 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5599 - sparse_categorical_accuracy: 0.8469 - val_loss: 3.7567 - val_sparse_categorical_accuracy: 0.3513\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5863 - sparse_categorical_accuracy: 0.8349 - val_loss: 3.9454 - val_sparse_categorical_accuracy: 0.3587\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.5820 - sparse_categorical_accuracy: 0.8383 - val_loss: 3.8841 - val_sparse_categorical_accuracy: 0.3440\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5751 - sparse_categorical_accuracy: 0.8395 - val_loss: 4.0962 - val_sparse_categorical_accuracy: 0.3563\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5708 - sparse_categorical_accuracy: 0.8410 - val_loss: 4.0772 - val_sparse_categorical_accuracy: 0.3537\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5902 - sparse_categorical_accuracy: 0.8317 - val_loss: 3.9251 - val_sparse_categorical_accuracy: 0.3430\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5780 - sparse_categorical_accuracy: 0.8400 - val_loss: 4.0071 - val_sparse_categorical_accuracy: 0.3553\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5585 - sparse_categorical_accuracy: 0.8492 - val_loss: 4.3477 - val_sparse_categorical_accuracy: 0.3643\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5626 - sparse_categorical_accuracy: 0.8438 - val_loss: 4.0704 - val_sparse_categorical_accuracy: 0.3557\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5684 - sparse_categorical_accuracy: 0.8441 - val_loss: 3.9068 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5714 - sparse_categorical_accuracy: 0.8392 - val_loss: 3.9413 - val_sparse_categorical_accuracy: 0.3363\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5917 - sparse_categorical_accuracy: 0.8322 - val_loss: 3.9175 - val_sparse_categorical_accuracy: 0.3547\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5674 - sparse_categorical_accuracy: 0.8420 - val_loss: 3.9279 - val_sparse_categorical_accuracy: 0.3430\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5644 - sparse_categorical_accuracy: 0.8439 - val_loss: 3.8022 - val_sparse_categorical_accuracy: 0.3313\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5602 - sparse_categorical_accuracy: 0.8463 - val_loss: 4.1437 - val_sparse_categorical_accuracy: 0.3430\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5597 - sparse_categorical_accuracy: 0.8470 - val_loss: 4.2379 - val_sparse_categorical_accuracy: 0.3417\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5716 - sparse_categorical_accuracy: 0.8405 - val_loss: 4.1249 - val_sparse_categorical_accuracy: 0.3510\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5438 - sparse_categorical_accuracy: 0.8513 - val_loss: 4.3201 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.5562 - sparse_categorical_accuracy: 0.8457 - val_loss: 4.2463 - val_sparse_categorical_accuracy: 0.3487\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5877 - sparse_categorical_accuracy: 0.8347 - val_loss: 3.9556 - val_sparse_categorical_accuracy: 0.3447\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5473 - sparse_categorical_accuracy: 0.8520 - val_loss: 4.1505 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5630 - sparse_categorical_accuracy: 0.8465 - val_loss: 4.2717 - val_sparse_categorical_accuracy: 0.3617\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5737 - sparse_categorical_accuracy: 0.8420 - val_loss: 4.0532 - val_sparse_categorical_accuracy: 0.3447\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.5603 - sparse_categorical_accuracy: 0.8480 - val_loss: 4.0406 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.5553 - sparse_categorical_accuracy: 0.8477 - val_loss: 4.1826 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5653 - sparse_categorical_accuracy: 0.8427 - val_loss: 4.0037 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5500 - sparse_categorical_accuracy: 0.8494 - val_loss: 4.1140 - val_sparse_categorical_accuracy: 0.3480\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6178 - sparse_categorical_accuracy: 0.8209 - val_loss: 4.1235 - val_sparse_categorical_accuracy: 0.3573\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5278 - sparse_categorical_accuracy: 0.8629 - val_loss: 4.4497 - val_sparse_categorical_accuracy: 0.3550\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5465 - sparse_categorical_accuracy: 0.8511 - val_loss: 4.1251 - val_sparse_categorical_accuracy: 0.3547\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5418 - sparse_categorical_accuracy: 0.8541 - val_loss: 4.3370 - val_sparse_categorical_accuracy: 0.3427\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5551 - sparse_categorical_accuracy: 0.8472 - val_loss: 4.3788 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5564 - sparse_categorical_accuracy: 0.8469 - val_loss: 4.1570 - val_sparse_categorical_accuracy: 0.3503\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5381 - sparse_categorical_accuracy: 0.8555 - val_loss: 3.9474 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5692 - sparse_categorical_accuracy: 0.8403 - val_loss: 4.3929 - val_sparse_categorical_accuracy: 0.3573\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5572 - sparse_categorical_accuracy: 0.8482 - val_loss: 4.2668 - val_sparse_categorical_accuracy: 0.3657\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5854 - sparse_categorical_accuracy: 0.8346 - val_loss: 3.9793 - val_sparse_categorical_accuracy: 0.3447\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.8512 - val_loss: 4.2976 - val_sparse_categorical_accuracy: 0.3480\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5431 - sparse_categorical_accuracy: 0.8541 - val_loss: 4.2297 - val_sparse_categorical_accuracy: 0.3363\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5341 - sparse_categorical_accuracy: 0.8582 - val_loss: 4.4382 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5441 - sparse_categorical_accuracy: 0.8538 - val_loss: 4.1146 - val_sparse_categorical_accuracy: 0.3507\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5656 - sparse_categorical_accuracy: 0.8441 - val_loss: 4.1122 - val_sparse_categorical_accuracy: 0.3547\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5422 - sparse_categorical_accuracy: 0.8563 - val_loss: 4.2577 - val_sparse_categorical_accuracy: 0.3530\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.5412 - sparse_categorical_accuracy: 0.8526 - val_loss: 4.1753 - val_sparse_categorical_accuracy: 0.3517\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5452 - sparse_categorical_accuracy: 0.8525 - val_loss: 4.2120 - val_sparse_categorical_accuracy: 0.3430\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5503 - sparse_categorical_accuracy: 0.8508 - val_loss: 4.1132 - val_sparse_categorical_accuracy: 0.3473\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5917 - sparse_categorical_accuracy: 0.8310 - val_loss: 4.0651 - val_sparse_categorical_accuracy: 0.3453\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5692 - sparse_categorical_accuracy: 0.8423 - val_loss: 4.0885 - val_sparse_categorical_accuracy: 0.3520\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5436 - sparse_categorical_accuracy: 0.8515 - val_loss: 4.3284 - val_sparse_categorical_accuracy: 0.3453\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.5928 - sparse_categorical_accuracy: 0.8293 - val_loss: 3.8573 - val_sparse_categorical_accuracy: 0.3563\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5264 - sparse_categorical_accuracy: 0.8609 - val_loss: 4.2738 - val_sparse_categorical_accuracy: 0.3507\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5217 - sparse_categorical_accuracy: 0.8643 - val_loss: 3.9314 - val_sparse_categorical_accuracy: 0.3480\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5459 - sparse_categorical_accuracy: 0.8515 - val_loss: 4.2106 - val_sparse_categorical_accuracy: 0.3553\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5864 - sparse_categorical_accuracy: 0.8334 - val_loss: 3.9161 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5876 - sparse_categorical_accuracy: 0.8331 - val_loss: 3.9387 - val_sparse_categorical_accuracy: 0.3630\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5391 - sparse_categorical_accuracy: 0.8581 - val_loss: 4.0160 - val_sparse_categorical_accuracy: 0.3570\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5360 - sparse_categorical_accuracy: 0.8583 - val_loss: 4.1261 - val_sparse_categorical_accuracy: 0.3590\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5399 - sparse_categorical_accuracy: 0.8529 - val_loss: 4.1561 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5268 - sparse_categorical_accuracy: 0.8583 - val_loss: 4.3809 - val_sparse_categorical_accuracy: 0.3530\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5583 - sparse_categorical_accuracy: 0.8440 - val_loss: 3.9257 - val_sparse_categorical_accuracy: 0.3407\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5408 - sparse_categorical_accuracy: 0.8541 - val_loss: 4.2838 - val_sparse_categorical_accuracy: 0.3477\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5124 - sparse_categorical_accuracy: 0.8656 - val_loss: 4.3033 - val_sparse_categorical_accuracy: 0.3500\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5409 - sparse_categorical_accuracy: 0.8527 - val_loss: 4.0939 - val_sparse_categorical_accuracy: 0.3430\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.5471 - sparse_categorical_accuracy: 0.8516 - val_loss: 4.1089 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5231 - sparse_categorical_accuracy: 0.8604 - val_loss: 4.4503 - val_sparse_categorical_accuracy: 0.3657\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 37s 2ms/step - loss: 0.5394 - sparse_categorical_accuracy: 0.8545 - val_loss: 4.4909 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5472 - sparse_categorical_accuracy: 0.8503 - val_loss: 4.1745 - val_sparse_categorical_accuracy: 0.3520\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 40s 2ms/step - loss: 0.7753 - sparse_categorical_accuracy: 0.7662 - val_loss: 2.4385 - val_sparse_categorical_accuracy: 0.3597\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.9325 - sparse_categorical_accuracy: 0.6871 - val_loss: 2.7898 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.7401 - sparse_categorical_accuracy: 0.7717 - val_loss: 3.8286 - val_sparse_categorical_accuracy: 0.3597\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5744 - sparse_categorical_accuracy: 0.8457 - val_loss: 4.1977 - val_sparse_categorical_accuracy: 0.3407\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5433 - sparse_categorical_accuracy: 0.8556 - val_loss: 4.3913 - val_sparse_categorical_accuracy: 0.3510\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5476 - sparse_categorical_accuracy: 0.8523 - val_loss: 4.2833 - val_sparse_categorical_accuracy: 0.3500\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5442 - sparse_categorical_accuracy: 0.8523 - val_loss: 4.2425 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5211 - sparse_categorical_accuracy: 0.8637 - val_loss: 4.6760 - val_sparse_categorical_accuracy: 0.3550\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5273 - sparse_categorical_accuracy: 0.8607 - val_loss: 4.6691 - val_sparse_categorical_accuracy: 0.3460\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.8509 - val_loss: 4.5309 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5403 - sparse_categorical_accuracy: 0.8527 - val_loss: 4.5560 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5329 - sparse_categorical_accuracy: 0.8583 - val_loss: 4.4478 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5313 - sparse_categorical_accuracy: 0.8558 - val_loss: 4.3863 - val_sparse_categorical_accuracy: 0.3517\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5584 - sparse_categorical_accuracy: 0.8479 - val_loss: 4.0568 - val_sparse_categorical_accuracy: 0.3380\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5678 - sparse_categorical_accuracy: 0.8400 - val_loss: 4.2036 - val_sparse_categorical_accuracy: 0.3583\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5540 - sparse_categorical_accuracy: 0.8507 - val_loss: 4.1830 - val_sparse_categorical_accuracy: 0.3457\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5375 - sparse_categorical_accuracy: 0.8566 - val_loss: 4.5755 - val_sparse_categorical_accuracy: 0.3493\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5298 - sparse_categorical_accuracy: 0.8597 - val_loss: 4.2430 - val_sparse_categorical_accuracy: 0.3630\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5317 - sparse_categorical_accuracy: 0.8575 - val_loss: 4.4846 - val_sparse_categorical_accuracy: 0.3687\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5467 - sparse_categorical_accuracy: 0.8521 - val_loss: 4.1497 - val_sparse_categorical_accuracy: 0.3457\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6150 - sparse_categorical_accuracy: 0.8250 - val_loss: 3.7805 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5298 - sparse_categorical_accuracy: 0.8571 - val_loss: 4.2833 - val_sparse_categorical_accuracy: 0.3557\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5120 - sparse_categorical_accuracy: 0.8655 - val_loss: 4.4161 - val_sparse_categorical_accuracy: 0.3457\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5249 - sparse_categorical_accuracy: 0.8607 - val_loss: 4.3121 - val_sparse_categorical_accuracy: 0.3473\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6467 - sparse_categorical_accuracy: 0.8114 - val_loss: 3.9910 - val_sparse_categorical_accuracy: 0.3470\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5112 - sparse_categorical_accuracy: 0.8661 - val_loss: 4.4949 - val_sparse_categorical_accuracy: 0.3477\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5221 - sparse_categorical_accuracy: 0.8632 - val_loss: 4.5082 - val_sparse_categorical_accuracy: 0.3450\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4971 - sparse_categorical_accuracy: 0.8709 - val_loss: 4.7044 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5308 - sparse_categorical_accuracy: 0.8596 - val_loss: 4.2121 - val_sparse_categorical_accuracy: 0.3400\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5275 - sparse_categorical_accuracy: 0.8585 - val_loss: 4.6042 - val_sparse_categorical_accuracy: 0.3513\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5171 - sparse_categorical_accuracy: 0.8640 - val_loss: 4.4128 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4994 - sparse_categorical_accuracy: 0.8683 - val_loss: 4.8546 - val_sparse_categorical_accuracy: 0.3457\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5384 - sparse_categorical_accuracy: 0.8527 - val_loss: 4.4026 - val_sparse_categorical_accuracy: 0.3377\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5129 - sparse_categorical_accuracy: 0.8661 - val_loss: 4.4899 - val_sparse_categorical_accuracy: 0.3480\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5037 - sparse_categorical_accuracy: 0.8686 - val_loss: 4.4251 - val_sparse_categorical_accuracy: 0.3510\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5069 - sparse_categorical_accuracy: 0.8661 - val_loss: 4.6354 - val_sparse_categorical_accuracy: 0.3423\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5345 - sparse_categorical_accuracy: 0.8572 - val_loss: 4.4084 - val_sparse_categorical_accuracy: 0.3463\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5701 - sparse_categorical_accuracy: 0.8418 - val_loss: 3.4603 - val_sparse_categorical_accuracy: 0.3447\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5349 - sparse_categorical_accuracy: 0.8567 - val_loss: 4.3073 - val_sparse_categorical_accuracy: 0.3463\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5019 - sparse_categorical_accuracy: 0.8706 - val_loss: 4.3674 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5637 - sparse_categorical_accuracy: 0.8434 - val_loss: 4.1050 - val_sparse_categorical_accuracy: 0.3390\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5776 - sparse_categorical_accuracy: 0.8382 - val_loss: 3.7995 - val_sparse_categorical_accuracy: 0.3413\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5321 - sparse_categorical_accuracy: 0.8566 - val_loss: 4.4184 - val_sparse_categorical_accuracy: 0.3367\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5092 - sparse_categorical_accuracy: 0.8665 - val_loss: 4.2890 - val_sparse_categorical_accuracy: 0.3487\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4918 - sparse_categorical_accuracy: 0.8755 - val_loss: 4.3976 - val_sparse_categorical_accuracy: 0.3537\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5228 - sparse_categorical_accuracy: 0.8619 - val_loss: 4.5069 - val_sparse_categorical_accuracy: 0.3580\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4940 - sparse_categorical_accuracy: 0.8724 - val_loss: 4.7979 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5263 - sparse_categorical_accuracy: 0.8599 - val_loss: 4.7594 - val_sparse_categorical_accuracy: 0.3423\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5165 - sparse_categorical_accuracy: 0.8632 - val_loss: 4.4848 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5366 - sparse_categorical_accuracy: 0.8567 - val_loss: 4.4838 - val_sparse_categorical_accuracy: 0.3613\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5047 - sparse_categorical_accuracy: 0.8694 - val_loss: 4.7076 - val_sparse_categorical_accuracy: 0.3563\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5565 - sparse_categorical_accuracy: 0.8482 - val_loss: 4.3602 - val_sparse_categorical_accuracy: 0.3560\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5160 - sparse_categorical_accuracy: 0.8651 - val_loss: 4.3351 - val_sparse_categorical_accuracy: 0.3423\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4893 - sparse_categorical_accuracy: 0.8747 - val_loss: 4.4546 - val_sparse_categorical_accuracy: 0.3397\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5008 - sparse_categorical_accuracy: 0.8690 - val_loss: 4.8317 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5192 - sparse_categorical_accuracy: 0.8609 - val_loss: 4.1103 - val_sparse_categorical_accuracy: 0.3380\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5158 - sparse_categorical_accuracy: 0.8623 - val_loss: 4.5201 - val_sparse_categorical_accuracy: 0.3490\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4868 - sparse_categorical_accuracy: 0.8759 - val_loss: 4.5659 - val_sparse_categorical_accuracy: 0.3383\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5004 - sparse_categorical_accuracy: 0.8690 - val_loss: 4.6726 - val_sparse_categorical_accuracy: 0.3577\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5389 - sparse_categorical_accuracy: 0.8528 - val_loss: 4.3987 - val_sparse_categorical_accuracy: 0.3367\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5080 - sparse_categorical_accuracy: 0.8654 - val_loss: 4.8283 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5430 - sparse_categorical_accuracy: 0.8506 - val_loss: 4.5114 - val_sparse_categorical_accuracy: 0.3530\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5237 - sparse_categorical_accuracy: 0.8588 - val_loss: 4.5765 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5048 - sparse_categorical_accuracy: 0.8683 - val_loss: 4.6060 - val_sparse_categorical_accuracy: 0.3613\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5091 - sparse_categorical_accuracy: 0.8685 - val_loss: 4.4915 - val_sparse_categorical_accuracy: 0.3657\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5122 - sparse_categorical_accuracy: 0.8626 - val_loss: 4.8295 - val_sparse_categorical_accuracy: 0.3493\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5109 - sparse_categorical_accuracy: 0.8646 - val_loss: 4.6787 - val_sparse_categorical_accuracy: 0.3523\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5014 - sparse_categorical_accuracy: 0.8692 - val_loss: 4.9241 - val_sparse_categorical_accuracy: 0.3473\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5054 - sparse_categorical_accuracy: 0.8662 - val_loss: 4.5152 - val_sparse_categorical_accuracy: 0.3393\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5134 - sparse_categorical_accuracy: 0.8629 - val_loss: 4.5268 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5032 - sparse_categorical_accuracy: 0.8696 - val_loss: 4.3195 - val_sparse_categorical_accuracy: 0.3547\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5107 - sparse_categorical_accuracy: 0.8660 - val_loss: 4.6375 - val_sparse_categorical_accuracy: 0.3520\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4931 - sparse_categorical_accuracy: 0.8728 - val_loss: 4.6072 - val_sparse_categorical_accuracy: 0.3560\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4886 - sparse_categorical_accuracy: 0.8763 - val_loss: 4.7899 - val_sparse_categorical_accuracy: 0.3423\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5286 - sparse_categorical_accuracy: 0.8568 - val_loss: 4.8155 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4918 - sparse_categorical_accuracy: 0.8724 - val_loss: 4.8013 - val_sparse_categorical_accuracy: 0.3510\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5852 - sparse_categorical_accuracy: 0.8387 - val_loss: 3.6470 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5121 - sparse_categorical_accuracy: 0.8658 - val_loss: 4.4781 - val_sparse_categorical_accuracy: 0.3490\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4933 - sparse_categorical_accuracy: 0.8734 - val_loss: 4.5651 - val_sparse_categorical_accuracy: 0.3527\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5061 - sparse_categorical_accuracy: 0.8683 - val_loss: 4.7153 - val_sparse_categorical_accuracy: 0.3453\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4914 - sparse_categorical_accuracy: 0.8725 - val_loss: 4.7834 - val_sparse_categorical_accuracy: 0.3517\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4865 - sparse_categorical_accuracy: 0.8750 - val_loss: 4.6479 - val_sparse_categorical_accuracy: 0.3433\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4796 - sparse_categorical_accuracy: 0.8796 - val_loss: 5.0509 - val_sparse_categorical_accuracy: 0.3560\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5027 - sparse_categorical_accuracy: 0.8685 - val_loss: 4.4597 - val_sparse_categorical_accuracy: 0.3380\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5001 - sparse_categorical_accuracy: 0.8681 - val_loss: 4.8323 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4835 - sparse_categorical_accuracy: 0.8765 - val_loss: 4.6488 - val_sparse_categorical_accuracy: 0.3533\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4720 - sparse_categorical_accuracy: 0.8794 - val_loss: 5.0585 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4887 - sparse_categorical_accuracy: 0.8742 - val_loss: 5.0088 - val_sparse_categorical_accuracy: 0.3423\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5120 - sparse_categorical_accuracy: 0.8636 - val_loss: 4.4556 - val_sparse_categorical_accuracy: 0.3430\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5145 - sparse_categorical_accuracy: 0.8621 - val_loss: 4.8192 - val_sparse_categorical_accuracy: 0.3480\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4651 - sparse_categorical_accuracy: 0.8848 - val_loss: 4.8121 - val_sparse_categorical_accuracy: 0.3493\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4829 - sparse_categorical_accuracy: 0.8775 - val_loss: 4.7592 - val_sparse_categorical_accuracy: 0.3517\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4917 - sparse_categorical_accuracy: 0.8731 - val_loss: 4.9037 - val_sparse_categorical_accuracy: 0.3533\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4944 - sparse_categorical_accuracy: 0.8710 - val_loss: 4.6368 - val_sparse_categorical_accuracy: 0.3523\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4844 - sparse_categorical_accuracy: 0.8754 - val_loss: 4.6194 - val_sparse_categorical_accuracy: 0.3467\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4845 - sparse_categorical_accuracy: 0.8754 - val_loss: 4.6998 - val_sparse_categorical_accuracy: 0.3517\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4952 - sparse_categorical_accuracy: 0.8724 - val_loss: 4.7727 - val_sparse_categorical_accuracy: 0.3440\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4817 - sparse_categorical_accuracy: 0.8755 - val_loss: 5.1240 - val_sparse_categorical_accuracy: 0.3427\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4778 - sparse_categorical_accuracy: 0.8796 - val_loss: 4.7784 - val_sparse_categorical_accuracy: 0.3467\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5632 - sparse_categorical_accuracy: 0.8433 - val_loss: 4.6689 - val_sparse_categorical_accuracy: 0.3533\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5150 - sparse_categorical_accuracy: 0.8627 - val_loss: 4.5549 - val_sparse_categorical_accuracy: 0.3467\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4981 - sparse_categorical_accuracy: 0.8721 - val_loss: 4.5669 - val_sparse_categorical_accuracy: 0.3490\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4805 - sparse_categorical_accuracy: 0.8770 - val_loss: 4.6121 - val_sparse_categorical_accuracy: 0.3403\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 40s 2ms/step - loss: 0.4999 - sparse_categorical_accuracy: 0.8710 - val_loss: 4.4535 - val_sparse_categorical_accuracy: 0.3467\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5029 - sparse_categorical_accuracy: 0.8702 - val_loss: 4.4331 - val_sparse_categorical_accuracy: 0.3467\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5209 - sparse_categorical_accuracy: 0.8605 - val_loss: 4.3706 - val_sparse_categorical_accuracy: 0.3647\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5472 - sparse_categorical_accuracy: 0.8509 - val_loss: 4.1911 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4938 - sparse_categorical_accuracy: 0.8695 - val_loss: 4.3790 - val_sparse_categorical_accuracy: 0.3463\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4696 - sparse_categorical_accuracy: 0.8806 - val_loss: 5.0068 - val_sparse_categorical_accuracy: 0.3553\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5091 - sparse_categorical_accuracy: 0.8680 - val_loss: 3.9254 - val_sparse_categorical_accuracy: 0.3490\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4877 - sparse_categorical_accuracy: 0.8743 - val_loss: 4.4303 - val_sparse_categorical_accuracy: 0.3500\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4593 - sparse_categorical_accuracy: 0.8889 - val_loss: 4.7770 - val_sparse_categorical_accuracy: 0.3490\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4842 - sparse_categorical_accuracy: 0.8748 - val_loss: 4.6995 - val_sparse_categorical_accuracy: 0.3497\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5018 - sparse_categorical_accuracy: 0.8677 - val_loss: 4.4351 - val_sparse_categorical_accuracy: 0.3317\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5571 - sparse_categorical_accuracy: 0.8488 - val_loss: 4.3623 - val_sparse_categorical_accuracy: 0.3510\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4726 - sparse_categorical_accuracy: 0.8829 - val_loss: 4.4147 - val_sparse_categorical_accuracy: 0.3420\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4907 - sparse_categorical_accuracy: 0.8731 - val_loss: 4.7507 - val_sparse_categorical_accuracy: 0.3370\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4720 - sparse_categorical_accuracy: 0.8808 - val_loss: 4.9745 - val_sparse_categorical_accuracy: 0.3510\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4984 - sparse_categorical_accuracy: 0.8698 - val_loss: 4.4374 - val_sparse_categorical_accuracy: 0.3437\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4864 - sparse_categorical_accuracy: 0.8749 - val_loss: 4.8877 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4854 - sparse_categorical_accuracy: 0.8746 - val_loss: 4.5895 - val_sparse_categorical_accuracy: 0.3510\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4661 - sparse_categorical_accuracy: 0.8834 - val_loss: 5.1776 - val_sparse_categorical_accuracy: 0.3550\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4808 - sparse_categorical_accuracy: 0.8770 - val_loss: 4.8048 - val_sparse_categorical_accuracy: 0.3513\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5194 - sparse_categorical_accuracy: 0.8619 - val_loss: 4.5711 - val_sparse_categorical_accuracy: 0.3443\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6353 - sparse_categorical_accuracy: 0.8239 - val_loss: 2.4123 - val_sparse_categorical_accuracy: 0.3667\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8094 - sparse_categorical_accuracy: 0.7330 - val_loss: 3.4640 - val_sparse_categorical_accuracy: 0.3490\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5710 - sparse_categorical_accuracy: 0.8434 - val_loss: 4.0123 - val_sparse_categorical_accuracy: 0.3440\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5033 - sparse_categorical_accuracy: 0.8729 - val_loss: 4.4261 - val_sparse_categorical_accuracy: 0.3447\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4638 - sparse_categorical_accuracy: 0.8875 - val_loss: 4.6671 - val_sparse_categorical_accuracy: 0.3447\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4595 - sparse_categorical_accuracy: 0.8880 - val_loss: 4.9956 - val_sparse_categorical_accuracy: 0.3353\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4499 - sparse_categorical_accuracy: 0.8916 - val_loss: 4.8515 - val_sparse_categorical_accuracy: 0.3370\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4727 - sparse_categorical_accuracy: 0.8801 - val_loss: 4.6364 - val_sparse_categorical_accuracy: 0.3427\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.6461 - sparse_categorical_accuracy: 0.8134 - val_loss: 3.9094 - val_sparse_categorical_accuracy: 0.3557\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5097 - sparse_categorical_accuracy: 0.8668 - val_loss: 4.6213 - val_sparse_categorical_accuracy: 0.3410\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4553 - sparse_categorical_accuracy: 0.8897 - val_loss: 4.8954 - val_sparse_categorical_accuracy: 0.3460\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4837 - sparse_categorical_accuracy: 0.8773 - val_loss: 4.9647 - val_sparse_categorical_accuracy: 0.3513\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4720 - sparse_categorical_accuracy: 0.8826 - val_loss: 4.5566 - val_sparse_categorical_accuracy: 0.3273\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4852 - sparse_categorical_accuracy: 0.8762 - val_loss: 4.5644 - val_sparse_categorical_accuracy: 0.3430\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4731 - sparse_categorical_accuracy: 0.8852 - val_loss: 4.6609 - val_sparse_categorical_accuracy: 0.3570\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4760 - sparse_categorical_accuracy: 0.8806 - val_loss: 4.7427 - val_sparse_categorical_accuracy: 0.3627\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4914 - sparse_categorical_accuracy: 0.8712 - val_loss: 4.4308 - val_sparse_categorical_accuracy: 0.3433\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4813 - sparse_categorical_accuracy: 0.8783 - val_loss: 4.9521 - val_sparse_categorical_accuracy: 0.3590\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4905 - sparse_categorical_accuracy: 0.8712 - val_loss: 4.8282 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5621 - sparse_categorical_accuracy: 0.8504 - val_loss: 3.1089 - val_sparse_categorical_accuracy: 0.3257\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.6230 - sparse_categorical_accuracy: 0.8256 - val_loss: 4.3305 - val_sparse_categorical_accuracy: 0.3547\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4702 - sparse_categorical_accuracy: 0.8863 - val_loss: 4.9604 - val_sparse_categorical_accuracy: 0.3440\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4725 - sparse_categorical_accuracy: 0.8816 - val_loss: 4.5317 - val_sparse_categorical_accuracy: 0.3390\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5169 - sparse_categorical_accuracy: 0.8634 - val_loss: 4.4415 - val_sparse_categorical_accuracy: 0.3347\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5418 - sparse_categorical_accuracy: 0.8552 - val_loss: 4.8135 - val_sparse_categorical_accuracy: 0.3507\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4779 - sparse_categorical_accuracy: 0.8811 - val_loss: 4.6340 - val_sparse_categorical_accuracy: 0.3477\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4577 - sparse_categorical_accuracy: 0.8889 - val_loss: 5.0509 - val_sparse_categorical_accuracy: 0.3400\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4702 - sparse_categorical_accuracy: 0.8807 - val_loss: 4.8385 - val_sparse_categorical_accuracy: 0.3307\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4909 - sparse_categorical_accuracy: 0.8731 - val_loss: 4.7252 - val_sparse_categorical_accuracy: 0.3537\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4717 - sparse_categorical_accuracy: 0.8833 - val_loss: 4.7655 - val_sparse_categorical_accuracy: 0.3457\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5416 - sparse_categorical_accuracy: 0.8529 - val_loss: 4.1119 - val_sparse_categorical_accuracy: 0.3520\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5390 - sparse_categorical_accuracy: 0.8535 - val_loss: 4.5663 - val_sparse_categorical_accuracy: 0.3503\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4839 - sparse_categorical_accuracy: 0.8739 - val_loss: 4.6129 - val_sparse_categorical_accuracy: 0.3450\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4562 - sparse_categorical_accuracy: 0.8879 - val_loss: 4.7673 - val_sparse_categorical_accuracy: 0.3513\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4553 - sparse_categorical_accuracy: 0.8891 - val_loss: 5.1931 - val_sparse_categorical_accuracy: 0.3587\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5010 - sparse_categorical_accuracy: 0.8677 - val_loss: 4.7422 - val_sparse_categorical_accuracy: 0.3450\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4664 - sparse_categorical_accuracy: 0.8832 - val_loss: 5.1970 - val_sparse_categorical_accuracy: 0.3550\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4801 - sparse_categorical_accuracy: 0.8787 - val_loss: 4.7673 - val_sparse_categorical_accuracy: 0.3427\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4847 - sparse_categorical_accuracy: 0.8764 - val_loss: 4.8093 - val_sparse_categorical_accuracy: 0.3447\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4567 - sparse_categorical_accuracy: 0.8876 - val_loss: 4.9329 - val_sparse_categorical_accuracy: 0.3560\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4707 - sparse_categorical_accuracy: 0.8811 - val_loss: 4.7204 - val_sparse_categorical_accuracy: 0.3420\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4804 - sparse_categorical_accuracy: 0.8781 - val_loss: 4.4837 - val_sparse_categorical_accuracy: 0.3440\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4717 - sparse_categorical_accuracy: 0.8805 - val_loss: 5.0903 - val_sparse_categorical_accuracy: 0.3400\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4517 - sparse_categorical_accuracy: 0.8884 - val_loss: 5.0402 - val_sparse_categorical_accuracy: 0.3617\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4734 - sparse_categorical_accuracy: 0.8792 - val_loss: 4.7631 - val_sparse_categorical_accuracy: 0.3460\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6204 - sparse_categorical_accuracy: 0.8225 - val_loss: 4.4294 - val_sparse_categorical_accuracy: 0.3587\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4888 - sparse_categorical_accuracy: 0.8751 - val_loss: 4.5468 - val_sparse_categorical_accuracy: 0.3470\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4703 - sparse_categorical_accuracy: 0.8836 - val_loss: 4.6660 - val_sparse_categorical_accuracy: 0.3567\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4897 - sparse_categorical_accuracy: 0.8738 - val_loss: 4.2989 - val_sparse_categorical_accuracy: 0.3427\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4675 - sparse_categorical_accuracy: 0.8839 - val_loss: 4.8267 - val_sparse_categorical_accuracy: 0.3443\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4494 - sparse_categorical_accuracy: 0.8907 - val_loss: 4.8922 - val_sparse_categorical_accuracy: 0.3383\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4678 - sparse_categorical_accuracy: 0.8826 - val_loss: 4.8030 - val_sparse_categorical_accuracy: 0.3520\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5173 - sparse_categorical_accuracy: 0.8625 - val_loss: 4.5530 - val_sparse_categorical_accuracy: 0.3447\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4893 - sparse_categorical_accuracy: 0.8746 - val_loss: 4.1633 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5172 - sparse_categorical_accuracy: 0.8621 - val_loss: 4.5779 - val_sparse_categorical_accuracy: 0.3457\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4604 - sparse_categorical_accuracy: 0.8857 - val_loss: 4.8936 - val_sparse_categorical_accuracy: 0.3447\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4473 - sparse_categorical_accuracy: 0.8897 - val_loss: 4.6844 - val_sparse_categorical_accuracy: 0.3507\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4909 - sparse_categorical_accuracy: 0.8720 - val_loss: 4.7633 - val_sparse_categorical_accuracy: 0.3493\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.6254 - sparse_categorical_accuracy: 0.8248 - val_loss: 4.1243 - val_sparse_categorical_accuracy: 0.3453\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4984 - sparse_categorical_accuracy: 0.8707 - val_loss: 4.3736 - val_sparse_categorical_accuracy: 0.3350\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4599 - sparse_categorical_accuracy: 0.8869 - val_loss: 4.9262 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4553 - sparse_categorical_accuracy: 0.8857 - val_loss: 4.7135 - val_sparse_categorical_accuracy: 0.3590\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4603 - sparse_categorical_accuracy: 0.8854 - val_loss: 4.7688 - val_sparse_categorical_accuracy: 0.3420\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4951 - sparse_categorical_accuracy: 0.8697 - val_loss: 4.5266 - val_sparse_categorical_accuracy: 0.3500\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5130 - sparse_categorical_accuracy: 0.8651 - val_loss: 4.4148 - val_sparse_categorical_accuracy: 0.3433\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4717 - sparse_categorical_accuracy: 0.8814 - val_loss: 4.8772 - val_sparse_categorical_accuracy: 0.3570\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4776 - sparse_categorical_accuracy: 0.8766 - val_loss: 4.8731 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4487 - sparse_categorical_accuracy: 0.8893 - val_loss: 4.9075 - val_sparse_categorical_accuracy: 0.3470\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4740 - sparse_categorical_accuracy: 0.8801 - val_loss: 4.7208 - val_sparse_categorical_accuracy: 0.3350\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4535 - sparse_categorical_accuracy: 0.8880 - val_loss: 4.5523 - val_sparse_categorical_accuracy: 0.3473\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4820 - sparse_categorical_accuracy: 0.8763 - val_loss: 4.7729 - val_sparse_categorical_accuracy: 0.3507\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4441 - sparse_categorical_accuracy: 0.8906 - val_loss: 4.7701 - val_sparse_categorical_accuracy: 0.3343\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4922 - sparse_categorical_accuracy: 0.8735 - val_loss: 4.7749 - val_sparse_categorical_accuracy: 0.3620\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5166 - sparse_categorical_accuracy: 0.8638 - val_loss: 4.0094 - val_sparse_categorical_accuracy: 0.3573\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4899 - sparse_categorical_accuracy: 0.8725 - val_loss: 4.6194 - val_sparse_categorical_accuracy: 0.3507\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4686 - sparse_categorical_accuracy: 0.8841 - val_loss: 4.6601 - val_sparse_categorical_accuracy: 0.3607\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4670 - sparse_categorical_accuracy: 0.8844 - val_loss: 4.7278 - val_sparse_categorical_accuracy: 0.3507\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4749 - sparse_categorical_accuracy: 0.8808 - val_loss: 4.7275 - val_sparse_categorical_accuracy: 0.3560\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5227 - sparse_categorical_accuracy: 0.8625 - val_loss: 4.5509 - val_sparse_categorical_accuracy: 0.3400\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4364 - sparse_categorical_accuracy: 0.8942 - val_loss: 5.3077 - val_sparse_categorical_accuracy: 0.3653\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4878 - sparse_categorical_accuracy: 0.8740 - val_loss: 4.5509 - val_sparse_categorical_accuracy: 0.3497\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4465 - sparse_categorical_accuracy: 0.8897 - val_loss: 4.7690 - val_sparse_categorical_accuracy: 0.3373\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4731 - sparse_categorical_accuracy: 0.8769 - val_loss: 4.9615 - val_sparse_categorical_accuracy: 0.3547\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4394 - sparse_categorical_accuracy: 0.8923 - val_loss: 5.1936 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4787 - sparse_categorical_accuracy: 0.8777 - val_loss: 5.0108 - val_sparse_categorical_accuracy: 0.3633\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 40s 2ms/step - loss: 0.4787 - sparse_categorical_accuracy: 0.8766 - val_loss: 5.0729 - val_sparse_categorical_accuracy: 0.3403\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4448 - sparse_categorical_accuracy: 0.8915 - val_loss: 4.9890 - val_sparse_categorical_accuracy: 0.3450\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4549 - sparse_categorical_accuracy: 0.8891 - val_loss: 4.7405 - val_sparse_categorical_accuracy: 0.3407\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5120 - sparse_categorical_accuracy: 0.8634 - val_loss: 4.8098 - val_sparse_categorical_accuracy: 0.3490\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4668 - sparse_categorical_accuracy: 0.8838 - val_loss: 4.6570 - val_sparse_categorical_accuracy: 0.3550\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4401 - sparse_categorical_accuracy: 0.8917 - val_loss: 5.2560 - val_sparse_categorical_accuracy: 0.3567\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4601 - sparse_categorical_accuracy: 0.8854 - val_loss: 5.0561 - val_sparse_categorical_accuracy: 0.3623\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4812 - sparse_categorical_accuracy: 0.8755 - val_loss: 4.4633 - val_sparse_categorical_accuracy: 0.3433\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4656 - sparse_categorical_accuracy: 0.8817 - val_loss: 5.3272 - val_sparse_categorical_accuracy: 0.3560\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4520 - sparse_categorical_accuracy: 0.8866 - val_loss: 5.0189 - val_sparse_categorical_accuracy: 0.3617\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4804 - sparse_categorical_accuracy: 0.8755 - val_loss: 4.5241 - val_sparse_categorical_accuracy: 0.3520\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4727 - sparse_categorical_accuracy: 0.8791 - val_loss: 4.9706 - val_sparse_categorical_accuracy: 0.3700\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4658 - sparse_categorical_accuracy: 0.8820 - val_loss: 4.9692 - val_sparse_categorical_accuracy: 0.3473\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4779 - sparse_categorical_accuracy: 0.8806 - val_loss: 3.9448 - val_sparse_categorical_accuracy: 0.3663\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5421 - sparse_categorical_accuracy: 0.8500 - val_loss: 4.8824 - val_sparse_categorical_accuracy: 0.3447\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4380 - sparse_categorical_accuracy: 0.8929 - val_loss: 5.1532 - val_sparse_categorical_accuracy: 0.3570\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4705 - sparse_categorical_accuracy: 0.8786 - val_loss: 5.0531 - val_sparse_categorical_accuracy: 0.3547\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4908 - sparse_categorical_accuracy: 0.8698 - val_loss: 4.6462 - val_sparse_categorical_accuracy: 0.3437\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4489 - sparse_categorical_accuracy: 0.8897 - val_loss: 5.0753 - val_sparse_categorical_accuracy: 0.3620\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4633 - sparse_categorical_accuracy: 0.8845 - val_loss: 4.5548 - val_sparse_categorical_accuracy: 0.3317\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4796 - sparse_categorical_accuracy: 0.8755 - val_loss: 4.7593 - val_sparse_categorical_accuracy: 0.3487\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4422 - sparse_categorical_accuracy: 0.8936 - val_loss: 5.0166 - val_sparse_categorical_accuracy: 0.3567\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4888 - sparse_categorical_accuracy: 0.8721 - val_loss: 4.5493 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5011 - sparse_categorical_accuracy: 0.8676 - val_loss: 4.6627 - val_sparse_categorical_accuracy: 0.3527\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4311 - sparse_categorical_accuracy: 0.8944 - val_loss: 4.9613 - val_sparse_categorical_accuracy: 0.3617\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4429 - sparse_categorical_accuracy: 0.8905 - val_loss: 5.0698 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4507 - sparse_categorical_accuracy: 0.8864 - val_loss: 4.9587 - val_sparse_categorical_accuracy: 0.3617\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4467 - sparse_categorical_accuracy: 0.8908 - val_loss: 5.2297 - val_sparse_categorical_accuracy: 0.3690\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4464 - sparse_categorical_accuracy: 0.8897 - val_loss: 4.9185 - val_sparse_categorical_accuracy: 0.3450\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4550 - sparse_categorical_accuracy: 0.8867 - val_loss: 4.8640 - val_sparse_categorical_accuracy: 0.3447\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4793 - sparse_categorical_accuracy: 0.8785 - val_loss: 4.7337 - val_sparse_categorical_accuracy: 0.3350\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4518 - sparse_categorical_accuracy: 0.8876 - val_loss: 4.6974 - val_sparse_categorical_accuracy: 0.3393\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4335 - sparse_categorical_accuracy: 0.8972 - val_loss: 4.8705 - val_sparse_categorical_accuracy: 0.3587\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4882 - sparse_categorical_accuracy: 0.8742 - val_loss: 4.6040 - val_sparse_categorical_accuracy: 0.3577\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4683 - sparse_categorical_accuracy: 0.8799 - val_loss: 4.9758 - val_sparse_categorical_accuracy: 0.3523\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 40s 2ms/step - loss: 0.4340 - sparse_categorical_accuracy: 0.8954 - val_loss: 5.1227 - val_sparse_categorical_accuracy: 0.3600\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4582 - sparse_categorical_accuracy: 0.8831 - val_loss: 5.1026 - val_sparse_categorical_accuracy: 0.3580\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4851 - sparse_categorical_accuracy: 0.8760 - val_loss: 4.7772 - val_sparse_categorical_accuracy: 0.3573\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4446 - sparse_categorical_accuracy: 0.8894 - val_loss: 4.7168 - val_sparse_categorical_accuracy: 0.3420\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4424 - sparse_categorical_accuracy: 0.8912 - val_loss: 5.0574 - val_sparse_categorical_accuracy: 0.3587\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5600 - sparse_categorical_accuracy: 0.8463 - val_loss: 4.3065 - val_sparse_categorical_accuracy: 0.3493\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4828 - sparse_categorical_accuracy: 0.8745 - val_loss: 4.7718 - val_sparse_categorical_accuracy: 0.3520\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4271 - sparse_categorical_accuracy: 0.8992 - val_loss: 5.1805 - val_sparse_categorical_accuracy: 0.3433\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4532 - sparse_categorical_accuracy: 0.8879 - val_loss: 5.1558 - val_sparse_categorical_accuracy: 0.3583\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4364 - sparse_categorical_accuracy: 0.8954 - val_loss: 5.1193 - val_sparse_categorical_accuracy: 0.3497\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4629 - sparse_categorical_accuracy: 0.8835 - val_loss: 4.6994 - val_sparse_categorical_accuracy: 0.3433\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4668 - sparse_categorical_accuracy: 0.8811 - val_loss: 5.1329 - val_sparse_categorical_accuracy: 0.3453\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4365 - sparse_categorical_accuracy: 0.8917 - val_loss: 4.9357 - val_sparse_categorical_accuracy: 0.3320\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4745 - sparse_categorical_accuracy: 0.8784 - val_loss: 5.1581 - val_sparse_categorical_accuracy: 0.3530\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4417 - sparse_categorical_accuracy: 0.8922 - val_loss: 4.9374 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4541 - sparse_categorical_accuracy: 0.8867 - val_loss: 5.3926 - val_sparse_categorical_accuracy: 0.3567\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4402 - sparse_categorical_accuracy: 0.8914 - val_loss: 5.1118 - val_sparse_categorical_accuracy: 0.3623\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4630 - sparse_categorical_accuracy: 0.8827 - val_loss: 4.9404 - val_sparse_categorical_accuracy: 0.3457\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4531 - sparse_categorical_accuracy: 0.8889 - val_loss: 4.6090 - val_sparse_categorical_accuracy: 0.3410\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4348 - sparse_categorical_accuracy: 0.8913 - val_loss: 5.3697 - val_sparse_categorical_accuracy: 0.3507\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4372 - sparse_categorical_accuracy: 0.8929 - val_loss: 5.0038 - val_sparse_categorical_accuracy: 0.3470\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4648 - sparse_categorical_accuracy: 0.8801 - val_loss: 4.6982 - val_sparse_categorical_accuracy: 0.3433\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4624 - sparse_categorical_accuracy: 0.8825 - val_loss: 5.1947 - val_sparse_categorical_accuracy: 0.3507\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4947 - sparse_categorical_accuracy: 0.8697 - val_loss: 4.5731 - val_sparse_categorical_accuracy: 0.3680\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4783 - sparse_categorical_accuracy: 0.8762 - val_loss: 4.8109 - val_sparse_categorical_accuracy: 0.3430\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4717 - sparse_categorical_accuracy: 0.8794 - val_loss: 4.5709 - val_sparse_categorical_accuracy: 0.3373\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4402 - sparse_categorical_accuracy: 0.8898 - val_loss: 5.2479 - val_sparse_categorical_accuracy: 0.3677\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4329 - sparse_categorical_accuracy: 0.8934 - val_loss: 5.3083 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4401 - sparse_categorical_accuracy: 0.8916 - val_loss: 5.3942 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4608 - sparse_categorical_accuracy: 0.8848 - val_loss: 5.2660 - val_sparse_categorical_accuracy: 0.3477\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4442 - sparse_categorical_accuracy: 0.8920 - val_loss: 5.1337 - val_sparse_categorical_accuracy: 0.3577\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4698 - sparse_categorical_accuracy: 0.8797 - val_loss: 4.6959 - val_sparse_categorical_accuracy: 0.3503\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6109 - sparse_categorical_accuracy: 0.8279 - val_loss: 3.8390 - val_sparse_categorical_accuracy: 0.3400\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4972 - sparse_categorical_accuracy: 0.8704 - val_loss: 4.8200 - val_sparse_categorical_accuracy: 0.3383\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4311 - sparse_categorical_accuracy: 0.8963 - val_loss: 4.9088 - val_sparse_categorical_accuracy: 0.3410\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4316 - sparse_categorical_accuracy: 0.8941 - val_loss: 5.3436 - val_sparse_categorical_accuracy: 0.3393\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4193 - sparse_categorical_accuracy: 0.9004 - val_loss: 5.4125 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4324 - sparse_categorical_accuracy: 0.8958 - val_loss: 5.3654 - val_sparse_categorical_accuracy: 0.3383\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4774 - sparse_categorical_accuracy: 0.8759 - val_loss: 4.4949 - val_sparse_categorical_accuracy: 0.3420\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4721 - sparse_categorical_accuracy: 0.8781 - val_loss: 4.8249 - val_sparse_categorical_accuracy: 0.3410\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4798 - sparse_categorical_accuracy: 0.8767 - val_loss: 4.3190 - val_sparse_categorical_accuracy: 0.3493\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4834 - sparse_categorical_accuracy: 0.8759 - val_loss: 4.4499 - val_sparse_categorical_accuracy: 0.3513\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4634 - sparse_categorical_accuracy: 0.8847 - val_loss: 4.3029 - val_sparse_categorical_accuracy: 0.3427\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4479 - sparse_categorical_accuracy: 0.8888 - val_loss: 5.2865 - val_sparse_categorical_accuracy: 0.3547\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4246 - sparse_categorical_accuracy: 0.8990 - val_loss: 5.0357 - val_sparse_categorical_accuracy: 0.3490\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4403 - sparse_categorical_accuracy: 0.8908 - val_loss: 5.0210 - val_sparse_categorical_accuracy: 0.3443\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4507 - sparse_categorical_accuracy: 0.8869 - val_loss: 4.8561 - val_sparse_categorical_accuracy: 0.3407\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4292 - sparse_categorical_accuracy: 0.8955 - val_loss: 5.2800 - val_sparse_categorical_accuracy: 0.3493\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5506 - sparse_categorical_accuracy: 0.8511 - val_loss: 4.1246 - val_sparse_categorical_accuracy: 0.3417\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.8395 - sparse_categorical_accuracy: 0.7340 - val_loss: 2.9432 - val_sparse_categorical_accuracy: 0.3557\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.6177 - sparse_categorical_accuracy: 0.8226 - val_loss: 4.0960 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4916 - sparse_categorical_accuracy: 0.8742 - val_loss: 4.5010 - val_sparse_categorical_accuracy: 0.3500\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4523 - sparse_categorical_accuracy: 0.8879 - val_loss: 4.7899 - val_sparse_categorical_accuracy: 0.3517\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5403 - sparse_categorical_accuracy: 0.8558 - val_loss: 3.9971 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5399 - sparse_categorical_accuracy: 0.8533 - val_loss: 4.0178 - val_sparse_categorical_accuracy: 0.3397\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4683 - sparse_categorical_accuracy: 0.8823 - val_loss: 4.4438 - val_sparse_categorical_accuracy: 0.3413\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4469 - sparse_categorical_accuracy: 0.8904 - val_loss: 4.5698 - val_sparse_categorical_accuracy: 0.3477\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4552 - sparse_categorical_accuracy: 0.8864 - val_loss: 4.8145 - val_sparse_categorical_accuracy: 0.3470\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4696 - sparse_categorical_accuracy: 0.8814 - val_loss: 4.8297 - val_sparse_categorical_accuracy: 0.3430\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4254 - sparse_categorical_accuracy: 0.8963 - val_loss: 5.3060 - val_sparse_categorical_accuracy: 0.3497\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4506 - sparse_categorical_accuracy: 0.8871 - val_loss: 4.6337 - val_sparse_categorical_accuracy: 0.3497\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4452 - sparse_categorical_accuracy: 0.8892 - val_loss: 4.9165 - val_sparse_categorical_accuracy: 0.3430\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4431 - sparse_categorical_accuracy: 0.8889 - val_loss: 4.9253 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4512 - sparse_categorical_accuracy: 0.8864 - val_loss: 4.9427 - val_sparse_categorical_accuracy: 0.3533\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4658 - sparse_categorical_accuracy: 0.8815 - val_loss: 4.4791 - val_sparse_categorical_accuracy: 0.3530\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5146 - sparse_categorical_accuracy: 0.8649 - val_loss: 4.0581 - val_sparse_categorical_accuracy: 0.3340\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4709 - sparse_categorical_accuracy: 0.8824 - val_loss: 4.7677 - val_sparse_categorical_accuracy: 0.3590\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4526 - sparse_categorical_accuracy: 0.8878 - val_loss: 4.9891 - val_sparse_categorical_accuracy: 0.3477\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5037 - sparse_categorical_accuracy: 0.8698 - val_loss: 3.9281 - val_sparse_categorical_accuracy: 0.3507\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4578 - sparse_categorical_accuracy: 0.8847 - val_loss: 4.8349 - val_sparse_categorical_accuracy: 0.3593\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4231 - sparse_categorical_accuracy: 0.8991 - val_loss: 4.9818 - val_sparse_categorical_accuracy: 0.3510\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 40s 2ms/step - loss: 0.4288 - sparse_categorical_accuracy: 0.8958 - val_loss: 4.6788 - val_sparse_categorical_accuracy: 0.3383\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4617 - sparse_categorical_accuracy: 0.8824 - val_loss: 4.6598 - val_sparse_categorical_accuracy: 0.3397\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4393 - sparse_categorical_accuracy: 0.8915 - val_loss: 4.8858 - val_sparse_categorical_accuracy: 0.3440\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4354 - sparse_categorical_accuracy: 0.8920 - val_loss: 4.9809 - val_sparse_categorical_accuracy: 0.3600\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4414 - sparse_categorical_accuracy: 0.8913 - val_loss: 5.3489 - val_sparse_categorical_accuracy: 0.3513\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5045 - sparse_categorical_accuracy: 0.8657 - val_loss: 4.3321 - val_sparse_categorical_accuracy: 0.3477\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4604 - sparse_categorical_accuracy: 0.8839 - val_loss: 5.1288 - val_sparse_categorical_accuracy: 0.3517\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4388 - sparse_categorical_accuracy: 0.8915 - val_loss: 4.6044 - val_sparse_categorical_accuracy: 0.3507\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4109 - sparse_categorical_accuracy: 0.9029 - val_loss: 5.3253 - val_sparse_categorical_accuracy: 0.3547\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4509 - sparse_categorical_accuracy: 0.8868 - val_loss: 4.7579 - val_sparse_categorical_accuracy: 0.3533\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4707 - sparse_categorical_accuracy: 0.8793 - val_loss: 4.4177 - val_sparse_categorical_accuracy: 0.3483\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4460 - sparse_categorical_accuracy: 0.8908 - val_loss: 5.0087 - val_sparse_categorical_accuracy: 0.3323\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4342 - sparse_categorical_accuracy: 0.8937 - val_loss: 4.9771 - val_sparse_categorical_accuracy: 0.3437\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4520 - sparse_categorical_accuracy: 0.8850 - val_loss: 5.0217 - val_sparse_categorical_accuracy: 0.3460\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4518 - sparse_categorical_accuracy: 0.8870 - val_loss: 4.6471 - val_sparse_categorical_accuracy: 0.3533\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4324 - sparse_categorical_accuracy: 0.8933 - val_loss: 5.1257 - val_sparse_categorical_accuracy: 0.3487\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4438 - sparse_categorical_accuracy: 0.8906 - val_loss: 4.9602 - val_sparse_categorical_accuracy: 0.3420\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4373 - sparse_categorical_accuracy: 0.8929 - val_loss: 5.1270 - val_sparse_categorical_accuracy: 0.3370\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4547 - sparse_categorical_accuracy: 0.8878 - val_loss: 4.5075 - val_sparse_categorical_accuracy: 0.3400\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5059 - sparse_categorical_accuracy: 0.8651 - val_loss: 4.6523 - val_sparse_categorical_accuracy: 0.3433\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.6650 - sparse_categorical_accuracy: 0.8049 - val_loss: 2.9621 - val_sparse_categorical_accuracy: 0.3550\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5742 - sparse_categorical_accuracy: 0.8373 - val_loss: 4.0309 - val_sparse_categorical_accuracy: 0.3450\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4542 - sparse_categorical_accuracy: 0.8853 - val_loss: 5.1898 - val_sparse_categorical_accuracy: 0.3567\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4208 - sparse_categorical_accuracy: 0.8992 - val_loss: 4.7857 - val_sparse_categorical_accuracy: 0.3293\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4284 - sparse_categorical_accuracy: 0.8962 - val_loss: 4.7233 - val_sparse_categorical_accuracy: 0.3440\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4742 - sparse_categorical_accuracy: 0.8790 - val_loss: 5.2216 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4230 - sparse_categorical_accuracy: 0.8982 - val_loss: 5.1792 - val_sparse_categorical_accuracy: 0.3563\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4199 - sparse_categorical_accuracy: 0.9002 - val_loss: 5.3094 - val_sparse_categorical_accuracy: 0.3517\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4496 - sparse_categorical_accuracy: 0.8889 - val_loss: 5.1276 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.5077 - sparse_categorical_accuracy: 0.8669 - val_loss: 3.9990 - val_sparse_categorical_accuracy: 0.3380\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4523 - sparse_categorical_accuracy: 0.8872 - val_loss: 4.8638 - val_sparse_categorical_accuracy: 0.3407\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4666 - sparse_categorical_accuracy: 0.8806 - val_loss: 4.6425 - val_sparse_categorical_accuracy: 0.3457\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4491 - sparse_categorical_accuracy: 0.8891 - val_loss: 4.8626 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4314 - sparse_categorical_accuracy: 0.8951 - val_loss: 4.9829 - val_sparse_categorical_accuracy: 0.3507\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4296 - sparse_categorical_accuracy: 0.8975 - val_loss: 4.6490 - val_sparse_categorical_accuracy: 0.3383\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4460 - sparse_categorical_accuracy: 0.8879 - val_loss: 5.2345 - val_sparse_categorical_accuracy: 0.3567\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4342 - sparse_categorical_accuracy: 0.8920 - val_loss: 4.9615 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4358 - sparse_categorical_accuracy: 0.8939 - val_loss: 5.2157 - val_sparse_categorical_accuracy: 0.3523\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4528 - sparse_categorical_accuracy: 0.8864 - val_loss: 4.7292 - val_sparse_categorical_accuracy: 0.3350\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4735 - sparse_categorical_accuracy: 0.8792 - val_loss: 4.6189 - val_sparse_categorical_accuracy: 0.3340\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5058 - sparse_categorical_accuracy: 0.8657 - val_loss: 4.5918 - val_sparse_categorical_accuracy: 0.3453\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4271 - sparse_categorical_accuracy: 0.8972 - val_loss: 4.9084 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4539 - sparse_categorical_accuracy: 0.8849 - val_loss: 4.9095 - val_sparse_categorical_accuracy: 0.3600\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4665 - sparse_categorical_accuracy: 0.8772 - val_loss: 4.8524 - val_sparse_categorical_accuracy: 0.3503\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4512 - sparse_categorical_accuracy: 0.8868 - val_loss: 5.1621 - val_sparse_categorical_accuracy: 0.3537\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4195 - sparse_categorical_accuracy: 0.8983 - val_loss: 4.8963 - val_sparse_categorical_accuracy: 0.3513\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4482 - sparse_categorical_accuracy: 0.8890 - val_loss: 4.6743 - val_sparse_categorical_accuracy: 0.3460\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4463 - sparse_categorical_accuracy: 0.8891 - val_loss: 4.9708 - val_sparse_categorical_accuracy: 0.3500\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4276 - sparse_categorical_accuracy: 0.8977 - val_loss: 5.0096 - val_sparse_categorical_accuracy: 0.3490\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4373 - sparse_categorical_accuracy: 0.8917 - val_loss: 5.0866 - val_sparse_categorical_accuracy: 0.3523\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4444 - sparse_categorical_accuracy: 0.8880 - val_loss: 4.7458 - val_sparse_categorical_accuracy: 0.3343\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4206 - sparse_categorical_accuracy: 0.8988 - val_loss: 5.4548 - val_sparse_categorical_accuracy: 0.3637\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4669 - sparse_categorical_accuracy: 0.8784 - val_loss: 4.8219 - val_sparse_categorical_accuracy: 0.3430\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4410 - sparse_categorical_accuracy: 0.8907 - val_loss: 5.1669 - val_sparse_categorical_accuracy: 0.3520\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4768 - sparse_categorical_accuracy: 0.8784 - val_loss: 4.7200 - val_sparse_categorical_accuracy: 0.3480\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4453 - sparse_categorical_accuracy: 0.8915 - val_loss: 5.3286 - val_sparse_categorical_accuracy: 0.3527\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4496 - sparse_categorical_accuracy: 0.8869 - val_loss: 4.6955 - val_sparse_categorical_accuracy: 0.3500\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4713 - sparse_categorical_accuracy: 0.8803 - val_loss: 4.8765 - val_sparse_categorical_accuracy: 0.3420\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4265 - sparse_categorical_accuracy: 0.8955 - val_loss: 5.0475 - val_sparse_categorical_accuracy: 0.3440\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4630 - sparse_categorical_accuracy: 0.8794 - val_loss: 4.7103 - val_sparse_categorical_accuracy: 0.3430\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 40s 2ms/step - loss: 0.4178 - sparse_categorical_accuracy: 0.8991 - val_loss: 5.2755 - val_sparse_categorical_accuracy: 0.3557\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4879 - sparse_categorical_accuracy: 0.8738 - val_loss: 5.1312 - val_sparse_categorical_accuracy: 0.3577\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4503 - sparse_categorical_accuracy: 0.8896 - val_loss: 4.4958 - val_sparse_categorical_accuracy: 0.3490\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4602 - sparse_categorical_accuracy: 0.8823 - val_loss: 5.1376 - val_sparse_categorical_accuracy: 0.3490\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4484 - sparse_categorical_accuracy: 0.8895 - val_loss: 4.3240 - val_sparse_categorical_accuracy: 0.3530\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.7135 - sparse_categorical_accuracy: 0.7887 - val_loss: 3.2652 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5172 - sparse_categorical_accuracy: 0.8636 - val_loss: 4.4244 - val_sparse_categorical_accuracy: 0.3467\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4401 - sparse_categorical_accuracy: 0.8919 - val_loss: 4.8018 - val_sparse_categorical_accuracy: 0.3547\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5705 - sparse_categorical_accuracy: 0.8428 - val_loss: 3.9793 - val_sparse_categorical_accuracy: 0.3427\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5275 - sparse_categorical_accuracy: 0.8642 - val_loss: 3.8126 - val_sparse_categorical_accuracy: 0.3477\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4895 - sparse_categorical_accuracy: 0.8770 - val_loss: 4.3610 - val_sparse_categorical_accuracy: 0.3293\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5467 - sparse_categorical_accuracy: 0.8528 - val_loss: 3.9848 - val_sparse_categorical_accuracy: 0.3453\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 38s 2ms/step - loss: 0.4617 - sparse_categorical_accuracy: 0.8863 - val_loss: 4.3847 - val_sparse_categorical_accuracy: 0.3497\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4648 - sparse_categorical_accuracy: 0.8814 - val_loss: 4.7543 - val_sparse_categorical_accuracy: 0.3537\n",
      "Epoch 4/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4789 - sparse_categorical_accuracy: 0.8782 - val_loss: 4.2355 - val_sparse_categorical_accuracy: 0.3387\n",
      "Epoch 5/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4387 - sparse_categorical_accuracy: 0.8967 - val_loss: 4.7399 - val_sparse_categorical_accuracy: 0.3470\n",
      "Epoch 6/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.5505 - sparse_categorical_accuracy: 0.8543 - val_loss: 4.0711 - val_sparse_categorical_accuracy: 0.3453\n",
      "Epoch 7/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4634 - sparse_categorical_accuracy: 0.8849 - val_loss: 4.1905 - val_sparse_categorical_accuracy: 0.3467\n",
      "Epoch 8/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4458 - sparse_categorical_accuracy: 0.8933 - val_loss: 4.5918 - val_sparse_categorical_accuracy: 0.3453\n",
      "Epoch 9/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4549 - sparse_categorical_accuracy: 0.8860 - val_loss: 5.0892 - val_sparse_categorical_accuracy: 0.3600\n",
      "Epoch 10/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4258 - sparse_categorical_accuracy: 0.8965 - val_loss: 5.0937 - val_sparse_categorical_accuracy: 0.3453\n",
      "Train on 24634 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4911 - sparse_categorical_accuracy: 0.8722 - val_loss: 4.6900 - val_sparse_categorical_accuracy: 0.3607\n",
      "Epoch 2/10\n",
      "24634/24634 [==============================] - 39s 2ms/step - loss: 0.4874 - sparse_categorical_accuracy: 0.8725 - val_loss: 4.1584 - val_sparse_categorical_accuracy: 0.3437\n",
      "Epoch 3/10\n",
      "24634/24634 [==============================] - 45s 2ms/step - loss: 0.4477 - sparse_categorical_accuracy: 0.8893 - val_loss: 4.6149 - val_sparse_categorical_accuracy: 0.3467\n",
      "Epoch 4/10\n",
      " 5056/24634 [=====>........................] - ETA: 46s - loss: 0.4425 - sparse_categorical_accuracy: 0.8877"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-59c8f06ea98c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mhistory16\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_dev_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_dev_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mhistory16_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    history16 = model16.fit(X_train_n, Y_train_n, epochs=10, batch_size=32, validation_data = (X_dev_n, Y_dev_n))\n",
    "    history16_all.append(history16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
